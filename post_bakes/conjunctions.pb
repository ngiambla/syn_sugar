7 
1 
0 
2 
g 
u 
A 
7 
1 
] 
S 
A 
. 
s 
s 
e 
e 
[ 
1 
v 
2 
0 
3 
5 
0 
. 
8 
0 
7 
1 
: 
v 
i 
X 
r 
a 
AUTOMATICORGANISATION,SEGMENTATION,ANDFILTERINGOFUSER-GENERATEDAUDIOCONTENTGonc¸aloMordido,Jo˜aoMagalh˜aes,SoﬁaCavacoNOVALINCS,DepartamentodeInform´aticaFaculdadedeCiˆenciaseTecnologia,UniversidadeNovadeLisboa2829-516Caparica,Portugalgoncalomordido@gmail.com,{jm.magalhaes,scavaco}@fct.unl.ptABSTRACTUsingsolelytheinformationretrievedbyaudioﬁnger-printingtechniques,weproposemethodstotreatapossiblylargedatasetofuser-generatedaudiocontent,that(1)enablethegroupingofseveralaudioﬁlesthatcontainacommonau-dioexcerpt(i.e.arerelativetothesameevent),and(2)giveinformationabouthowthoseﬁlesarecorrelatedintermsoftimeandqualityinsideeachevent.Furthermore,weusesu-pervisedlearningtodetectincorrectmatchesthatmayarisefromtheaudioﬁngerprintingalgorithmitself,whilstensuringourmodellearnswithpreviouspredictions.Allthepresentedmethodswerefurthervalidatedbyuser-generatedrecordingsofseveraldifferentconcertsmanuallycrawledfromYouTube.IndexTerms—audioﬁngerprinting,user-generatedcon-tent,audiosynchronisation,supervisedlearning1.INTRODUCTIONGiventheabundanceandubiquityofvideo-orientedcontent(and,consequently,audiocontent)experiencedinmostsocialnetworksnowadays,itisimportanttounderstandsuchlargeamountofinformationinameaningfulway.Oneimportantsteptoachievesuchunderstandingistogroupthecontentinseveralclustersbasedonsimilarity,whichinthecontextofthisworkisbasedonevents.Whenweconsiderseveraluser-generatedrecordingsofdifferentlengthsreportingthesameevent,whichisverylikelytohappenduetothenatureofuser-generatedcontent,theexistenceofoverlappingsectionsbetweentwoofsuchrecordingsmeansthattheyshouldbe-longtothesamecluster/event.Audioﬁngerprintinghasbeenprimarilyusedtodetectifagivenquerysongmatchesothersongsinapreexistingdatabase[1,2,6,8].Nonetheless,thisalgorithmretrievesveryvaluableinformation,thatcanbeusedforseveralotherpurposes.Here,weproposetouseittoperformtheorgan-isation(clustering),segmentationandalignment,ofaudiorecordingsofmusicevents.978-1-5090-3649-3/17/$31.00c(cid:13)2017IEEEThemaincontributionsofthispaperarethentheorgan-isationofalargedatasetofaudiorecordingsintothedif-ferenteventstheyportrait(section2),withadditionalinfor-mationregardinghoweachevent’srecordingsaredistributedovertime(section3),andthedetectionandﬁlteringofincor-rectmatchespossiblyretrievedfromtheaudioﬁngerprintingalgorithmusingasupervisedlearningapproach(section4),whilstensuringourmodellearnswithpreviouspredictions(section5).Moreover,ﬁndingcorrelationsbetweenthecontentinsideeachclustercanalsobeverybeneﬁcialtoachieveabettercomprehensionofthedata.Inthisworkweproposetoalignallevent’ssongclipsovertimeandwefurtheruseaqualityinferencetechniquealreadypresentedinpreviousworktoor-derthemintermsoftheirrelativequality[7].2.DATAORGANISATIONConsideringtheabundantandubiquitousnatureofuser-generatedcontent,itisverylikelytodealwithadatabaseofseveraldifferentevents(e.g.audiorecordingsofseveralcon-certs),inwhicheacheventhasseveralrecordingsreportingit(e.g.relativetoacertainconcertsong).Ourgoalisthentogatherallsongclipsofagiveneventintothesamecluster.Ourtechniquetogroupclipsofagiveneventisbasedonthemhavingcommonexcerptsofaudio.Giventhelikelynoisyandtimesparsenatureofuser-generatedcontent(i.e.thedifferentrecordingscapturedifferentpartsoftheevent,withpossibleoverlaps),weneedtouseatechniquethatisresistanttonoiseandatthesametimecanidentifyoverlappingexcerptsinmusicrecordingsfromthesameevent.Audioﬁngerprintingenablessynchronisingaquerysongsqagainstseveralotheraudioclipspresentinaformerlycre-ateddatabase,whilstbeingrelativelyresistanttonoise.Notethatwhenwerefertoaquerysong,wedonotmeanthatwearedealingwiththewholesong,instead,wearereferringtoaportionofthewholesongthathasbeenrecordedinanau-dioclip.Section2.1explainsinmoredetailwhyusingaudioﬁngerprintingtocharacteriseandcomparethedifferentaudio ﬁles(similarlytowhatalreadyproposedinourpreviouswork[7])isappropriatewhendealingwithpossiblyverynoisyau-dioﬁles,whichislikelytobeexperiencedinthecontextofourproblem.Oncetheaudioﬁngerprintsofthedifferentaudioﬁlesarecomparedandpossiblymatched,weusethisinformationtoidentifyoverlappingexcerptsandclusterourdataintothedif-ferentevents.Section2.2takesadeeperlookonhowthegroupingofthedifferentrecordedclipsisindeedachievedandinternallyrepresented.2.1.AudioFingerprintingTheﬁrststepofouralgorithmistocharacterisethedatawithaudioﬁngerprints.Usingaﬁngerprinttocharacteriseeachrecordedclipenablestoefﬁcientlyrepresentandcomparedif-ferentclips,whichisessentialconsideringthevastoccurrenceofuser-generateddataexperiencednowadays.Sincethegen-erationofthisﬁngerprintinvolvesthedirectusage,oracom-binationoffeaturesfromtheaudiosignal,itisimportanttopickthefeaturesthatarethemostrepresentativeand,tosomeextent,invarianttodistortion.Similaritiesbetweenﬁnger-printsofdifferentsongclipsleadtoamatchoftheclips.OuralgorithmusesCottonandEllis’landmark-basedaudioﬁngerprintingalgorithm1,whichisbasedinthewell-knownapproachformerlyproposedbyWang[3,8].Aﬁn-gerprintiscomposedofseverallandmarks,whichinturnaregeneratedthroughtheanalysisoftwofrequencypeakswithhighenergyinasmallperiodoftime.Morespeciﬁcally,alandmarkisapairoftwopeaks,andcontainsinformationabouteachpeakfrequency,thetimeatwhichtheﬁrstpeakoccurred,andthetimeoffsetbetweenthem.Givenaquerysongsq,ouralgorithmusestheaudioﬁn-gerprintsinformationtomatchitagainstthesongclipssinthedatabase[7].Sinceeachaudioclip’sﬁngerprintsarealistoflandmarks,ouralgorithmconsidersthattwosongclips,sqands,containthesameaudioexcerptifmorethanacertainnumberoflandmarksareequalinbothoftheirﬁngerprints;thethresholdusedisnormallyasmallvalue(e.g.5)sincewrongmatchesareunlikely.Todiscoverthetimeoffsetbe-tweenthetwoclipswesimplyneedtoanalysethetimedif-ferencebetweenthetimestampoftheequallandmarksinsqands.2.2.AudioClusteringThesecondstepofouralgorithmistoorganisethedataintoclusters,suchthattheclipsfromthesameevent(i.e.fromthesamewholemusic)areinthesamecluster.Thisisachievedusingtheinformationretrievedfromtheﬁngerprintingstage.Moreover,sincethedifferentrecordingswillverylikelybeindifferentrangesofquality,fromextremelynoisytoclean1Thislandmark-basedaudioﬁngerprintingalgorithmisavailableinhttps://github.com/dpwe/audfprint.recordings,audioﬁngerprintingpermitsthesynchronisationofthelow-qualityrecordingsagainstbetterqualityrecordingsinthedatabase,conceivablyincommonaudioportionsthatmightnotbetooaffectedbynoiseinthelow-qualityrecord-ing.Inordertoorganisetheaudioclipsinthedatabase,wematcheachcliptoalltheotheronespresentinthedatabase,ensuringallclipsaretestedagainstoneanother.Inotherwords,foreachclipinthedatabaseweconsideritasaquerysongandusetheﬁngerprintsinformationtomatchitagainstallotherclipsinthedatabase.Sincetheremaybemultipleclipsforthesameevent(i.e.,wholesong)eachquerysongwilllikelyhaveseveralsongmatches,thattogethercomposethematchinglistofthequerysong.Theﬁngerprintsinformationisusedtobuildagraph,G=(V,E),withthenodes,V,representingallsongclipsinourdatabaseandeachedgeinErepresentingamatchbetweentwoclips.Sinceeachclipisrepresentedbyanode,wewillusethesamename(s)torefertosongclipsandthenodethatrepresentsthatclip.Moreover,eachedgeisassignedaweightthatconsistsoftheoffset(inseconds)betweenthetwoconnectedclips.Inotherwords,ifedge(s1,s2,o12)∈E,thenthereisamatchbetweenclipss1ands2withoffseto12.Isolatednodesinthegraphrepresentclipsthathaveanemptymatchinglistandthatarenotpresentinanyoftheotherclips’matchinglists.Eventhoughtheanalysisoftheweightsofthepathsisnotnecessarytoperformingtheclustering,itwillbeessentialtoperformtheaudiosegmentationpresentedinsection3.Thebasistodetectanddistributetheclipstothedifferentclustersresidesinthenotionthatifthereisapathbetweentwoclips,thentheyshouldbelongtothesamecluster.ThisisanadaptationofKennedyandNaaman’salgorithm,thatusesthisgraph-basedrepresentationtodetectdifferentepisodesinsideagivenevent[5].3.AUDIOSEGMENTATIONAnalysinghowthedifferentclipsofeacheventarescatteredovereachevent’stimelineisofextremeimportancetobettermanagethedifferentaudioﬁles.Thereforethissectionfo-cusesonﬁndingthetimeintervals(i.e.segments)inwhichthedifferentclipsaredistributedinsideeachcluster.Animpor-tantaspectofthissynchronisationtaskisthatitonlyrequiresinformationalreadyobtainedfromtheaudioﬁngerprintingal-gorithmthatwasusedtoperformtheclusteringdescribedinsection2.3.1.AudioSynchronisationTheoffsetsreturnedbytheaudioﬁngerprintingalgorithmwerefurtherusedtoperformthealignmentoftheaudioclips.Thistaskusesthegraph-basedrepresentationofourclips,Gdescribedinsection2.2.Asmentionedabove,theweights oftheedgesaretheoffset(returnedbytheaudioﬁngerprint-ing)betweentwoclips.FollowingthepathsinG,wecanderivetheoffsetsbetweenanytwoclipsinthesameclusterbyaddingtheweightsinthepath(i.e.,bycalculatingthecostofthepath).Itisimportanttonoticethatthisonlyworksbecauseifthereisapositiveedgeinthegraphconnectingtwonodes,thereisalsoanegativeedgeintheoppositedirection.Wecanthenrepresenttheoffsetoijbetweenanytwonodessiandsjthatareinthesamecluster,asoij=cost(G,si,sj).Theactualwaythesynchronisationofallclipsinsideaclusterismadeisbyelectingarepresentativesongclipandbygettingtheoffsetofalltheotherclipsrelativetothisone(thatis,oirforeverysongclipsiinthecluster).Notethattherepresentativeclipcanbeanyofthecluster’sclips,sinceallclipsofagivenevent(cluster)areconnectedinthegraph.Afteralloffsetsareobtained,iftherepresentativeclipisnottherecordingthathastheearlieststartingtimestamp,theoff-setvaluesareupdatedaccordingtotheclipwiththeearliesttimestamp(i.e.theclipthatstartsﬁrstintheevent’stimeline).Wecandeﬁnetheearlieststartingsongclipseastheclipwiththeminimumdistancetothereferenceclipsr:∀si∈Voer≤oir.Thisminimumdistancecaneitherbe0,iftherepresentativesongisindeedtheearlieststartingclip(sinceorr=0),oranegativenumber,ifsestartsbeforesongsr.Afterwards,wecalculatealloffsetsoie.Thesecanbeobtainedbyaddingthevalueofoertothepreviouslycalculatedoffsetsoir:∀si∈Voie=oir+oerUsingthisapproach,alloffsetsaregreaterorequalthan0andcorrectlyalignedintermsoftheirstartingpointalongtheevent’stimeline,sincealloffsetsarenowrelativetotheearlieststartingclip.3.2.Time-basedSegmentationByhavingtheoveralloffsetsofallclipsofagivencluster,togetherwiththedurationofeachclip,onehastheknowledgeofwhichclipsexistinagivenmomentoftime.Thus,wecanorganiseaneventwithsegments,suchthatsegmentscoincidewiththetimeintervalofoverlappingclips.Theoverallevent’stimelinewillbesegmentedintosev-eralnon-overlappingsegments.Givenalloffsetsoie(forallsiinthecluster),anewsegmentfromtimetstarttotimetendiscreatedwhenoneofthefollowingsituationsoccurs:(1)Anewsongclipsistartsattimetstart(oie=tstart).(2)Aclipsiwithdurationd(si)endsattimetend(thatis,oie+d(si)=tend).Asaconsequence,wheneveranewseg-mentstartsattstart,thereisasegmentendingattstart−1,exceptwhentstart=0meaningthatitistheﬁrstsegmentofthatevent.Thesongclipscanthenbecutaccordingtothetimes-tampsofeachofthesegmentstheyarepartof.Forinstance,ifsongs1belongstosegmentAandB,thenthesongiscutintosongs1Aands1B(s1isequaltotheconcatenationofs1Aands1B).Thisinformationisencapsulatedinatuplethatrepresentsasegment.Thetuplecontainsaninitialandﬁnaltimes-tamp,andallclipsthatoverlapbetweenthatperiodoftime,(tstart,tend,s1A,s2A,...).Eachcluster,orevent,isthencomposedbyseveralsegments,thatgiveinformationonwhichclipsareavailableinthedifferenttimeintervalsandthereforeatanymomentoftimeintheevent’stimeline.3.3.QualityInferenceInpreviousworkweproposedamethodtoinferthequalityofeachsongcliprelativetoalltheotherclipsinsideagivenclusterbyanalysingthesumofeachclip’snumberofmatch-inglandmarksagainsttherestoftheclipsinthedatabase[7].Thismethodcanbefurtherusedtoinferthequalityoftheclipsinsideeachsegmentbymatchingthemusingtheaudioﬁngerprintingalgorithm(thatis,thealgorithmiscalledoncemorebutwiththeclipswithinthesegmentandnotallclipsinthedatabase).However,giventhepossiblesmalltimelengthoftheseg-ments,togetherwiththepossiblesmallnumberofclipswithineachsegment,matchesarelesslikelytohappen.Thus,in-creasingthenumberoflandmarksbyincreasingthenumberoflandmarks/secperformedbythealgorithmforeachclip,generatesahighernumberofmatchinglandmarksbetweendifferentsongclipsandthereforeincreasesthelikelinessofmatchestooccur.Sincetheclusterswereformedbasedonsongclipswithcommonexcerpts,andaftertheﬁlteringoffalsematchesthatwillbepresentedinsection4,wecaneliminatethematch-inglandmarksthresholdleadingamatchtobedeclaredevenwithonly1matchinglandmarkbetweentwoclips.Sinceallclipsinsideasegmentaretime-aligned,theexpectedoffsetreturnedbythealgorithmshouldbe0seconds,meaningalltheothermatchinglandmarkswithdifferentoffsetscanbediscardedandnotconsideredfortheclip’squalityscore.Thisqualityinferencestepenablesultimatelyforsongclipstobeorderedbasedontheirrelativequalityinsideeachsegment.Thus,ontopofhavinginformationtowhichclipsareavailableatagiventimeintheoverallevent’stimeline,wenowknowhowthedifferentsongclipsinsidethesegmentrelateintermsoftheirrelativequality.4.FILTERINGMETHODEventhoughunlikely,theprobabilityofafalsematchbe-tweentwoclipsfromtheaudioﬁngerprintingalgorithmisstillgreaterthan0.Weproposeamethodtoﬁlteroutsuchfalsematchesfromtheclusters.Inpreviouswork,weproposedaﬁlteringapproachbasedontheanalysisofsigniﬁcantdropsonthederivativesofthe percentageofmatchinglandmarksbetweenthequeryandmatchedsongrelativetotheoverallnumberofthematchedclip’slandmarks[7].Here,wepresentanalternativemethodthatusesmachinelearningtodetectsuchfalsematches.4.1.FeatureSelectionOursamples,orfeaturevectors,arederivedfromtheﬁnger-printingalgorithm’soutput,andeverysongisrepresentedbyseveralsamples.Eachsamplecorrespondstoamatchre-turnedbytheﬁngerprintingalgorithm.Givenaquerysongsq,theﬁngerprintingalgorithmre-turnsthefollowingforeverysongsiinthedatabase:(1)thenumberoflandmarks,#Lsq,ofthequerysongsq,(2)theoff-setbetweensqandsi,thatisoqi,(3)thenumberofmatchinglandmarkswithoffsetoqi,whichwecall#MLoqi,and(4)thenumberoftotalmatchinglandmarksinalloffsets,#TML.Notethatwhenasongisaddedtothedatabase,thenumberoflandmarkscomputedforthatsongisalsoretrievedfromthealgorithm,hencethenumberoflandmarksofallsongsareknown.Thus,(5)thenumberoflandmarks,#Lsi,ofsongsiisalsoknown.Sincetheactualvalueoftheoffsetdoesnotdirectlyinﬂuenceifamatchiscorrectorincorrect,itisnotconsideredtoenterthefeaturespace.However,alltheotherreferredfeaturesmightbeagoodindicatorofafalsematch.Thesetofavailableandpossiblyrelevantfeatures,foreachpair(sq,si),isthenthefollowing:F={#MLoqi,#TML,#Lsq,#Lsi}.Wetestedourmod-elswithseveralsubsetsofF,morespeciﬁcally:•{#MLoqi,#TML}•{#MLoqi,#TML,#Lsq}•{#MLoqi,#Lsq,#Lsi}•{#MLoqi,#TML,#Lsq,#Lsi}Eachoneofourclassiﬁerswastrainedwiththesefeaturessubsetstoaccesswhichcombinationgeneratesthebestmodel.4.2.TrainingDataSincethegoalofourmodelsistopredictwhetherasampleisafalsematchoratruematch,thereareonlytwoclasses:0and1,respectively.Falsematchesareincorrectmatches.Thesecanbewrongmatches,ifthetwomatchedsongsdonothaveanycommonaudioexcerpt,orrepetitionmatches,iftheyhaveindeedacommonexcerptbuttheassignedoffsetisnotcorrect.Thelattercasecanbeeasilydetectedasithappenswhenasongsiappearsinthematchinglistofaquerysqseveraltimeswithdifferentoffsets,describedasrepetitions.Inthiscase,thematchoffset(oqi)withthehighestnumberofmatchinglandmarksisconsideredatruematch(i.e.,assignedtoclass1),whilstallothermatchoffsets(o0qi,o00qi,o000qi,...)areconsideredfalsematches(i.e.,assignedtoclass0).Adatasetof198audiorecordingﬁles,retrievedfrom23differentconcertsongsfromYouTube,wasusedasthedatabaseoftheaudioﬁngerprintingalgorithm,whichcorre-spondedtoanaverageof8.6differentrecordingsperconcertsong(i.e.event).Thisdatabasegenerated3098matches,whichwereusedtotrain,validate,andtestourmodels.Fromthese,therewere1071truematches(class1)and2027falsematches(class0)fromwhich2021wererepetitionmatchesand6werewrongmatches.Notethatwebalancedthetrain-ingseteverytimeanewmodelwastrained(i.e.thenumberofsamplesofclass0wasequaltothenumberofsamplesofclass1).4.3.ModelEstimationWeusedthreedifferentmethodstosolvethisclassiﬁcationproblem:logisticregression,k-nearestneighbours(kNN),andsupportvectormachines(SVM).Thepurposeofusingdifferentclassiﬁersistohaveabroaderwayofcomparisononhowthedifferentfeaturesusedinﬂuencetheoutcomeoftheoverallpredictionsofthedifferentmethods.Apartfromtryingdifferentfeaturevectors,wealsovariedtheclassiﬁersparameters.Forlogisticregression,wedou-bledthevalueoftheregularisationparametercduring20it-erations(withitsinitialvaluebeingsetto1.0).Wetriedalloddnumbersbetween1and39forthenumberofneighbourskinthekNNclassiﬁer.RegardingtheSVMclassiﬁer,weusedtheRBFkernelandtheoptimalvaluesforcandγwereobtainedbyexecutinganexhaustivesearchoverallpossiblecombinationsofasubsetofpossiblevaluesforeachparame-ter.Forthiswefollowedthemethodologyofusingexponen-tiallygrowingsequences[4].Morespeciﬁcallyvaryingctothefollowingvalues2−5,2−3,...,215,217andγto2−15,2−13,...,23,25.ThissearchingprocessisoftendescribedasGrid-search,anditreturnsthebestvalueofeachparameterofagivenmodel(i.e.thehypothesisthatachievesthehighestaccuracy).Weuseddoublecross-validationtoretrievethemodelwithlowestvalidationerrorforeachclassiﬁer(varyingtheparametersasexplainedabove):westartbyperformingleave-one-song-outcross-validation,inwhicheverysonginthetrainingsetexceptoneareusedtotrainthemodelwithak-foldcross-validation,withk=10,whilsttheleft-outsongisusedtotestthemodel;thisprocessisthenrepeateduntilallsongshavebeenleft-outandrepeatedineverycombinationofpossibleparametersassignedforeachclassiﬁer.Thetrainingandvalidationerrorofeachmodelistheaverageoftheerroroccurredinalltheleave-one-song-outiterations,withtheaccuracyofthemodelbeingtestedontheoverallpredictionsofallleft-outsongs’samples.Followingthesestepsforalldesignatedrangesofpossiblevaluesforthedifferentclassi-ﬁers’parameters,weassignthemodelwithlowestvalidationerrorinthe10-foldvalidationforeachclassiﬁerasthemostsuitablemodel. 4.4.PredictionResultsTheaccuracyresultsforeachclassiﬁerisshowninﬁg-ure1.TheSVMshowedbetterresultsacrossthediffer-entfeaturecombinations(98.23%,97.22%,96.12%,and97.68%,respectively)butwascloselyfollowedbytheotherclassiﬁerswiththeexceptionoflogisticregressionwith(#MLoqi,#Lsq,#Lsi),thatachievedaconsiderablyloweraccuracy(82.07%).Fig.1.Accuracyofthebestmodels(i.e.withlowestvalidationerror)ofeachclassiﬁerforthedifferentcombinationoffeatures.Theparametervaluesaredescribedinsideeachbar.Thenumbersplacedontopofeachbarrepresentthenumberoffalsepositivesforeachmodel.Despitetheirhighaccuracy,modelsthatincorrectlyclas-sifywrongmatches(falsepositives)havesongsofdifferenteventsassignedtothesamecluster,leadingultimatelytothemergeofclustersofdifferentevents.Therefore,insteadofsimplychoosingthemodelwithlowestvalidationerrorforeachclassiﬁer,wecandiscardallmodelsthatwronglyclassi-ﬁedthewrongmatchesandchoosethelowervalidationerrormodeloftheremaining.Figure2showstheupdatedclassi-ﬁersresultsaddingthisconstraint.Eventhoughthemodels’accuracyslightlydecreased,wemanagedtoﬁndnewmodelsforkNNandSVMthatsatisfyourconditionofclassifyingwrongmatchescorrectly(thatis,toclass0),whilstmaintainingahighaccuracy(97.12%and97.49%,respectively).Thelogisticregressionmodelsal-readypresentedinﬁgure1remainedintactsincetheyhadnoincorrectclassiﬁcationsofwrongmatches,exceptwhenus-ingthefeaturecombination(#MLoqi,#TML,#Lsq),withtheiraccuracyof97.40%fortheﬁrstpresentedfeaturecom-bination,and97.21%forthelatter.Insum,thereisaslightadvantageofconsideringonlythemodelswithnoincorrectclassiﬁcationofwrongmatchessincetheirﬁlteringiscrucialintheproposedsolution.Wemanagedtoachievehighaccuracyresultswitheachofthethreeclassiﬁers.UsinglogisticregressionandkNNwith(#MLoqi,#TML),thatis,thematchinglandmarksintherightoffsetandthetotalnumberofmatchinglandmarksinallFig.2.Themodelsthataremissinginthegrahincorrectlyclassi-ﬁedatleastonewrongmatch.NewmodelswithdifferentparametervalueswerefoundforbothkNNandSVMwhilstrespectingthiscondition.detectedoffsets,aswellasusinglogisticregressionandSVMwiththe4feature-combination,wouldrepresentpracticallyviableoptionsforthepresentedﬁlteringapproach.5.LEARNINGEXTENSIONThetrainingsetcanbefurtherexpandedbytheanalysisoftheinformationretrievedfromtheaudioﬁngerprintalgorithmcombinedwithourmodelpredictions.Thisextensioncanoccurintwostages:duringtheaudioclusteringphase(sec-tion2.2),andbytheanalysisofthematchesbetweenthecutsampleswhenperformingtheaudioqualityinferenceinsideeachsegment(section3.3).Duringtheaudioclusteringphase,allrepetitionmatches(repetitionsofagivenmatchedsonginanother’smatchinglist)canbeaddedtothetrainingset:thefeaturevectorsoftherepetitionmatchesareassignedtoclass0.Thisissupportedbytheassumptionthatsinceonlyoneoffsetispossiblebe-tweentwosongs,thecorrectoffsetistheonethatgeneratedmorematchinglandmarks,whilsttheothersarediscarded.Thequalityinferencestagecanserveasaconﬁrmationforsomeofthesamplesthatwerepredictedastruematchesaftertheﬁlteringmethod.SinceallmatchesclassiﬁedaswrongmatchesareﬁlteredintheAudioClusteringphase(section2.2),eitherbythediscardingoftherepetitionsorbyfalsematchesclassiﬁcations,allthesamplesofthesongspresentintheAudioSegmentationphase(section3)werethereforepredictedastruematchesbyourmodel(i.e.as-signedtoclass1).Hence,aftercuttingeachsongaccordingtothedifferentsegmentsinwhichitappears,andbymatchingallcutsongswithoneanotherinsideasegmenttoinferthequality,allmatchesshouldbeassignedtooffset0.0secondssinceallthecutsongsaremeanttobesynchronisedintime.Letusdeﬁnethefunctionoffset(s,S)asreturningthesetofoffsetvaluesofthedifferentmatchesbetweensongsand eachsonginsetS.Functioncount(A,v)retrievesthenumberofoccurrencesoftherealnumbervinsetA,andTM(m)assignssamplematchmtoclass1inthetrainingset.Then,wecandeﬁnethefollowingexpressionforeveryclusterc:∀t∈Tc∀s∈Stcount(offset(s,St\{s}),0)=kSt\{s}k⇒∀m∈Mc:TM(m)wheretisasegmentinTc,whichinturnisthesetof(time)segmentsofclusterc,andStisthesetofsongsinsegmentt.Mcisthesetofallmatches(i.e.samples)inthatcluster.Tosumup,onecanthenassumethat,ifforeachcutsonginsideeachcluster’ssegmentsthereisamatchtoeachoftheothercutsongswithoffsetof0seconds,thenallsamplesthatpreviouslycontributedtotheformationofthatgivenclusterareconsideredtruematchesandaddedtothetrainingsetwiththeirclassassignedto1.6.CONCLUSIONInthisworkweproposedifferentmethodsthatmanipulateandcorrelatedifferentuser-generatedrecordingsinapossi-blylargedatasetofaudioﬁles,contributingultimatelyforabettercomprehensionofthedata.Thebasisofallpresentedworkrelieduponthedirectanalysisoftheinformationre-trievedbythematchesofthedifferentaudioﬁlesfromtheaudioﬁngerprintingalgorithm.Althoughusingaudioﬁngerprintingtoorganisedifferentaudioﬁleswithcommonaudioexcerptswasinitiallypro-posedbyKennedyandNaaman[5]andfurtherextendedinourpreviouswork[7],hereweintroducedanovelﬁlteringapproachbyusingmachinelearningtechniquesandachievingoptimalﬁlteringresults(i.e.successfullyﬁlteringallwrongmatches)whilstalsoachievinghighpredictionaccuracyinourconsiderablelargetestsetup(e.g.97.49%usingSVMand4features).Moreover,weintroducethepossibilityofex-tendingourlearningbyincreasingthetrainingsetindifferentpossiblestages,moreconcretelyintheAudioOrganisationandAudioSegmentationphases,bythedetectionofrepeti-tionsandbytheanalysisofthepreviouspredictions.WeadditionallyproposedAudioSegmentationinsideeachcluster/eventwhichprovidesvaluableinsightonhowthedifferentevent’saudioﬁlesarecorrelatedintermsoftime.Thiscanbeextremelyusefulsinceitprovidestheknowl-edgeofwhichaudioﬁlesareavailableatagivenmomentoftime.Moreover,usingapreviouslyproposedaudioinferenceapproach[7]withparameteradaptationsintheaudioﬁnger-printingalgorithm,wealsorepresenthowthedifferentaudioﬁlesrelateintermsoftheirrelativeaudioqualityinsideeachsegmentofagivencluster.AcknowledgmentsThisworkwaspartiallyfundedbytheH2020ICTprojectCOGNITUSwithgrantagreementNo687605andbythePor-tugueseFoundationforScienceandTechnologyunderprojectNOVA-LINCSPEest/UID/CEC/04516/2013.References[1]AcoustID.Chromaprint—AcoustID.URL:https://acoustid.org/chromaprint.[2]ACRCloud.AutomaticContentRecognitionCloudSer-vices.URL:https://www.acrcloud.com.[3]V.CottonandD.Ellis.“Audioﬁngerprintingtoidentifymultiplevideosofanevent.”In:ICASSP.IEEE,2010,pp.2386–2389.[4]C.Hsu,C.Chang,C.Lin,etal.“Apracticalguidetosupportvectorclassiﬁcation”.In:(2003).[5]L.KennedyandM.Naaman.“LessTalk,MoreRock:AutomatedOrganizationofCommunity-contributedCollectionsofConcertVideos”.In:Proceedingsofthe18thInternationalConferenceonWorldWideWeb.WWW’09.ACM,2009,pp.311–320.[6]Midomi.SearchforMusicUsingYourVoice.URL:http://www.midomi.com/index.php.[7]G.Mordido,J.Magalh˜aes,andS.Cavaco.“AutomaticOrganisationandQualityAnalysisofUser-GeneratedContentwithAudioFingerprinting”.In:201725thEu-ropeanSignalProcessingConference(EUSIPCO)(EU-SIPCO2017).2017,pp.1864–1868.[8]A.L.Wang.“Anindustrial-strengthaudiosearchalgo-rithm”.In:Proceedingsofthe4thInternationalConfer-enceonMusicInformationRetrieval.2003. 
