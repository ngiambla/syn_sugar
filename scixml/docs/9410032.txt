 This paper presents PROVERB a text planner for argumentative texts . 
 PROVERB main feature is that it combines global hierarchical planning and unplanned organization of text with respect to local derivation relations in a complementary way . 
 The former splits the task of presenting a particular proof into subtasks of presenting subproofs . 
 The latter simulates how the next intermediate conclusion to be presented is chosen under the guidance of the local focus . 
 This paper presents a text planner for the verbalization of natural deduction ( ND ) style proofs Gentzen 1935 . 
 Several similar attempts can be found in previous work . 
 Developed before the era of NL generation , the system EXPOUND of Chester 1976 can be characterized as an example of direct translation : Although a sophisticated linearization is applied on the input ND proofs , the steps are then translated locally in a template driven way . 
 ND proofs were tested as input to an early version of the MUMBLE system of McDonald 1983 , the main aim however , was to show the feasibility of the architecture . 
 A more recent attempt can be found in THINKER Edgar and Pelletier 1993 , which implements several interesting but isolated proof presentation strategies , without giving a comprehensive underlying model . 
 Our computational model can therefore be viewed as the first serious attempt at a comprehensive computational model that produces adequate argumentative texts from ND style proofs . 
 The main aim is to show how existing text planning techniques can be adapted for this particular application . 
 To test its feasibility , this computational model is implemented in a system called PROVERB . 
 Most current NL text planners assume that language generation is planned behavior and therefore adopt a hierarchical planning approach Hovy 1988 , Moore 1989 , Dale 1992, Reithinger 1991 . 
 Nonetheless there is psychological evidence that language has an unplanned , spontaneous aspect as well Ochs 1979 . 
 Based on this observation , researchers have exploited organizing text with respect to some local relations . 
 Sibun 1990 implemented a system generating descriptions for objects with a strong domain structure , such as houses , chips and families . 
 Once a discourse is started , local structures suggest the next objects available . 
 Instead of planning globally , short-range strategies are employed to organize a short segment of text . 
 From a computational point of view , a hierarchical planner elaborates recursively on the initial communicative goal until the final subgoals can be achieved by applying a primitive operator . 
 A text generator based on the local organization , in contrast , repeatedly chooses a part of the remaining task and carries it out . 
 The macroplanner of PROVERB combines hierarchical planning with local organization in a uniform planning framework . 
 The hierarchical planning is realized by so-called top-down presentation operators that split the task of presenting a particular proof into subtasks of presenting subproofs . 
 While the overall planning mechanism follows the RST-based planning approach Moore 1989 , Reithinger 1991 , the planning operators more closely resemble the schemata in schema-based planning McKeown 1985, Paris 1988 . 
 Bottom-up presentation operators are devised to simulate the unplanned aspect , where the next intermediate conclusion to be presented is chosen under the guidance of the local focus mechanism in a more spontaneous way . 
 Since top-down operators embody explicit communicative norms , they are always given a higher priority . 
 Only when no top-down presentation operator is applicable , will a bottom-up presentation operator be chosen . 
 This distinction between planned and unplanned presentation leads to a very natural segmentation of the discourse into an attentional hierarchy , since , following the theory of Grosz and Sidner 1986 , there is a one-to-one correspondence between the intentional hierarchy and the attentional hierarchy . 
 This attentional hierarchy is used to make reference choices for inference methods and for previously presented intermediate conclusions . 
 The inference choices are the main concern of the microplanner of PROVERB Huang 1994b . 
 The text planner discussed in this paper is the macroplanner of PROVERB , which translates machine-found proofs in several steps into natural language . 
 PROVERB adopts a reconstructive approach : Once a proof in a machine oriented formalism is generated in the proof development environment  - MKRP , a new proof that more resembles those found in mathematical textbooks is reconstructed Huang 1994a . 
 The reconstructed proof is a proof tree , where proof nodes are derived from their children by applying an inference method ( also called a justification ) . 
 Most of the steps are justified by the application of a definition or a theorem , the rest are justified by inference rules of the natural deduction ( ND ) calculus , such as the `` Case '' rule . 
 Figure  is an example of a segment of a possible input proof , where some nodes are labeled for convenience . 
 The justifications `` Du '' , `` Dsubgr '' , `` Ds '' , `` Dg '' , and `` Tsol '' stand for the definitions of unit element , of subgroup , of subset , of group , and the theorem about solution , respectively . 
 The input proof tree is also augmented with an ordered list of nodes , being roots of subproofs planned in this order . 
 The proof in Figure  is associated with the list : (  ,  ,  ,  ) .
 The macroplanner of PROVERB elaborates on communicative goals , selects and orders pieces of information to fulfill these goals . 
 The output is an ordered sequence of proof communicative act intentions ( PCAs ) . 
 PCAs can be viewed as speech acts in our domain of application . 
 PROVERB combines the two above mentioned presentation modes by encoding communication knowledge for both top-down planning and bottom-up presentation in form of operators in a uniform planning framework . 
 Since top-down presentation operators embody explicit communicative norms , they are given a higher priority . 
 A bottom-up presentation is chosen only when no top-down presentation operator applies . 
 The overall planning framework is realized by the function Present . 
 Taking as input a subproof , Present repeatedly executes a basic planning cycle until the input subproof is conveyed . 
 Each cycle carries out one presentation operator , where Present always tries first to choose and apply a top-down operator . 
 If impossible , a bottom-up operator will be chosen . 
 The function Present is first called with the entire proof as the presentation task . 
 The execution of a top-down presentation operator may generate subtasks by calling it recursively . 
 The discourse produced by each call to Present forms an attentional unit ( compare the subsection below ) . 
 The discourse carried out so far is recorded in a discourse model . 
 Rather than recording the semantic objects and their properties , our discourse model consists basically of the part of the input proof tree which has already been conveyed . 
 The discourse model is also segmented into an attentional hierarchy , where subproofs posted by a top-down presentation operators as subtasks constitute attentional units . 
 The following are some notions useful for the formulation of the presentation operators : 
 Task is the subproof in the input proof whose presentation is the current task . 
 Local focus is the intermediate conclusion last presented , while the semantic objects involved in the local focus are called the focal centers . 
 PCAs are the primitive actions planned during the macroplanning to achieve communicative goals . 
 Like speech acts , PCAs can be defined in terms of the communicative goals they fulfill as well as their possible verbalizations . 
 Based on an analysis of proofs in mathematical textbooks , each PCA has as goal a combination of the following subgoals : 
 Conveying a step of the derivation . 
 The simplest PCA is the operator Derive . 
 Instantiated as below : 
 depending on the reference choices , a possible verbalization is given as following : 
 `` Because a is an element of  and  is a subset of  , according to the definition of subset , a is an element of  . '' 
 Updates of the global attentional structure . 
 These PCAs sometimes also convey a partial plan for the further presentation . 
 Effects of this group of PCAs include : creating new attentional units , setting up partially premises and the goal of a new unit , closing the current unit , or reallocating the attention of the reader from one attentional unit to another . 
 The PCA  
 creates two attentional units with A and B as the assumptions , and Formula as the goal by producing the verbalization : 
 `` To prove Formula , let us consider the two cases by assuming A and B. '' 
 Thirteen PCAs are currently employed in PROVERB . 
 See Huang 1994b for more details . 
 Although top-down and bottom-up presentation activities are of a conceptually different nature , the corresponding communication knowledge is uniformly encoded as presentation operators in a planning framework , similar to the plan operators in other generation systems Hovy 1988 , Moore 1989 , Dale 1992, Reithinger 1991 . 
 In general , presentation operators map an original presentation task into a sequence of subtasks and finally into a sequence of PCAs . 
 All of them have the following four slots : 
 Proof : a proof schema , which characterizes the syntactical structure of a proof segment for which this operator is designed . 
 It plays the role of the goal slot in the traditional planning framework . 
 Applicability Condition : a predicate . 
 Acts : a procedure which essentially carries out a sequence of presentation acts . 
 They are either primitive PCAs , or are recursive calls to the procedure Present for subproofs . 
 Features : a list of features which helps to select the best of a set of applicable operators . 
 This section elaborates on the communicative norms concerning how a proof to be presented can be split into subproofs , as well as how the hierarchically-structured subproofs can be mapped onto some linear order for presentation . 
 In contrast with operators employed in RST-based planners that split goals according to the rhetorical structures , our operators encode standard schemata for presenting proofs , which contain subgoals . 
 The top-down presentation operators are roughly divided into two categories : 
 schemata-based operators encoding complex schemata for the presentation of proofs of a specific pattern ( twelve of them are currently integrated in PROVERB ) , 
 general operators embodying general presentation norms , concerning splitting proofs and ordering subgoals . 
 Let us first look at an operator devised for proof segments containing cases . 
 The corresponding schema of such a proof tree is shown in Figure  . 
 Under two circumstances a writer may recognize that he is confronted with a proof segment containing cases . 
 First , when the subproof that has the structure of Figure  is the current presentation task , tested by ( task  ) . 
 Second , when the disjunction  has just been presented in the bottom-up mode , tested by ( local-focus  ) . 
 Under both circumstances , a communication norm motivates the writer to first present the part leading to  ( in the second case this subgoal has already been achieved ) , and then to proceed with the two cases . 
 It enforces also that certain PCAs be used to mediate between parts of proofs . 
 This procedure is exactly captured by the presentation operator below . 
 Case-Implicit 
 Proof : as given in Figure  
 Applicability Condition : 
 Acts : 
 if  has not been conveyed , then present  ( subgoal 1 ) 
 a PCA with the verbalization : `` First , let us consider the first case by assuming F. '' 
 present  ( subgoal 2 ) a PCA with the verbalization : `` Next , we consider the second case by assuming G . '' 
 present  ( subgoal 3 ) mark  as conveyed 
 features : ( top-down compulsory implicit ) . 
 The feature values can be divided into two groups : those characterizing the style of the text this operator produces , and those concerning other planning aspects . 
 `` Implicit '' is a stylistic feature value , indicating that the splitting of the proof into the three subgoals is not made explicit . 
 In its explicit dual Case-Explicit a PCA is added to the beginning of the Acts slot , which produces the verbalization : 
 `` To prove Q , let us first prove  , and consider the two cases separately . '' 
 The feature value `` compulsory '' indicates that if the applicability condition is satisfied , and the style of the operator conforms to the global style the text planner is committed to , this operator should be chosen . 
 Two weaker values also reflect the specificity of plan operators : `` specific '' and `` general '' . 
 General presentation operators perform a simple task according to some general text organization principles . 
 They either 
 enforce a linearization on subproofs to be presented , or 
 split the task of the presentation of a proof with ordered subproofs into subtasks . 
 The first ordering operator operationalizes a general ordering strategy called minimal load principle . 
 This principle predicates that a writer usually presents shorter branches before longer ones . 
 The argument of Levelt is rather simple : When one branch is chosen to be described first , the writer has to have the choice node flagged in his memory for return . 
 If he follows the shorter branch first , the duration of the load will be shorter . 
 The concrete operator is omitted . 
 Note that , the subproofs being ordered are subproofs conceptually planned while the corresponding proof is constructed . 
 There are two other ordering operators based on general ordering principles : the local focus principle and the proof time order principle Huang 1994b . 
 The invocation of an ordering operator is always followed by the invocation of a splitting operator , which actually posts subgoals by calling the function Present with the ordered goals subsequently . 
 The bottom-up presentation process simulates the unplanned part of proof presentation . 
 Instead of splitting presentation goals into subgoals according to standard schemata , it follows the local derivation relation to find a next proof node or subproof to be presented . 
 In this sense , it is similar to the local organization techniques used in Sibun 1990 . 
 When no top-down presentation operator applies , PROVERB chooses a bottom-up operator . 
 The node to be presented next is suggested by the mechanism of local focus . 
 Although logically any proof node having the local focus as a child could be chosen for the next step , usually the one with the greatest semantic overlapping with the focal centers is preferred . 
 As mentioned above , focal centers are semantic objects mentioned in the proof node which is the local focus . 
 This is based on the observation that if one has proved a property about some semantic objects , one tends to continue to talk about these particular objects before turning to new objects . 
 Let us examine the situation when the proof below is awaiting presentation . 
 Assume that node  is the local focus , the set  are the focal centers ,  is a previously presented node and node  is the current task . 
  is chosen as the next node to be presented , since it does not ( re ) introduce any new semantic object and its overlap with the focal centers (  ) is larger than those of  (  ) . 
 Under different circumstances the derivation of the next-node is also presented in different ways . 
 The corresponding presentation knowledge is encoded as bottom-up presentation operators . 
 The one most frequently used presents one step of derivation : 
 Derive-Bottom-Up . 
 Proof :  
 Applicability Condition :  is suggested by the focus mechanism as the next node , and  ,  ,  are conveyed . 
 Acts : a PCA that conveys the fact that  is derived from the premises  ,  ,  by applying  . 
 Features : ( bottom-up general explicit detailed ) . 
 If the conclusion  , the premises and the method  are instantiated to  , (  ,  ) , def-subset respectively , the following verbalization can be produced : 
 `` Since a is an element of  , and  is a subset of  , a is an element of  according to the definition of subset . '' 
 A trivial subproof may be presented as a single derivation by omitting the intermediate nodes . 
 This next subproof is also suggested by the local focus . 
 This is simulated by a bottom-up operator called Simplify-Bottom-Up . 
 Currently seven bottom-up operators are integrated in PROVERB . 
 Macroplanning produces a sequence of PCAs . 
 Our microplanner is restricted to the treatment of the reference choices for the inference methods and for the previously presented intermediate conclusions . 
 While the former depends on static salience relating to the domain knowledge , the latter is similar to subsequent references , and is therefore sensitive to the context , in particular to its segmentation into attentional hierarchy . 
 Due to space restrictions , we only show the following piece of a preverbal message as an example , being a PCA enriched with reference choices for reasons and method by the microplanner Huang 1994b, Huang 1994b . 
 Our surface generator TAG-GEN Kilger 1994 produces the utterance : 
 `` Since a is an element of U , a is an element of F. ''  
 Notice , only the reason labeled as `` explicit '' is verbalized . 
 Finally , to demonstrate the type of proofs currently generated by PROVERB , below is the complete output for a proof constructed by  - MKRP : 
 Theorem : 
 Let F be a group and U a subgroup of F , if 1 and  are unit elements of F and U respectively , then  . 
 Proof : 
 Let F be a group , U be a subgroup of F , 1 be a unit element of F and  be a unit element of U. According to the definition of unit element ,  . 
 Therefore there is an X ,  . 
 Now suppose that  is such an X . 
 According to the definition of unit element ,  . 
 Since U is a subgroup of F ,  . 
 Therefore  . 
 Similarly  , since  . 
 Since F is a group , F is a semigroup . 
 Because  ,  is a solution of the equation  . 
 Since 1 is a unit element of F ,  . 
 Since 1 is a unit element of F ,  . 
 Because  , 1 is a solution of the equation  . 
 Since F is a group ,  by the uniqueness of solution . 
 This conclusion is independent of the choice of the element  . 
 This paper puts forward an architecture that combines several established NL generation techniques adapted for a particular application , namely the presentation of ND style proofs . 
 We hope that this architecture is also of general interest beyond this particular application . 
 The most important feature of this model is that hierarchical planning and unplanned spontaneous presentation are integrated in a uniform framework . 
 Top-down hierarchical planning views language generation as planned behavior . 
 Based on explicit communicative knowledge encoded as schemata , hierarchical planning splits a presentation task into subtasks . 
 Although our overall presentation mechanism has much in common with that of RST-based text planners , the top-down planning operators contain mostly complex presentation schemata , like those in schema-based planning . 
 Since schemata-based planning covers only proofs of some particular structure , it is complemented by a mechanism called bottom-up presentation . 
 Bottom-up presentation aims at simulating the unplanned part of proof presentation , where a proof node or a subproof awaiting presentation is chosen as the next to be presented via the local derivation relations . 
 Since more than one such node is often available , the local focus mechanism is employed to single out the candidate having the strongest semantic links with the focal centers . 
 The distinction between planned and unplanned behavior enables a very natural segmentation of the discourse into an attentional hierarchy . 
 This provide an appropriate basis for a discourse theory which handles reference choices Huang 1994b . 
 Compared with proofs found in mathematical textbooks , the output of PROVERB is still too tedious and inflexible . 
 The tediousness is largely ascribed to the lack of plan level knowledge of the input proofs , which distinguishes crucial steps from unimportant details . 
 Therefore , sophisticated plan recognition techniques are necessary . 
 The inflexibility of text currently produced is partly inherited from the schemata-based approach , for which a fine-grained planning in terms of single PCAs might be a remedy . 
 It is also partly due to the fixed lexicon choice , which we are currently reimplementing . 
