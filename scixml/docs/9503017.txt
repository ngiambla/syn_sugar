 In dialogues in which both agents are autonomous , each agent deliberates whether to accept or reject the contributions of the current speaker . 
 A speaker cannot simply assume that a proposal or an assertion will be accepted . 
 However , an examination of a corpus of naturally-occurring problem-solving dialogues shows that agents often do not explicitly indicate acceptance or rejection . 
 Rather the speaker must infer whether the hearer understands and accepts the current contribution based on indirect evidence provided by the hearer 's next dialogue contribution . 
 In this paper , I propose a model of the role of informationally redundant utterances in providing evidence to support inferences about mutual understanding and acceptance . 
 The model 
 requires a theory of mutual belief that supports mutual beliefs of various strengths ; 
 explains the function of a class of informationally redundant utterances that cannot be explained by other accounts ; and 
 contributes to a theory of dialogue by showing how mutual beliefs can be inferred in the absence of the master-slave assumption . 
 It seems a perfectly valid rule of conversation not to tell people what they already know . 
 Indeed , Grice 's QUANTITY maxim has often been interpreted this way : Do not make your contribution more informative than is required Grice 1967 . 
 Stalnaker , as well , suggests that to assert something that is already presupposed is to attempt to do something that is already done Stalnaker 1978 . 
 Thus , the notion of what is informative is judged against a background of what is presupposed , i.e. propositions that all conversants assume are mutually known or believed . 
 These propositions are known as the COMMON GROUND Lewis 1969, Grice 1967 . 
 The various formulations of this ` no redundancy ' rule permeate many computational analyses of natural language and notions of cooperativity . 
 However consider the following excerpt from the middle of an advisory dialogue between Harry ( h ) , a talk show host , and Ray ( r ) his caller . 
 h. YUP THAT KNOCKS HER OUT . 
 In standard information theoretic terms , both  and  are REDUNDANT . 
 Harry 's assertion in  simply paraphrases what was said in  and  and so it cannot be adding beliefs to the common ground . 
 Furthermore , the truth of  cannot be in question , for instead of  , Harry could not say Yup , but that doesn't knock her out . 
 So why does Ray ( r ) in  REPEAT Harry 's ( h ) assertion of it does , and why does Harry PARAPHRASE himself and Ray in  . 
 My claim is that informationally redundant utterances ( IRU 's ) have two main discourse functions : 
 to provide EVIDENCE to support the assumptions underlying the inference of mutual beliefs , 
 to CENTER a proposition , ie. make or keep a proposition salient Grosz et al. 1986 . 
 This paper will focus on  leaving  for future work . 
 First consider the notion of evidence . 
 One reason why agents need EVIDENCE for beliefs is that they only have partial information about : 
 the state of world ; 
 the effects of actions ; 
 other agent 's beliefs , preferences and goals . 
 This is especially true when it comes to modelling the effects of linguistic actions . 
 Linguistic actions are different than physical actions . 
 An agent 's prior beliefs , preferences and goals cannot be ascertained by direct inspection . 
 This means that it is difficult for the speaker to verify when an action has achieved its expected result , and so giving and receiving evidence is critical and the process of establishing mutual beliefs is carefully monitored by the conversants . 
 The characterization of IRU 's as informationally redundant follows from an axiomatization of action in dialogue that I will call the DETERMINISTIC MODEL . 
 This model consists of a number of simplifying assumptions such as : 
 Propositions are are either believed or not believed , 
 Propositions representing beliefs and intentions get added to the context by the unilateral action of one conversant , 
 Agents are logically omniscient . 
 The context of a discourse is an undifferentiated set of propositions with no specific relations between them . 
 I claim that these assumptions must be dropped in order to explain the function of IRU 's in dialogue . 
 Section  discusses assumption  ; section  shows how assumption  can be dropped ; section  discusses  ; section  shows that some IRU 's facilitate the inference of relations between adjacent propositions . 
 The account proposed here of how the COMMON GROUND is augmented , is based is Lewis 's SHARED ENVIRONMENT model for common knowledge Lewis 1969, Clark and Marshall 1981 . 
 In this model , mutual beliefs depend on evidence , openly available to the conversants , plus a number of underlying assumptions . 
 Shared Environment Mutual Belief Induction Schema 
 It is mutually believed in a population P that  if and only if some situation  holds such that : 
 Everyone in P has reason to believe that  holds . 
  indicates to everyone in P that everyone in P has reason to believe that  holds . 
  indicates to everyone in P that  . 
 The situation  , used above in the mutual belief induction schema , is the context of what has been said . 
 This schema supports a weak model of mutual beliefs , that is more akin to mutual assumptions or mutual suppositions Prince 1987 . 
 Mutual beliefs can be inferred based on some evidence , but these beliefs may depend on underlying assumptions that are easily defeasible . 
 This model can be implemented using Gallier 's theory of autonomous belief revision and the corresponding system Galliers 1991 . 
 A key part of this model is that some types of evidence provide better support for beliefs than other types . 
 The types of evidence considered are categorized and ordered based on the source of the evidence : hypothesis  <  default  <  inference  <  linguistic  <  physical Clark and Marshall 1981 , Galliers 1991 ) . 
 This ordering reflects the relative defeasibility of different assumptions . 
 Augmenting the strength of an assumption thus decreases its relative defeasibility . 
 A claim of this paper is that one role of IRU 's is to ensure that these assumptions are supported by evidence , thus decreasing the defeasibility of the mutual beliefs that depend on them Galliers 1991 . 
 Thus mutual beliefs depend on a defeasible inference process . 
 All inferences depend on the evidence to support them , and stronger evidence can defeat weaker evidence . 
 So a mutual belief supported as an inference can get defeated by linguistic information . 
 In addition , I adopt an an assumption that a chain of reasoning is only as strong as its weakest link : 
 Weakest Link Assumption : 
 The strength of a belief P depending on a set of underlying assumptions  is MIN ( Strength (  ) ) . 
 This seems intuitively plausible and means that the strength of belief depends on the strength of underlying assumptions , and that for all inference rules that depend on multiple premises , the strength of an inferred belief is the weakest of the supporting beliefs . 
 This representation of mutual belief differs from the common representation in terms of an iterated conjunction Litman and Allen 1990 in that : 
 it relocates information from mental states to the environment in which utterances occur ; 
 it allows one to represent the different kinds of evidence for mutual belief ; 
 it controls reasoning when discrepancies in mutual beliefs are discovered since evidence and assumptions can be inspected ; 
 it does not consist of an infinite list of statements . 
 This section examines the assumption from the DETERMINISTIC MODEL that :  Propositions representing beliefs and intentions get added to the context by the unilateral action of one conversant . 
 This assumption will also be examined in section  . 
 The key claim of this section is that agents monitor the effects of their utterance actions and that the next action by the addressee is taken as evidence of the effect of the speaker 's utterance . 
 That the utterance will have the intended effect is only a hypothesis at the point where the utterance has just been made , irrespective of the intentions of the speaker . 
 This distinguishes this account from others that assume either that utterance actions always succeed or that they succeed unless the addressee previously believed otherwise Litman and Allen 1990, Grosz and Sidner 1990 . 
 I adopt the assumption that the participants in a dialogue are trying to achieve some purpose Grosz and Sidner 1986 . 
 Some aspects of the structure of dialogue arises from the structure of these purposes and their relation to one another . 
 The minimal purpose of any dialogue is that an utterance be understood , and this goal is a prerequisite to achieving other goals in dialogue , such as commitment to future action . 
 Thus achieving mutual belief of understanding is an instance of the type of activity that agents must perform as they collaborate to achieve the purposes of the dialogue . 
 I claim that a model of the achievement of mutual belief of understanding can be extended to the achievement of other goals in dialogue . 
 Achieving understanding is not unproblematic , it is a process that must be managed , just as other goal achieving processes are Clark and Schaefer 1989 . 
 Inference of mutual understanding relies upon some evidence , e.g. the utterance that is made , and a number of underlying assumptions . 
 The assumptions are given with the inference rule below . 
 This schema means that when A says u to B intending to convey p , that this leads to the mutual belief that B understands u as p under certain assumptions . 
 The assumptions are that A and B were copresent , that B was attending to the utterance event , that B heard the utterance , and that B believes that the utterance u realizes the intended meaning p . 
 The [ evidence-type ] annotation indicates the strength of evidence supporting the assumption . 
 All of the assumptions start out supported by no evidence ; their evidence type is therefore hypothesis . 
 It isn't until after the addressee 's next action that an assumption can have its strength modified . 
 The claim here is that one class of IRU 's addresses these assumptions underlying the inference of mutual understanding . 
 Each type of IRU , the assumption addressed and the evidence type provided is given in Figure  . 
 Examples are provided in sections  and  . 
 It is also possible that A intends that BY saying u , which realizes p , B should make a certain inference q. Then B 's understanding of u should include B making this inference . 
 This adds an additional assumption : 
 Thus assuming that q was inferred relies on the assumption that B believes that p licenses q in the context . 
 Figure  says that prompts , repetitions , paraphrases and making inferences explicit all provide linguistic evidence of attention . 
 All that prompts such as uh huh do is provide evidence of attention . 
 However repetitions , paraphrases and making inferences explicit also demonstrate complete hearing . 
 In addition , a paraphrase and making an inference explicit provides linguistic evidence of what proposition the paraphraser believes the previous utterance realizes . 
 Explicit inferences additionally provide evidence of what inferences the inferrer believes the realized proposition licenses in this context . 
 In each case , the IRU addresses one or more assumptions that have to be made in order to infer that mutual understanding has actually been achieved . 
 The assumption , rather than being a hypothesis or a default , get upgraded to a support type of linguistic as a result of the IRU . 
 The fact that different IRU 's address different assumptions leads to the perception that some IRU 's are better evidence for understanding than others , e.g. a PARAPHRASE is stronger evidence of understanding than a REPEAT Clark and Schaefer 1989 . 
 In addition , any next utterance by the addressee can upgrade the strength of the underlying assumptions to default ( See Figure  ) . 
 Of course default evidence is weaker than linguistic evidence . 
 The basis for these default inferences will be discussed in section  . 
 Consider example  in section  . 
 Ray , in  , repeats Harry 's assertion from  . 
 This upgrades the evidence for the assumptions of hearing and attention associated with utterance  from hypothesis to linguistic . 
 The assumption about what proposition p 7 is realized by u 7 remains a default . 
 This instantiates the inference rule for understanding as follows : 
 Because of the WEAKEST LINK assumption , the belief about understanding is still a default . 
 Consider the following excerpt : 
 Harry 's utterance of  is said with a falling intonational contour and hence is unlikely to be a question . 
 This utterance results in an instantiation of the inference rule as follows : 
 In this case , the belief about understanding is supported by linguistic evidence since all of the supporting assumptions are supported by linguistic evidence . 
 Thus a paraphrase provides excellent evidence that an agent actually understood what another agent meant . 
 In addition , these IRU 's leave a proposition salient , where otherwise the discourse might have moved on to other topics . 
 This is part of the CENTERING function of IRU 's and is left to future work . 
 This section discusses assumption  of the determistic model , namely that : Agents are logically omniscient . 
 This assumption is challenged by a number of cases in naturally occurring dialogues where inferences that follow from what has been said are made explicit . 
 I restrict the inferences that I discuss to those that are 
 based on information explicitly provided in the dialogue or , 
 licensed by applications of Gricean Maxims such as scalar implicature inferences Hirschberg 1985 . 
 For example the logical omniscience assumption would mean that if  and  below are in the context , then  will be as well since it is entailed from  and  . 
 You can buy an I R A if and only if you do NOT have an existing pension plan . 
 You have an existing pension plan . 
 You cannot buy an I R A . 
 The following excerpt demonstrates this structure . 
 Utterance  realizes  , utterance  realizes  , and utterance  makes the inference explicit that is given in  for the particular tax year of 1981 . 
 After  , since the propositional content of  is inferrable , the assumption that Harry has made this inference is supported by the inference evidence type : 
 According to the model of achieving mutual understanding that was outlined in section  , utterance  provides linguistic evidence that Harry ( h ) believes that the proposition realized by utterance  licenses the inference of  in this context . 
 Furthermore , the context here consists of a discussion of two tax years 1981 and 1982 . 
 Utterance  selects eighty one , with a narrow focus pitch accent . 
 This implicates that there is some other tax year for which Joe is eligible , namely 1982 Hirschberg 1985 . 
 Joe 's next utterance , but I am for 82 , reinforces the implicature that Harry makes in  , and upgrades the evidence underlying the assumption that  licenses  to linguistic . 
 A subcase of ensuring that certain inferences get made involves the juxtaposition of two propositions . 
 These cases challenge the assumption that :  The context of a discourse is an undifferentiated set of propositions with no specific relations between them . 
 While this assumption is certainly not made in most discourse models , it is often made in semantic models of the context Stalnaker 1987 . 
 In the following segment , Jane ( j ) describes her financial situation to Harry ( h ) and a choice between a settlement and an annuity . 
 Harry interrupts her at  since he believes he has enough information to suggest a course of action , and tells her take your money . 
 To provide SUPPORT for this course of action he produces an inference that follows from what she has told him in  , namely You 're only getting 1500 ( dollars ) a year . 
 SUPPORT is a general relation that holds between beliefs and intentions in this model . 
 Presumably Jane would have no trouble calculating that $125.45 a month for 12 months amounts to a little over $1500 a year , and thus can easily accept this statement that is intended to provide the necessary SUPPORT relation , ie. the juxtaposition of this fact against the advice to take the money conveys that the fact that she is only getting 1500 dollars a year is a reason for her to adopt the goal of taking the money , although this is not explicitly stated . 
 In section  , I examine the assumption that :  Propositions representing beliefs and intentions get added to the context by the unilateral action of one conversant . 
 I suggested that this assumption can be replaced by adopting a model in which agents ' behavior provides evidence for whether or not mutual understanding has been achieved . 
 I also discussed some of the effects of resource bounds , ie. cases of ensuring that or providing evidence that certain inferences dependent on what is said are made . 
 Achieving understanding and compensating for resource bounds are issues for a model of dialogue whether or not agents are autonomous . 
 But agents ' autonomy means there are a number of other reasons why A 's utterance to B conveying a proposition p might not achieve its intended effect : 
 p may not cohere with B 's beliefs , 
 B may not think that p is relevant , 
 B may believe that p does not contribute to the common goal , 
 B may prefer doing or believing some q where p is mutually exclusive with q , 
 If p is about an action , B may want to partially modify p with additional constraints about how , or when p . 
 Therefore it is important to distinguish an agent actually ACCEPTING the belief that p or intending to perform an action described by p from merely understanding that p was conveyed . 
 Other accounts legislate that helpful agents should adopt other 's beliefs and intentions or that acceptance depends on whether or not the agent previously believed  p Litman and Allen 1990, Grosz and Sidner 1990 . 
 But agents can decide whether as well as how to revise their beliefs Galliers 1991 . 
 Evidence of acceptance may be given explicitly , but acceptance can be inferred in some dialogue situations via the operation of a simple principle of cooperative dialogue : 
 COLLABORATIVE PRINCIPLE : 
 Conversants must provide evidence of a detected discrepancy in belief as soon as possible . 
 This principle claims that evidence of conflict should be made apparent in order to keep default inferences about acceptance or understanding from going through . 
 IRU 's such as PROMPTS , REPETITIONS , PARAPHRASES , and making an INFERENCE explicit cannot function as evidence for conflicts in beliefs or intentions via their propositional content since they are informationally redundant . 
 If they are realized with question intonation , the inference of acceptance is blocked . 
 In the dialogue below between Harry ( h ) and Ruth ( r ) , Ruth in  , first ensures that she understood Harry correctly , and then provides explicit evidence of non-acceptance in  , based on her autonomous preferences about how her money is invested . 
 In the following example , Joe in  makes a statement that provides propositional content that conflicts with Harry 's statement in  and thus provides evidence of non-acceptance . 
 Joe 's statement is based on his prior beliefs . 
 In both of these cases this evidence for conflict is given immediately . 
 However when there is no evidence to the contrary , and goals of the discourse require achievement of acceptance , inferences about acceptance are licensed as default . 
 They can be defeated later by stronger evidence . 
 Without this principle , a conversant might not bring up an objection until much later in the conversation , at which point the relevant belief and some inferences following from that belief will have been added to the common ground as defaults . 
 The result of this is that the retraction of that belief results in many beliefs being revised . 
 The operation of this principle helps conversants avoid replanning resulting from inconsistency in beliefs , and thus provides a way to manage the augmentation of the common ground efficiently . 
 The first point to note is that the examples here are only a subset of the types of IRU 's that occur in dialogues . 
 I use the term antecedent to refer to the most recent utterance which should have added the proposition to the context . 
 This paper has mainly focused on cases where the IRU : 
 is adjacent to its antecedent , rather than remote ; 
 realizes a proposition whose antecedent was said by another conversant , 
 has only one antecedent . 
 It is with respect to this subset of the data that the alternate hypotheses are examined . 
 A distributional analysis of a subset of the corpus ( 171 IRU 's from 24 dialogues consisting of 976 turns ) , on the relation of an IRU to its antecedent and the context , shows that 35 % of the tokens occur remotely from their antecedents , that 32 % have more than one antecedent , that 48 % consist of the speaker repeating something that he said before and 52 % consist of the speaker repeating something that the other conversant said . 
 So the data that this paper focuses on accounts for about 30 % of the data . 
 In example  of section  , an alternative account of Ray 's repetition in  is that it is a question of some kind . 
 This raises a number of issues : 
 Why doesn't it have the form of a question ? , 
 What is it a question about ? , and 
 Why is it never denied ?
 Of 171 IRU 's , only 28 are realized with rising question intonation . 
 Of these 28 , 6 are actually redundant questions with question syntax , and 14 are followed by affirmations . 
 If these are generally questions , then one possible answer to what the question is about is that Ray is questioning whether he actually heard properly . 
 But then why doesn't he use an intonational contour that conveys this fact as Ruth does in example  ? 
 On an efficiency argument , it is hard to imagine that it would have cost Ray any more effort to have done so . 
 Finally , if it were a question it would seem that it should have more than one answer . 
 While 50 of these IRU 's are followed by an affirmation such as that 's correct , right , yup , none of them are ever followed by a denial of their content . 
 It seems an odd question that only has one answer . 
 Another hypothesis is that IRU 's result from the radio talk show environment in which silence is not tolerated . 
 So agents produce IRU 's because they cannot think of anything else to say but feel as though they must say something . 
 The first point to note is that IRU 's actually occur in dialogues that aren't on the radio Carletta 1992 . 
 The second question is why an agent would produce an IRU , rather than some other trivial statement such as I didn't know that . 
 Third , why don't these utterance correlate with typical stalling behavior such as false starts , pauses , and filled pauses such as uhhh . 
 The dead air hypothesis would seem to rely on an assumption that at unpredictable intervals , agents just can't think very well . 
 My claim is that IRU 's are related to goals , that they support inferencing and address assumptions underlying mutual beliefs , ie. they are not random . 
 In order to prove this it must be possible to test the hypothesis that it is only important propositions that get repeated , paraphrased or made explicit . 
 This can be based on analyzing when the information that is repeated has been specifically requested , such as in the caller 's opening question or by a request for information from Harry . 
 It should also be possible to test whether the IRU realizes a proposition that plays a role in the final plan that Harry and the caller negotiate . 
 However this type of strong evidence against the dead air hypothesis is left to future work . 
 It should be apparent from the account that the types of utterances examined here are not really redundant . 
 The reason that many models of belief transfer in dialogue would characterize them as redundant follows from a combination of facts : 
 The representation of belief in these models has been binary ; 
 The effects of utterance actions are either assumed to always hold , or to hold as defaults unless the listener already believed otherwise . 
 This means that these accounts cannot represent the fact that a belief must be supported by some kind of evidence and that the evidence may be stronger or weaker . 
 It also follows from  that these models assume that agents are not autonomous , or at least do not have control over their own mental states . 
 But belief revision is surely an autonomous process ; agents can choose whether to accept a new belief or revise old beliefs Galliers 1991, Grosz and Sidner 1990 . 
 The occurrence of IRU 's in dialogue has many ramifications for a model of dialogue . 
 Accounting for IRU 's has two direct effects on a dialogue model . 
 First it requires a model of mutual beliefs that specifies how mutual beliefs are inferred and how some mutual beliefs can be as weak as mutual suppositions . 
 One function of IRU 's is to address the assumptions on which mutual beliefs are based . 
 Second the assumption that propositions representing beliefs and intentions get added to the context by the unilateral action of one conversant must be dropped . 
 This account replaces that assumption with a model in which the evidence of the hearer must be considered to establish mutual beliefs . 
 The claim here is that both understanding and acceptance are monitored . 
 The model outlined here can be used for different types of dialogue , including dialogues in which agents are constructing mutual beliefs to support future action by them jointly or alone . 
 How and when agents decide to augment the strength of evidence for a belief has not been addressed in this work as yet . 
 Future work includes analyzing the corpus with respect to whether the IRU plays a role in the final plan that is negotiated between the conversants . 
