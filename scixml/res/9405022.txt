 The RHS preposition Prep is always a lexical lookup , and the entropy is thus zero , while the RHS NP in one case attaches to the LHS of rule np_det_np , in one case to the LHS of rule np_num , and in one case is a lexical lookup , and the resulting entropy is thus .
 In practice this was accomplished by compiling an and-or graph from the and-or tree and the set of selected cutnodes , where each set of equated nodes constituted a vertex of the graph , and traversing it .
 In the simplest scheme for calculating the entropy of an or-node , only the RHS phrase of the parent rule , i.e. the dominating and-node , contributes to the entropy , and there is in fact no need to employ an and-or tree at all , since the tree-cutting criterion becomes local to the parse tree being cut up .
 For example , the entropy of node n3 of the and-or tree of Figure will be calculated as follows : The mother rule vp_v_np will contribute the entropy associated with the RHS NP , which is , referring to the table above , 0.64 .
 The EBG scheme has previously proved most successful for tuning a natural-language grammar to a specific application domain and thereby achieve very much faster parsing , at the cost of a small reduction in coverage .
 Instruments have been developed and tested for controlling the coverage and for avoiding a large number of short reductions , which is argued to be the main source to poor parser performance .
 Although these instruments are currently slightly too blunt to enable producing grammars with the same high performance as the hand-coded tree-cutting criteria , they can most probably be sharpened by future research , and in particular refined to achieve the delicate balance between high coverage and a distribution of reduction lengths that is sufficiently biased towards long reductions .
