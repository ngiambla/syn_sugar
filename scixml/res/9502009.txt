 Given the verb v , the syntactic-relationship s and the candidate class c , the Association Score , Assoc , between v and c in s is defined : The two terms of Assoc try to capture different properties : Mutual information ratio , , measures the strength of the statistical association between the given verb v and the candidate class c in the given syntactic position s.
 It compares the prior distribution , , with the posterior distribution , . scales up the strength of the association by the frequency of the relationship .
 In intuitive terms , typical subjects ( e.g. person , individual , ... ) would be preferred ( to atypical subjects as suit _ of _ clothes ) as SRs on the subject in contrast to Assoc .
 The second advantage is that as long as the prior probabilities , , involve simpler events than those used in Assoc , , the estimation is easier and more accurate ( ameliorating data sparseness ) .
 In this section we propose the application of other measures apart from Assoc for learning SRs : log-likelihood ratio Dunning 1993 , relative entropy Cover and Thomas 1991 , mutual information ratio Church and Hanks 1990 , Gale and Church 1991 .
 The statistical measures used to detect associations on the distribution defined by two random variables X and Y work by measuring the deviation of the conditional distribution , , from the expected distribution if both variables were considered independent , i.e. the marginal distribution , .
 Besides the intrinsic difficulties of this approach , it does not seem appropriate when comparing across different techniques for learning SRs , because of its qualitative flavor .
