Combating Human Trafﬁcking with Deep Multimodal Models

Edmund Tong*

Language Technologies Institute

Carnegie Mellon University

7
1
0
2

 

y
a
M
8

 

 
 
]
L
C
.
s
c
[
 
 

1
v
5
3
7
2
0

.

5
0
7
1
:
v
i
X
r
a

edtong@cmu.edu

Cara Jones

Marinus Analytics, LLC

cara@marinusanalytics.com

Abstract

Human trafﬁcking is a global epidemic af-
fecting millions of people across the planet.
Sex trafﬁcking, the dominant form of hu-
man trafﬁcking, has seen a signiﬁcant rise
mostly due to the abundance of escort web-
sites, where human trafﬁckers can openly
advertise among at-will escort advertise-
ments.
In this paper, we take a major
step in the automatic detection of advertise-
ments suspected to pertain to human traf-
ﬁcking. We present a novel dataset called
Trafﬁcking-10k, with more than 10,000 ad-
vertisements annotated for this task. The
dataset contains two sources of informa-
tion per advertisement: text and images.
For the accurate detection of trafﬁcking ad-
vertisements, we designed and trained a
deep multimodal model called the Human
Trafﬁcking Deep Network (HTDN).

Introduction

1
Human trafﬁcking “a crime that shames us all”
(UNODC, 2008), has seen a steep rise in the United
States since 2012. The number of cases reported
rose from 3,279 in 2012 to 7,572 in 2016—more
than doubling over the course of ﬁve years (Hotline,
2017). Sex trafﬁcking is a form of human trafﬁck-
ing, and is a global epidemic affecting millions of
people each year (McCarthy, 2014). Victims of
sex trafﬁcking are subjected to coercion, force, and
control, and are not able to ask for help. Put plainly,
sex trafﬁcking is modern-day slavery and is one of
the top priorities of law enforcement agencies at all
levels.

A major advertising ground for human trafﬁckers
is the World Wide Web. The Internet has brought

* Authors contributed equally.

Amir Zadeh*

Language Technologies Institute

Carnegie Mellon University
abagherz@cs.cmu.edu

Louis-Philippe Morency

Language Technologies Institute

Carnegie Mellon University
morency@cs.cmu.edu

trafﬁckers the ability to advertise online and has
fostered the growth of numerous adult escort sites.
Each day, there are tens of thousands of Internet
advertisements posted in the United States and
Canada that market commercial sex. Hiding among
the noise of at-will adult escort ads are ads posted
by sex trafﬁckers. Often long undetected, trafﬁck-
ing rings and escort websites form a proﬁt cycle
that fuels the increase of both trafﬁcking rings and
escort websites.

For law enforcement, this presents a signiﬁcant
challenge: how should we identify advertisements
that are associated with sex trafﬁcking? Police
have limited human and technical resources, and
manually sifting through thousands of ads in the
hopes of ﬁnding something suspicious is a poor
use of those resources, even if they know what
they are looking for. Leveraging state-of-the-art
machine learning approaches in Natural Language
Processing and computer vision to detect and re-
port advertisements suspected of trafﬁcking is the
main focus of our work. In other words, we strive
to ﬁnd the victims and perpetrators of trafﬁcking
who hide in plain sight in the massive amounts
of data online. By narrowing down the number
of advertisements that law enforcement must sift
through, we endeavor to provide a real opportunity
for law enforcement to intervene in the lives of
victims. However, there are non-trivial challenges
facing this line of research:

Adversarial Environment. Human trafﬁcking
rings are aware that law enforcement monitors their
online activity. Over the years, law enforcement
ofﬁcers have populated lists of keywords that fre-
quently occur in trafﬁcking advertisements. How-
ever, these simplistic queries fail when trafﬁckers
use complex obfuscation. Trafﬁckers, again aware
of this, move to new keywords to blend in with the
at-will escort advertisements. This trend creates an
adversarial environment for any machine learning

system that attempts to ﬁnd trafﬁcking rings hiding
in plain sight.

Defective Language Compositionality. Online
escort advertisements are difﬁcult to analyze, be-
cause they lack grammatical structures such as
constituency. Therefore, any form of inference
must rely more on context than on grammar. This
presents a signiﬁcant challenge to the NLP commu-
nity. Furthermore, the majority of the ads contain
emojis and non-English characters.

Generalizable Language Context. Machine
learning techniques can easily learn unreliable cues
in training sets such as phone numbers, keywords,
and other forms of semantically unreliable discrim-
inators to reduce the training loss. Due to limited
similarity between the training and test data due to
the large number of ads available online, relying on
these cues is futile. Learned discriminative features
should be generalizable and model semantics of
trafﬁcking.

Multimodal Nature. Escort advertisements are
composed of both textual and visual information.
Our model should treat these features interdepen-
dently. For instance, if the text indicates that the
escort is in a hotel room, our model should con-
sider the effect that such knowledge may have on
the importance of certain visual features.

We believe that studying human trafﬁcking ad-
vertisements can be seen as a fundamental chal-
lenge to the NLP, computer vision, and machine
learning communities dealing with language and vi-
sion problems. In this paper, we present the follow-
ing contributions to this research direction. First,
we study the language and vision modalities of the
escort advertisements through deep neural model-
ing. Second, we take a signiﬁcant step in automatic
detection of advertisements suspected of sex traf-
ﬁcking. While previous methods (Dubrawski et al.,
2015) have used simplistic classiﬁers, we build an
end-to-end-trained multimodal deep model called
the Human Trafﬁcking Deep Network (HTDN).
The HTDN uses information from both text and
images to extract cues of human trafﬁcking, and
shows outstanding performance compared to pre-
viously used models. Third, we present the ﬁrst
rigorously annotated dataset for detection of human
trafﬁcking, called Trafﬁcking-10k, which includes
more than 10,000 trafﬁcking ads labeled with like-
lihoods of having been posted by trafﬁckers.1

1Due to the sensitive nature of this dataset, access can only
be granted by emailing Cara Jones. Different levels of access

2 Related Works

Automatic detection of human trafﬁcking has been
a relatively unexplored area of machine learning
research. Very few machine learning approaches
have been proposed to detect signs of human traf-
ﬁcking online. Most of these approaches use sim-
plistic methods such as multimedia matching (Zhou
et al., 2016), text-based ﬁltering classiﬁers such
as random forests, logistic regression, and SVMs
(Dubrawski et al., 2015), and named-entity recog-
nition to isolate the instances of trafﬁcking (Nagpal
et al., 2015). Studies have suggested using statis-
tical methods to ﬁnd keywords and signs of traf-
ﬁcking from data to help law enforcement agencies
(Kennedy, 2012) as well as adult content ﬁltering
using textual information (Zhou et al., 2016).

Multimodal approaches have gained popularity
over the past few years. These multimodal models
have been used for medical purposes, such as detec-
tion of suicidal risk, PTSD and depression (Scherer
et al., 2016; Venek et al., 2016; Yu et al., 2013; Val-
star et al., 2016); sentiment analysis (Zadeh et al.,
2016b; Poria et al., 2016; Zadeh et al., 2016a);
emotion recognition (Poria et al., 2017); image cap-
tioning and media description (You et al., 2016;
Donahue et al., 2015); question answering (Antol
et al., 2015); and multimodal translation (Specia
et al., 2016).

To the best of our knowledge, this paper presents
the ﬁrst multimodal and deep model for detection
of human trafﬁcking.

3 Trafﬁcking-10k Dataset

In this section, we present the dataset for our stud-
ies. We formalize the problem of recognizing sex
trafﬁcking as a machine learning task. The input
data is text and images; this is mapped to a measure
of how suspicious the advertisement is with regards
to human trafﬁcking.

3.1 Data Acquisition and Preprocessing
A subset of 10,000 ads were sampled randomly
from a large cache of escort ads for annotation in
Trafﬁcking-10k dataset. The distribution of adver-
tisements across the United States and Canada is
shown in Figure 1, which indicates the diversity of
advertisements in Trafﬁcking-10k. This diversity
ensures that models trained on Trafﬁcking-10k can
be applicable nationwide. The 10,000 collected ads

are provided only to scientiﬁc community.

Trafﬁcking-10k annotators have experience with
cases across the United States.

Annotators used an annotation interface speciﬁ-
cally designed for the Trafﬁcking-10k dataset. In
the annotation interface, each advertisement was
displayed on a separate webpage. The order of
the advertisements is determined uniformly ran-
domly, and annotators were unable to move to
the next advertisement without labeling the cur-
rent one. For each advertisement, the annotator
was presented with the question: “In your opin-
ion, would you consider this advertisement suspi-
cious of human trafﬁcking?” The annotator is pre-
sented with the following options: “Certainly no,”
“Likely no,” “Weakly no,” “Unsure,”2 “Weakly yes,”
“Likely yes,” and “Certainly yes.” Thus, the degree
to which advertisements are suspicious is quantized
into seven levels.

3.3 Analysis of Language
The language used in these advertisements intro-
duces fundamental challenges to the ﬁeld of NLP.
The nature of the textual content in these adver-
tisements raises the question of how we can make
inferences in a linguistic environment with a con-
stantly evolving lexicon. Language used in the
Trafﬁcking-10k dataset is highly inconsistent with
standard grammar. Often, words are obfuscated
by emojis and symbols. The word ordering is in-
consistent, and there is rarely any form of con-
stituency. This form of language is completely
different from spoken and written English. These
attributes make escort advertisements appear some-
what similar to tweets, speciﬁcally since these ads
are normally short (more than 90% of the ads have
at most 184 words). Another point of complex-
ity in these advertisements is the high number of
unigrams, due to usage of uncommon words and
obfuscation. On top of unigram complexity, ad-
vertisers continuously change their writing pattern,
making this problem more complex.

3.4 Dataset Statistics
There are 106,954 distinct unigrams, 353,324
distinct bigrams, and 565,403 trigrams in the
Trafﬁcking-10k dataset. There are 60,337 images.
The total number of distinct characters including
whitespace, punctuations, and hex characters is 182.
The average length of an ad is 137 words, with a

2This option is greyed out for 10 seconds to encourage

annotators to make an intuitive decision.

Figure 1: Distribution of advertisements in
Trafﬁcking-10k dataset across United States and
Canada.

each consist of text and zero or more images. The
text in the dataset is in plain text format, derived
by stripping the HTML tags from the raw source
of the ads. The set of characters in each advertise-
ment is encoded as UTF-8, because there is ample
usage of smilies and non-English characters. Ad-
vertisements are truncated to the ﬁrst 184 words, as
this covers more than 90% of the ads. Images are
resized to 224 × 224 pixels with RGB channels.
3.2 Trafﬁcking Annotation
Detecting whether or not an advertisement is suspi-
cious requires years of practice and experience in
working closely with law enforcement. As a result,
annotation is a highly complicated and expensive
process, which cannot be scaled using crowdsourc-
ing. In our dataset, annotation is carried out by two
expert annotators, each with at least ﬁve years of
experience, in detection of human trafﬁcking and
another annotator with one year of experience. In
our dataset, annotations were done by three experts.
One expert has over a year of experience, and the
other two have over ﬁve years of experience in the
human trafﬁcking domain. To calculate the inter-
annotator agreement, each annotator is given the
same set of 1000 ads to annotate and the nomi-
nal agreement is found: there was a 83% pairwise
agreement (0.62 Krippendorff’s alpha). Also, to
make sure that annotations are generalizable across
the annotators and law enforcement ofﬁcers, two
law enforcement ofﬁcers annotated, respectively, a
subset of 500 and 100 of the advertisements. We
found a 62% average pairwise agreement (0.42
Krippendorff’s alpha) with our annotators. This
gap is reasonable, as law enforcement ofﬁcers only
have experience with local advertisements, while

Advertisement lengths

Positive
Negative

1,500

1,000

500

0

0

40

80

120 160 200

+

Number of unigrams

Figure 2: Distribution of the length of advertise-
ments in Trafﬁcking-10k. There is no signiﬁcant
difference between positive and negative cases
purely based on length.

standard deviation of 74, median 133. The short-
est advertisement has 7 unigrams, and the longest
advertisement has 1810 unigrams. There are of
106,954 distinct unigrams, 353,324 distinct bi-
grams and 565,403 trigrams in the Trafﬁcking-10k
dataset. The average number of images in an ad-
vertisement is 5.9; the median is 5, the minimum
is 0, and the maximum is 90.

The length of suspected advertisements is 134
unigrams; the standard deviation is 39, the mini-
mum is 12, and the maximum is 666. The length
of non-suspected ads is 141; the standard deviation
is 85, the minimum is 7, and the maximum is 1810.
The total number of suspected ads is 3257; and the
total number of non-suspected ads is 6992. Fig-
ure 2 shows the histogram of number of ads based
on their length. Both the positive and negative dis-
tributions are similar. This means that there is no
obvious length difference between the two classes.
Most of the ads have a length of 80–180 words.

4 Model
In this section, we present our deep multimodal net-
work called the Human Trafﬁcking Deep Network
(HTDN). The HTDN is a multimodal network with
language and vision components. The input to the
HTDN is an ad, text and images. The HTDN is
shown in Figure 3. In the remainder of this section,
we will outline the different parts of the HTDN,
and the input features to each component.

4.1 Trafﬁcking Word Embeddings
Our approach to deal with the adversarial environ-
ment of escort ads is to use word vectors, deﬁning

words not based on their constituent characters, but
rather based on their context. For instance, consider
the two unigrams “cash” and “©a$h.” While these
contain different characters, semantically they are
the same, and they occur in the same context. Thus,
our expectation is that both the unigrams will be
mapped to similar vectors. Word embeddings pre-
trained on general domains do not cover most of
the unigrams in Trafﬁcking-10k. For instance,
the GloVe embedding (Pennington et al., 2014)
trained on Wikipedia covers only 49.7% of our
unigrams. The ﬁrst step of the HTDN pipeline
is to train word vectors (Mikolov et al., 2013)
based on the skip-gram model. This is especially
suitable for escort ads, because skip-gram mod-
els are able to capture context without relying on
word order. We train the word embedding using
1,000,000 unlabeled ads from a dataset that does
not include the Trafﬁcking-10k data. For each ad-
vertisement, the input to the trained embedding is a
sequence of words ˆw = [ ˆw1, . . . , ˆwt], and the out-
put is a sequence of 100-dimensional word vectors
w = [w1, . . . , wt], where t is the size of the adver-
tisement and wi ∈ R100. Our trained word vectors
cover 94.9% of the unigrams in the Trafﬁcking-10k
dataset.

4.2 Language Network

Our language network is designed to deal with
two challenging aspects of escort advertisements:
(1) violation of constituency, and (2) presence of
irrelevant information not related to trafﬁcking but
present in ads. We address both of these issues
by learning a time dependent embedding at word
level. This allows the model to not rely on con-
stituency and also remember useful information
from the past, should the model get overwhelmed
by irrelevant information. Our proposed language
network, Fl, takes as input a sequence of word
vectors w = [w1, . . . , wt], and outputs a neural
language representation hl. As a ﬁrst step, Fl uses
the word embeddings as input to a Long-Short
Term Memory (LSTM) network and produces a
new supervised context-aware word embedding
u = [u1, . . . , ut] where ui ∈ R300 is the output
of the LSTM at time i. Then, u is fed into a fully
connected layer with dropout p = 0.5 to produce
the neural language representation hl ∈ R300 ac-
cording to the following formulas with weights
Wl for the LSTM and implicit weights in the fully

Figure 3: Overview of our proposed Human Trafﬁcking Deep Network (HTDN). The input to HTDN is text
and a set of 5 images. The text goes through the Language Network Fl to get the language representation
hl and the set of 5 images go through the Vision Network Fv to get the visual representation hv. hl and hv
are then fused together to get the multimodal representation hm. The Convolutional Decision Network Fd
conditioned on the hm makes inference about whether or not the advertisement is suspected of trafﬁcking

connected layers, which we represent by FC :

ui = LSTM (i, wi; Wl)
u = [u1, . . . , ut]
hl = FC (u).

(1)
(2)
(3)

The generated hl is then used as part of the HTDN
pipeline, and is also trained independently to as-
sess the performance of the language-only model.
The language network Fl is the combination of the
LSTM and the fully-connected network.

4.3 Vision Network
Parallel to the language network, the vision net-
work Fv takes as input advertisement images and
extracts visual representations hv. The vision net-
work takes at most ﬁve images; the median num-
ber of images per advertisement in Trafﬁcking-10k
is 5. To learn contextual and abstract information
from images, we use a deep convolutional neural
network called Trafﬁcking-VGG (T-VGG), a ﬁne-
tuned instance of the well-known VGG network
(Simonyan and Zisserman, 2014). T-VGG is a deep
model with 13 consecutive convolutional layers fol-
lowed by 2 fully connected layers; it does not in-
clude the softmax layer of VGG. The procedure for
ﬁne-tuning T-VGG maps each individual image to
a label that comes from the advertisement, and then
performs end-to-end training. For example, if there
are ﬁve images in an advertisement with positive

label, all ﬁve images are mapped to positive label.
After ﬁne-tuning, three fully connected layers of
200 neurons with dropout p = 0.5 are added to
the network. The combination of T-VGG and the
fully connected layers is the vision network Fl. We
consider ﬁve images ˆı = {ˆı1, . . . , ˆı5} from each
input advertisement. If the advertisement has fewer
than ﬁve images, zero-ﬁlled images are added. For
each image, the output of Fv is a representation
of ﬁve images i = {i1, . . . , i5}. The visual repre-
sentation hv ∈ R5×200 is a matrix with a size-200
representation of each of the 5 images:

hv = Fv(ˆı; Wv).

(4)

4.4 Multimodal Fusion
Escort advertisements have complex dynamics be-
tween text and images. Often, neither linguistic nor
visual cues alone can sufﬁce to classify whether
an ad is suspicious. Interactions between linguistic
and visual cues can be non-trivial, so this requires
an explicit joint representation for each neuron in
the linguistic and visual representations. In our
multimodal fusion approach we address this by cal-
culating an outer product between language and
visual representations hl and hv to build the full
space of possible outcomes:

(5)
where ⊗ is an outer product of the two representa-
tions. This creates a joint multimodal tensor called

hm = hl ⊗ hv,

LanguageNetworkFld0ll@rto...gr8skype···LSTM···LSTM···LSTM···LSTMhl∈R300Traﬃckingembedding.........300σVisualNetworkFvˆı1ˆı2ˆı3ˆı4ˆı5TraﬃckingVGG.........200σ200σ200σhv∈R5×200ConvolutionalDecisionNetworkFdconvhm∈R5×200×300⊗5×200×300maxpoolingconv5×100×150maxpooling150linear...P[τ|hm;Wd]σFigure 4: 2D t-SNE representation of different input features for baseline models. Clockwise from top left:
one hot vectors with expert data, one hot vectors without expert data, visual features from Vision Network
Fv, and average word vectors. These representations show that inference is not trivial in Trafﬁcking-10k
dataset.

hm for language and visual modalities. In this ten-
sor, every neuron in the language representation
is multiplied by every neuron in vision representa-
tion, thus creating a new representation containing
the information of both of them. Thus, the ﬁnal
fusion tensor hm ∈ R5×200×300 contains informa-
tion from the joint interaction of the language and
visual modalities.

4.5 Convolutional Decision Network
The multimodal representation hm is used as the
input to the convolutional decision network Fd. Fd
has two layers of convolution and max pooling with
a dropout rate of p = 0.5, followed by a fully con-
nected layer of 150 neurons with a dropout rate of
p = 0.5. Performing convolutions in this space en-
ables the model to attend to small areas of linguistic
and visual cues. It can thus ﬁnd correspondences
between speciﬁc combinations of the linguistic and
visual representations. The ﬁnal decision is made

by a single sigmoid neuron.

5 Experiments
In our experiments, we compare the HTDN with
previously used approaches for detection of traf-
ﬁcking suspicious ads. Furthermore, we compare
the HTDN to the performance of its unimodal com-
ponents. In all our experiments we perform binary
classiﬁcation of whether the advertisement is sus-
pected of being related to trafﬁcking. The main
comparison method that we use is the weighted ac-
curacy and F1-score (due to imbalance it dataset).
The formulation for weighted accuracy is as fol-
lows:

Wt. Acc. =

TP × N/P + TN

2N

(6)

where TP (resp. TN) is true positive (resp. true
negative) predictions, and P (resp. N) is the total
number of positive (resp. negative) examples.

Model
Random
Keywords

Wt. Acc. (%) F1 (%) Acc. (%) Precision (%) Recall (%)
-

50.0

68.2

-

-

Random Forest
Logistic Regression
Linear SVM

Average Trafﬁcking Vectors

Random Forest
Logistic Regression
Linear SVM
108 One-Hot

Random Forest
Logistic Regression
Linear SVM
Bag of Words

Random Forest
Logistic Regression
Linear SVM

HTDN Unimodal

Fl
Fv [VGG]
Fv [T-VGG]

HTDN
Human

67.0
69.9
69.5

67.3
72.2
70.3

62.4
62.5
61.7

57.6
71.1
71.2

74.5
69.1
70.4
75.3
83.7

55.2
57.8
57.0

54.1
61.7
57.7

60.7
45.1
45.1

24.5
24.5
24.5

65.8
58.4
59.5
66.5
73.7

78.1
78.4
78.6

78.0
80.2
79.2

72.6
72.2
71.8

70.4
70.4
70.4

78.8
74.2
77.3
80.0
84.0

78.2
75.5
78.0

79.3
79.2
80.7

61.5
60.0
58.6

63.2
63.2
63.2

69.8
66.7
78.3
71.4
76.7

42.6
46.8
44.9

41.1
50.6
44.9

60.0
36.1
36.7

15.2
15.2
15.2

62.3
52.0
48.0
62.2
70.9

Table 1: Results of our experiments. We compare our HTDN model to various baselines using different
inputs. HTDN ourperforms other baselines in both weighted accuracy and F-score.

5.1 Baselines
We compare the performance of the HTDN network
with baseline models divided in 4 major categories
Bag-of-Words Baselines. This set of baselines
is designed to assess performance of off-the-shelf
basic classiﬁers and basic language features. We
train random forest, logistic regression and linear
SVMs to show the performance of simple language-
only models.

Keyword Baselines. These demonstrate the per-
formance of models that use a set of 108 keywords,
all highly related to trafﬁcking, provided by law
enforcement ofﬁcers.3 A binary one-hot vector
representing these keywords is used to train the
random forest, logistic regression, and linear SVM
models.

108 One-Hot Baselines. Similar to Keywords
Baseline, we use feature selection technique to ﬁl-

3Not presented in this paper due to sensitive nature of these

keywords.

ter the most informative 108 words for detection
of trafﬁcking. We compare the performance of this
baseline to Keywords baseline to evaluate the use-
fulness of expert knowledge in keywords selection
vs automatic data-driven keyword selection.

Average Trafﬁcking Vectors Baselines. We as-
sess the magnitude of success for the trafﬁcking
word embeddings for different classiﬁers. For the
random forest, logistic regression, and linear SVM
models, the average word vector is calculated and
used as input.

HTDN Unimodal. These baselines show the
performance of unimodal components of HTDN.
For language we only use Fl component of the
pipeline and for visual we use Fv, using both pre-
trained a VGG and ﬁnetuned T-VGG.
Random and Human. Random is based on as-
signing the more frequent class in training set to all
the test data, and can be considered a lower bound
for our model. Human performance metrics are

upper bounds for this task’s metrics.

We visualize the different inputs to our baseline
models to show the complexity of the dataset when
using different feature sets. Figure 4 shows the 2D
t-SNE (Maaten and Hinton, 2008) representation
of the training data in our dataset according to the
Bag-of-Words (top right) models, expert keywords
(top left), average word vectors (bottom right), and
the visual representation hv bottom left. The distri-
bution of points suggests that none of the feature
representations make the classiﬁcation task trivial.

5.2 Training Parameters

All the models in our experiments are trained on the
Trafﬁcking-10k designated training set and tested
on the designated test set. Hyperparameter eval-
uation is performed using a subset of training set
as validation set. The HTDN model is trained us-
ing the Adam optimizer (Kingma and Ba, 2014).
The neural weights were initialized randomly using
Xavier initialization technique (Glorot and Bengio,
2010). The random forest model uses 10 estimators,
with no maximum depth, and minimum-samples-
per-split value of 2. The linear SVM model uses
an (cid:96)2-penalty and a square hinge loss with C = 1.

6 Results and Discussion

The results of our experiments are shown in Table 1.
We report the results on three metrics: F1-score,
weighted accuracy, and accuracy. Due to the imbal-
ance between the numbers of positive and negative
samples, weighted accuracy is more informative
than unweighted accuracy, so we focus on the for-
mer.

HTDN. The ﬁrst observation from Table 1 is
that the HTDN model outperforms all the pro-
posed baselines. There is a signiﬁcant gap between
the HTDN (and variants) and other non-neural ap-
proaches. This better performance is an indicator
of complex interactions in detecting dynamics of
human trafﬁcking, which is captured by the HTDN.
Both Modalities are Helpful. Both modalities
are helpful in predicting signs of trafﬁcking (Fl and
Fv [T-VGG]). Fine-tuning VGG network param-
eters shows improvement over pre-trained VGG
parameters.
Language is More Important. Since Fl shows
better performance than Fv [T-VGG], the language
modality appears to be the more informative modal-
ity for detecting trafﬁcking suspicious ads.

7 Conclusion and Future Work

In this paper, we took a major step in multimodal
modeling of suspected online trafﬁcking advertise-
ments. We presented a novel dataset, Trafﬁcking-
10k, with more than 10,000 advertisements anno-
tated for this task. The dataset contains two modal-
ities of information per advertisement: text and im-
ages. We designed a deep multimodal model called
the Human Trafﬁcking Deep Network (HTDN). We
compared the performance of the HTDN to various
models that use language and vision alone. The
HTDN outperformed all of these, indicating that
using information from both sources may be more
helpful than using just one.

Exploring language through character mod-
eling. In order to eliminate the need for retraining
the word vectors as the language of the domain
evolves, we plan to use character models to learn
a better language model for trafﬁcking. As new
obfuscated words are introduced in escort adver-
tisements, our hope is that character models will
stay invariant to these obfuscations.

Understanding images. While CNNs have
proven to be useful for many different computer
vision tasks, we seek to improve the learning ca-
pability of the visual network. Future direction
involves using graphical modeling to understand in-
teractions in the scene. Another direction involves
working to understand text in images, which can
provide more information about the subjects of the
images.

Given that the current state of the art in this area
generally does not use deep models, this may be a
major opportunity for improvement. To this end,
we encourage the research community to reach out
to Cara Jones, an author of this paper, to obtain a
copy of Trafﬁcking-10k and other training data.

Acknowledgements

We would like to thank William Chargin for creat-
ing ﬁgures and revising this paper. We would also
like to thank Torsten W¨ortwein for his assistance in
visualizing our data. Furthermore, we would like to
thank our anonymous reviewers for their valuable
feedback. Finally, we would like to acknowledge
collaborators from Marinus Analytics for the time
and effort that they put into annotating advertise-
ments for the dataset, and for allowing us to use
their advertisement data.

References
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-
garet Mitchell, Dhruv Batra, C Lawrence Zitnick,
and Devi Parikh. 2015. Vqa: Visual question an-
swering. In Proceedings of the IEEE International
Conference on Computer Vision. pages 2425–2433.

Jeffrey Donahue, Lisa Anne Hendricks, Sergio Guadar-
rama, Marcus Rohrbach, Subhashini Venugopalan,
Kate Saenko, and Trevor Darrell. 2015. Long-term
recurrent convolutional networks for visual recogni-
In Proceedings of the IEEE
tion and description.
conference on computer vision and pattern recogni-
tion. pages 2625–2634.

Artur Dubrawski, Kyle Miller, Matthew Barnes,
Benedikt Boecking, and Emily Kennedy. 2015.
Leveraging publicly available data to discern pat-
terns of human-trafﬁcking activity. Journal of Hu-
man Trafﬁcking 1(1):65–85.

Xavier Glorot and Yoshua Bengio. 2010. Understand-
ing the difﬁculty of training deep feedforward neural
networks. In Aistats. volume 9, pages 249–256.

National Human Trafﬁcking Hotline. 2017. Hotline
statistics. https://humantrafﬁckinghotline.org/states.

Emily Kennedy. 2012. Predictive patterns of sex traf-

ﬁcking online. Dietrich College Honors Theses .

Diederik Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980 .

Laurens van der Maaten and Geoffrey Hinton. 2008.
Visualizing data using t-sne. Journal of Machine
Learning Research 9(Nov):2579–2605.

Lauren A McCarthy. 2014. Human trafﬁcking and the
new slavery. Annual Review of Law and Social Sci-
ence 10:221–242.

Soujanya Poria, Iti Chaturvedi, Erik Cambria, and
Amir Hussain. 2016. Convolutional mkl based mul-
timodal emotion recognition and sentiment analy-
sis. In 2016 IEEE 16th International Conference on
Data Mining (ICDM). IEEE, pages 439–448.

Stefan Scherer, Gale M Lucas, Jonathan Gratch, Al-
bert Skip Rizzo, and Louis-Philippe Morency. 2016.
Self-reported symptoms of depression and ptsd are
associated with reduced vowel space in screening in-
IEEE Transactions on Affective Comput-
terviews.
ing 7(1):59–73.

Karen Simonyan and Andrew Zisserman. 2014. Very
deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556 .

Lucia Specia, Stella Frank, Khalil Sima’an, and
Desmond Elliott. 2016. A shared task on multi-
modal machine translation and crosslingual image
description. In Proceedings of the First Conference
on Machine Translation, Berlin, Germany. Associa-
tion for Computational Linguistics.

UNODC.

2008.
overview.

trafﬁcking:
An
York.
http://www.ungift.org/doc/knowledgehub/resource-
centre/GIFT˙Human˙Trafﬁcking˙An˙Overview˙2008.pdf.

Human
Web,

New

Michel Valstar, Jonathan Gratch, Bj¨orn Schuller, Fa-
bien Ringeval, Dennis Lalanne, Mercedes Tor-
res Torres, Stefan Scherer, Giota Stratou, Roddy
Cowie, and Maja Pantic. 2016. Avec 2016: De-
pression, mood, and emotion recognition workshop
In Proceedings of the 6th Inter-
and challenge.
national Workshop on Audio/Visual Emotion Chal-
lenge. ACM, pages 3–10.

Verena Venek, Stefan Scherer, Louis-Philippe Morency,
Albert Rizzo, and John Pestian. 2016. Adolescent
suicidal risk assessment in clinician-patient interac-
tion. IEEE Transactions on Affective Computing .

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
In Advances in neural information processing
ity.
systems. pages 3111–3119.

Quanzeng You, Hailin Jin, Zhaowen Wang, Chen Fang,
and Jiebo Luo. 2016. Image captioning with seman-
tic attention. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition. pages
4651–4659.

Chirag Nagpal, Kyle Miller, Benedikt Boecking, and
Artur Dubrawski. 2015. An entity resolution ap-
proach to isolate instances of human trafﬁcking on-
line. arXiv preprint arXiv:1509.06659 .

Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. GloVe: Global vectors for word
representation. In EMNLP. volume 14, pages 1532–
1543.

Soujanya Poria, Erik Cambria, Rajiv Bajpai, and Amir
Hussain. 2017. A review of affective computing:
In-
From unimodal analysis to multimodal fusion.
formation Fusion 1:34.

Zhou Yu, Stefen Scherer, David Devault, Jonathan
Gratch, Giota Stratou, Louis-Philippe Morency, and
Justine Cassell. 2013. Multimodal prediction of psy-
chological disorders: Learning verbal and nonverbal
commonalities in adjacency pairs. In Semdial 2013
DialDam: Proceedings of the 17th Workshop on the
Semantics and Pragmatics of Dialogue. pages 160–
169.

Amir Zadeh, Rowan Zellers, Eli Pincus, and Louis-
Philippe Morency. 2016a. Mosi: Multimodal cor-
intensity and subjectivity anal-
pus of sentiment
arXiv preprint
ysis in online opinion videos.
arXiv:1606.06259 .

Amir Zadeh, Rowan Zellers, Eli Pincus, and Louis-
Philippe Morency. 2016b. Multimodal sentiment in-
tensity analysis in videos: Facial gestures and verbal
messages. IEEE Intelligent Systems 31(6):82–88.

Andrew Jie Zhou, Jiyun Luo, and Lewis John McGibb-
ney. 2016. Multimedia metadata-based forensics
in human trafﬁcking web data. Vanessa Murdock,
Charles LA Clarke, Jaap page 10.

