 PROBABILISTIC INTEGRATION OF STRUCTURED DATA A key idea of folksonomy learning through sapling inte- gration is to merge similar nodes from di erent saplings.
 Merging similar root nodes expands the width of the learned tree, while merging the leaf of one sapling to the root of another extends its depth.
 The merging process has two key sub-components: (1) a similarity function that evaluates how similar a pair of nodes is; (2) a pro- cedure that decides if two nodes should or should not be merged, based on their similarity.
 For the leaf-to-leaf similarity on a pair of leaf nodes, we can only consider the cluster label of their roots rather than all of their siblings.
 The con guration shown in the gure is valid since both C and D belong to the same exemplar E and their parents, A and B, belong to the same exemplar A.
 However, if cBB = 1, then the con guration is invalid, because parents of nodes in the cluster of exemplar E will belong to di erent exemplars (A and B).
 We then used the leaf node names of these saplings to identify other saplings whose root names were similar to these names, and so on, for two iterations.
 To compare the di erent strategies for exploiting struc- tural information, we apply the two clustering proce- dures, AP and RAP, with di erent similarity functions, to these data sets.
 We used the following similarity func- tions: (1) local : only local similarity; and (2) hybrid : local and structural similarity; and (3) class-hybrid : lo- cal and structural similarity using class labels.
 To make this work comparable to [17], we used the following pa- rameter values in the similarity functions: in local simi- larity Eq. 3, we set the number of top tags K = 40, and the number of common tags J = 4; in the hybrid sim- ilarity function, the weight combination between local and structural similarity is = 0.9 when comparing two nodes that are both roots or leaves, and = 0.2 when one node is a root and the other a leaf.
