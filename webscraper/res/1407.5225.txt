 Sophisticated bots can generate personas that appear as credible followers, and thus are harder for both people and ltering algorithms to detect.
 In addition to potentially endanger- ing democracy, causing panic during emergencies, and affecting the stock market, so- cial bots can harm our society in even subtler ways.
 A recent study demonstrated the vulnerability of social media users to a social botnet designed to expose private infor- mation, like phone numbers and addresses [Boshmaf et al. 2013].
 This kind of vul- nerability can be exploited by cybercrime and cause the erosion of trust in social me- dia [Hwang et al. 2012].
 A taxonomy of social bot detection systems For all the reasons outlined above, the computing community is engaging in the design of advanced methods to automatically detect social bots, or to discriminate between humans and bots.
 Graph-based social bot detection The challenge of social bot detection has been framed by various teams in an adver- sarial setting [Alvisi et al. 2013].
 Souche [Xie et al. 2012] and Anti- Reconnaissance [Paradise et al. 2014] also rely on the assumption that social network structure alone separates legitimate users from bots.
 This brought Alvisi et al. to recommend a portfolio of complementary detection techniques, and the manual identi cation of le- gitimate social network users to aid in the training of supervised learning algorithms.
 Combining multiple approaches Alvisi et al. [Alvisi et al. 2013] recognized rst the need of adopting complementary detection techniques to effectively deal with sybil attacks in social networks.
 In some ways, the Renren approach [Wang et al. 2013a; Yang et al. 2014] combines the best of network- and behavior-based con- ceptualizations of Sybil detection.
