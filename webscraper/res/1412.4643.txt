 The problem is made worse, not better, in the big data era despite and even because of the fact that our algorithms have access to increasingly relevant information.
 Meanwhile, advances in machine learning generally amount to discovering particularly fertile ways to constrain the space of rules the machine has to search, or in nding new and faster methods for searching it.
 It is that the way these algorithms work precludes their analysis in the very human ways we have learned to judge and reason about what is, and is not, just, reasonable, and good. 4 Algorithmic Solutions We nd ourselves in a quandary.
 They work by nding patterns in past data, and using the relative strengths of these patterns to classify new data of unknown type.
 The causal networks of Judea Pearl can be read by a human, and in a logically consistent fashion, their causal language can be used in moral explanations.
 But it does not yet play a role in many of the machine-learning algorithms, such as deep learning or random forests, in widespread use for monitoring and prediction today.
 One day, a framework such as this could provide a moral schematic for new algorithms, making it possible for researchers, policy makers, and citizens to reason ethically about their use.
 The method we propose post-processes and cleans prediction outputs so that we eliminate the possibility that the output of an algorithm correlates with a protected category.
 The same methods we use to study new tools for computer-aided prediction may change our views on rules we have used in the past.
 The very nature of big data blurs the boundary between inference to the best solution and ethical constraints on uses of that inference.
