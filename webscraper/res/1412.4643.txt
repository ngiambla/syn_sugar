 The problem is made worse, not better, in the big data era despite and even because of the fact that our algorithms have access to increasingly relevant information.
 They may not reveal, say, which features of a mortgage applicant s le combined to- gether to lead a bank s algorithm to offer or deny a loan.
 Nor do they provide an account of how the individual in question might have come to have those properties, or why those features and not others were chosen to begin with.
 Human-readable accounts of why someone failed to meet the bar for a scholarship, triggered a stop and frisk, or was awarded a government contract are the bread and butter for ethical debates on policy.
 In doing so, we lose out on many of the potential bene ts that these new algorithms promise: more ef cient use of resources, better aid to our fellow citizens, and new opportunities for human ourishing.
 Or, we can reject this earlier squaring of moral and technocratic goals, accept that machine-aided decision-making will lead to discrimination, and enter a new era of euphemisms, playing a game, at best, of catch as catch can, and banning the use of these methods when problems become apparent.
 They work by nding patterns in past data, and using the relative strengths of these patterns to classify new data of unknown type.
 Deep learning combines these two steps, simultaneously learning patterns and how they combine to produce the property of interest. 6 decision-making problem, it could highlight the relevant categories, and whether they made a positive or negative contribution to the nal choice.
 But it does not yet play a role in many of the machine-learning algorithms, such as deep learning or random forests, in widespread use for monitoring and prediction today.
 The machines that implement these algorithms increasingly become extensions of our will [18], giving us the ability to infer the outcomes of thought experiments, ll in missing knowledge, and predict the future with an unexpected accuracy.
