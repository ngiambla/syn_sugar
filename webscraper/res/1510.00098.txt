 We train a fully convolutional CNN model to predict nighttime lights from daytime imagery, simultaneously learning features that are use- ful for poverty prediction.
 We overcome this lack of training data by using a se- quence of transfer learning steps and a convolutional neu- ral network model.
 Speci cally, we start with a CNN model pre-trained for object classi ca- tion on ImageNet and learn a modi ed network that pre- dicts nighttime light intensities from daytime imagery.
 We show that transfer learning succeeds in learning features rel- evant not only for nighttime light prediction but also for poverty mapping.
 The output dimensions h and w depend on the stride and zero-padding parameters of the layer, which control how the convolutional lters slide across the input.
 The VGG model parameters are obtained from the Caffe Model Zoo, and all networks are trained with Caffe (Jia et al. 2014).
 The goal is to learn high-level features that are indicative of economic development and can be used for poverty mapping in the spirit of transfer learning.
 Figure 5: A set of 25 maximally activating images and their corresponding activation maps for a lter in the fth convolutional layer of the network trained on the 3-class nighttime light intensity prediction task.
 Figure 6: A set of 25 maximally activating images and their corresponding activation maps for a lter in the fth convolutional layer of the network trained on the 3-class nighttime light intensity prediction task.
 This lter seems to activate for water, barren, and forested lands, which this lter seems to group together as contributing similarly to nighttime light intensity.
