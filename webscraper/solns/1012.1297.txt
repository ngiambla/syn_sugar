in this note, we propose to use sparse methods (e.g. lasso, post-lasso,sqrt-lasso, and post-sqrt-lasso) to form first-stage predictions and estimateoptimal instruments in linear instrumental variables (iv) models with manyinstruments in the canonical gaussian case. the methods apply even when thenumber of instruments is much larger than the sample size. we derive asymptoticdistributions for the resulting iv estimators and provide conditions underwhich these sparsity-based iv estimators are asymptotically oracle-efficient.in simulation experiments, a sparsity-based iv estimator with a data-drivenpenalty performs well compared to recently advocated many-instrument-robustprocedures. we illustrate the procedure in an empirical example using theangrist and krueger (1991) schooling data.