  almost all research work in computational neuroscience involves software. as
researchers try to understand ever more complex systems, there is a continual
need for software with new capabilities. because of the wide range of questions
being investigated, new software is often developed rapidly by individuals or
small groups. in these cases, it can be hard to demonstrate that the software
gives the right results. software developers are often open about the code they
produce and willing to share it, but there is little appreciation among
potential users of the great diversity of software development practices and
end results, and how this affects the suitability of software tools for use in
research projects. to help clarify these issues, we have reviewed a range of
software tools and asked how the culture and practice of software development
affects their validity and trustworthiness. we identified four key questions
that can be used to categorize software projects and correlate them with the
type of product that results. the first question addresses what is being
produced. the other three concern why, how, and by whom the work is done. the
answers to these questions show strong correlations with the nature of the
software being produced, and its suitability for particular purposes. based on
our findings, we suggest ways in which current software development practice in
computational neuroscience can be improved and propose checklists to help
developers, reviewers and scientists to assess the quality whether particular
pieces of software are ready for use in research.
