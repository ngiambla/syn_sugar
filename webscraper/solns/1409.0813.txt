  relentless progress in artificial intelligence (ai) is increasingly raising
concerns that machines will replace humans on the job market, and perhaps
altogether. eliezer yudkowski and others have explored the possibility that a
promising future for humankind could be guaranteed by a superintelligent
"friendly ai", designed to safeguard humanity and its values. i argue that,
from a physics perspective where everything is simply an arrangement of
elementary particles, this might be even harder than it appears. indeed, it may
require thinking rigorously about the meaning of life: what is "meaning" in a
particle arrangement? what is "life"? what is the ultimate ethical imperative,
i.e., how should we strive to rearrange the particles of our universe and shape
its future? if we fail to answer the last question rigorously, this future is
unlikely to contain humans.
