  many real incidents demonstrate that users of online social networks need
mechanisms that help them manage their interactions by increasing the awareness
of the different contexts that coexist in online social networks and preventing
them from exchanging inappropriate information in those contexts or
disseminating sensitive information from some contexts to others. contextual
integrity is a privacy theory that conceptualises the appropriateness of
information sharing based on the contexts in which this information is to be
shared. computational models of contextual integrity assume the existence of
well-defined contexts, in which individuals enact pre-defined roles and
information sharing is governed by an explicit set of norms. however, contexts
in online social networks are known to be implicit, unknown a priori and ever
changing; users relationships are constantly evolving; and the information
sharing norms are implicit. this makes current contextual integrity models not
suitable for online social networks.
  in this paper, we propose the first computational model of implicit
contextual integrity, presenting an information model and an information
assistant agent that uses the information model to learn implicit contexts,
relationships and the information sharing norms to help users avoid
inappropriate information exchanges and undesired information disseminations.
through an experimental evaluation, we validate the properties of information
assistant agents, which are shown to: infer the information sharing norms even
if a small proportion of the users follow the norms and in presence of
malicious users; help reduce the exchange of inappropriate information and the
dissemination of sensitive information with only a partial view of the system
and the information received and sent by their users; and minimise the burden
to the users in terms of raising unnecessary alerts.
