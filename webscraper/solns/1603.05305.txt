principal component analysis (pca) has been a prominent tool forhigh-dimensional data analysis. online algorithms that estimate the principalcomponent by processing streaming data are of tremendous practical andtheoretical interests. despite its rich applications, theoretical convergenceanalysis remains largely open. in this paper, we cast online pca into astochastic nonconvex optimization problem, and we analyze the online pcaalgorithm as a stochastic approximation iteration. the stochastic approximationiteration processes data points incrementally and maintains a running estimateof the principal component. we prove for the first time a nearly optimalfinite-sample error bound for the online pca algorithm. under the subgaussianassumption, we show that the finite-sample error bound closely matches theminimax information lower bound.