  identifying and communicating relationships between causes and effects is
important for understanding our world, but is affected by language structure,
cognitive and emotional biases, and the properties of the communication medium.
despite the increasing importance of social media, much remains unknown about
causal statements made online. to study real-world causal attribution, we
extract a large-scale corpus of causal statements made on the twitter social
network platform as well as a comparable random control corpus. we compare
causal and control statements using statistical language and sentiment analysis
tools. we find that causal statements have a number of significant lexical and
grammatical differences compared with controls and tend to be more negative in
sentiment than controls. causal statements made online tend to focus on news
and current events, medicine and health, or interpersonal relationships, as
shown by topic models. by quantifying the features and potential biases of
causality communication, this study improves our understanding of the accuracy
of information and opinions found online.
