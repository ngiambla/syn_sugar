we introduce the notion of information ratio $\text{ir}(h/g)$ between two(simple, undirected) graphs $g$ and $h$, defined as the supremum of ratios$k/n$ such that there exists a mapping between the strong products $g^k$ to$h^n$ that preserves non-adjacency. operationally speaking, the informationratio is the maximal number of source symbols per channel use that can bereliably sent over a channel with a confusion graph $h$, where reliability ismeasured w.r.t. a source confusion graph $g$. various results are provided,including in particular lower and upper bounds on $\text{ir}(h/g)$ in terms ofdifferent graph properties, inequalities and identities for behavior understrong product and disjoint union, relations to graph cores, and notions ofgraph criticality. informally speaking, $\text{ir}(h/g)$ can be interpreted asa measure of similarity between $g$ and $h$. we make this notion precise byintroducing the concept of information equivalence between graphs, a morequantitative version of homomorphic equivalence. we then describe a naturalpartial ordering over the space of information equivalence classes, and endowit with a suitable metric structure that is contractive under the strongproduct. various examples and open problems are discussed.