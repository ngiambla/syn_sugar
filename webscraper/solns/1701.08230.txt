  algorithms are now regularly used to decide whether defendants awaiting trial
are too dangerous to be released back into the community. in some cases, black
defendants are substantially more likely than white defendants to be
incorrectly classified as high risk. to mitigate such disparities, several
techniques recently have been proposed to achieve algorithmic fairness. here we
reformulate algorithmic fairness as constrained optimization: the objective is
to maximize public safety while satisfying formal fairness constraints designed
to reduce racial disparities. we show that for several past definitions of
fairness, the optimal algorithms that result require detaining defendants above
race-specific risk thresholds. we further show that the optimal unconstrained
algorithm requires applying a single, uniform threshold to all defendants. the
unconstrained algorithm thus maximizes public safety while also satisfying one
important understanding of equality: that all individuals are held to the same
standard, irrespective of race. because the optimal constrained and
unconstrained algorithms generally differ, there is tension between improving
public safety and satisfying prevailing notions of algorithmic fairness. by
examining data from broward county, florida, we show that this trade-off can be
large in practice. we focus on algorithms for pretrial release decisions, but
the principles we discuss apply to other domains, and also to human decision
makers carrying out structured decision rules.
