we introduce a reformulation of regularized low-rank recovery models to takeadvantage of gpu, multiple cpu, and hybridized architectures. low-rank recoveryoften involves nuclear-norm minimization through iterative thresholding ofsingular values. these models are slow to fit and difficult to parallelizebecause of their dependence on computing a singular value decomposition at eachiteration. regularized low-rank recovery models also incorporate non-smoothterms to separate structured components (e.g. sparse outliers) from thelow-rank component, making these problems more difficult.  using burer-monteiro splitting and marginalization, we develop a smooth,non-convex formulation of regularized low-rank recovery models that can be fitwith first-order solvers. we develop a computable certificate of convergencefor this non-convex program, and use it to establish bounds on thesuboptimality of any point. using robust principal component analysis (rpca) asan example, we include numerical experiments showing that this approach is anorder-of-magnitude faster than existing rpca solvers on the gpu. we also showthat this acceleration allows new applications for rpca, including real-timebackground subtraction and mr image analysis.