we consider the question of estimating a solution to a system of equationsthat involve convex nonlinearities, a problem that is common in machinelearning and signal processing. because of these nonlinearities, conventionalestimators based on empirical risk minimization generally involve solving anon-convex optimization program. we propose anchored regression, a new approachbased on convex programming that amounts to maximizing a linear functional(perhaps augmented by a regularizer) over a convex set. the proposed convexprogram is formulated in the natural space of the problem, and avoids theintroduction of auxiliary variables, making it computationally favorable.working in the native space also provides great flexibility as structuralpriors (e.g., sparsity) can be seamlessly incorporated.  for our analysis, we model the equations as being drawn from a fixed setaccording to a probability law. our main results provide guarantees on theaccuracy of the estimator in terms of the number of equations we are solving,the amount of noise present, a measure of statistical complexity of the randomequations, and the geometry of the regularizer at the true solution. we alsoprovide recipes for constructing the anchor vector (that determines the linearfunctional to maximize) directly from the observed data.