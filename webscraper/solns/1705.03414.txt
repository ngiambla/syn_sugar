we study a distributed learning process observed in human groups and othersocial animals. this learning process appears in settings in which eachindividual in a group is trying to decide over time, in a distributed manner,which option to select among a shared set of options. specifically, we considera stochastic dynamics in a group in which every individual selects an option inthe following two-step process: (1) select a random individual and observe theoption that individual chose in the previous time step, and (2) adopt thatoption if its stochastic quality was good at that time step. variousinstantiations of such distributed learning appear in nature, and have alsobeen studied in the social science literature. from the perspective of anindividual, an attractive feature of this learning process is that it is asimple heuristic that requires extremely limited computational capacities. butwhat does it mean for the group -- could such a simple, distributed andessentially memoryless process lead the group as a whole to perform optimally?we show that the answer to this question is yes -- this distributed learning ishighly effective at identifying the best option and is close to optimal for thegroup overall. our analysis also gives quantitative bounds that show fastconvergence of these stochastic dynamics. prior to our work the onlytheoretical work related to such learning dynamics has been either indeterministic special cases or in the asymptotic setting. finally, we observethat our infinite population dynamics is a stochastic variant of the classicmultiplicative weights update (mwu) method. consequently, we arrive at thefollowing interesting converse: the learning dynamics on a finite populationconsidered here can be viewed as a novel distributed and low-memoryimplementation of the classic mwu method.