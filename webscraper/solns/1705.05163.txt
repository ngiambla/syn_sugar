this paper lies in the intersection of several fields: number theory, latticetheory, multilinear algebra, and scientific computing. we adapt existingsolution algorithms for tensor eigenvalue problems to the tensor-trainframework. as an application, we consider eigenvalue problems associated with aclass of lattice-theoretic meet and join tensors, which may be regarded asmultidimensional extensions of the classically studied meet and join matricessuch as gcd and lcm matrices, respectively. in order to effectively apply thesolution algorithms, we show that meet tensors have an explicit low-ranktensor-train decomposition with sparse tensor-train cores with respect to thedimension. moreover, this representation is independent of tensor order, whicheliminates the so-called curse of dimensionality from the numerical analysis ofthese objects and makes the solution of tensor eigenvalue problems tractablewith increasing dimensionality and order. for lcm tensors it is shown that atensor-train decomposition with an a priori known tt rank exists under certainassumptions. we present a series of easily reproducible numerical examplescovering tensor eigenvalue and generalized eigenvalue problems that serve asfuture benchmarks. the numerical results are used to assess the sharpness ofexisting theoretical estimates.