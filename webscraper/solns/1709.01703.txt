improving speech system performance in noisy environments remains achallenging task, and speech enhancement (se) is one of the effectivetechniques to solve the problem. motivated by the promising results ofgenerative adversarial networks (gans) in a variety of image processing tasks,we explore the potential of conditional gans (cgans) for se, and in particular,we make use of the image processing framework proposed by isola et al. [1] tolearn a mapping from the spectrogram of noisy speech to an enhancedcounterpart. the se cgan consists of two networks, trained in an adversarialmanner: a generator that tries to enhance the input noisy spectrogram, and adiscriminator that tries to distinguish between enhanced spectrograms providedby the generator and clean ones from the database using the noisy spectrogramas a condition. we evaluate the performance of the cgan method in terms ofperceptual evaluation of speech quality (pesq), short-time objectiveintelligibility (stoi), and equal error rate (eer) of speaker verification (anexample application). experimental results show that the cgan method overalloutperforms the classical short-time spectral amplitude minimum mean squareerror (stsa-mmse) se algorithm, and is comparable to a deep neuralnetwork-based se approach (dnn-se).