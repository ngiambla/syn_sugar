we study the problem of distributed information bottleneck, in which multipleencoders separately compress their observations in a manner such that,collectively, the compressed signals preserve as much information as possibleabout another signal. the model generalizes tishby's centralized informationbottleneck method to the setting of multiple distributed encoders. we establishsingle-letter characterizations of the information-rate region of this problemfor both i) a class of discrete memoryless sources and ii) memoryless vectorgaussian sources. furthermore, assuming a sum constraint on rate or complexity,for both models we develop blahut-arimoto type iterative algorithms that allowto compute optimal information-rate trade-offs, by iterating over a set ofself-consistent equations.