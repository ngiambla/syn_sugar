researchers often have data measuring features $x_{ij}$ of samples, such astest scores of students. in factor analysis and pca, these features are thoughtto be influenced by unobserved factors, such as skills. can we determine howmany factors affect the data? many approaches have been developed for thisfactor selection problem. the popular parallel analysis method randomlypermutes each feature of the data. it selects factors if their singular valuesare larger than those of the permuted data. it is used by leading appliedstatisticians, including t hastie, m stephens, j storey, r tibshirani and whwong. despite empirical evidence for its accuracy, there is currently notheoretical justification. this prevents us from knowing when it will work inthe future.  in this paper, we show that parallel analysis consistently selects thesignificant factors in certain high-dimensional factor models. the intuition isthat permutations keep the noise invariant, while "destroying" the low-ranksignal. this provides justification for permutation methods in pca and factormodels under some conditions. a key requirement is that the factors must loadon several variables. our work points to improvements of permutation methods.