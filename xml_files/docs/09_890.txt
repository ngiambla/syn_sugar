
 INTRODUCTION 
 This case is about a comparison report concerning acoustic shock protection devices.
These devices are amplifiers that are commonly used to limit the levels of sounds heard by call centre workers and to reduce the risk of acoustic shock which the workers sometimes experience.
The devices that were compared used digital sign processing.
Earlier versions were analogue devices.
Since 2001 the applicant (Polaris) has sold a limiting amplifier called SoundShield, which is designed, through the use of internal settable controls, to be inter-operable with a wide range of host telephones and any headset type.
Since about September 2006 the second respondent (Plantronics) has sold a competing limiting amplifier called M15D, which is designed solely for use with Plantronics equipment.
M15D was developed as the result of collaboration between Plantronics and the first respondent (Dynamic) which commenced in early 2005.
The aim of the collaboration, called the Tecate project, was to produce a limiting amplifier to compete with SoundShield, in particular in relation to Telstra, a major customer for such devices, which had its own particular requirements with respect to limiting amplifiers.
These requirements were contained in Telstra's specification TP TT404B51 called "Specification --- Headset  Limiting Amplifier, Acoustic Protection" (TT4).
Polaris was at the time a supplier of devices to Telstra.
In mid-2005 Dynamic distributed a report entitled "Comparisons of Acoustic Protection Devices --- Plantronics ADRO M15D versus the Polaris SoundShield".
The report was provided to Telstra, which gave a copy to Polaris on a confidential basis.
Plantronics provided a copy to Siemens, which was then its exclusive distributor in Australia of acoustic shock protection devices and telephone headsets, for the purpose of distribution.
Plantronics also gave a copy to Westpac.
The report was distributed in long and short form, though only the short form is at issue in the proceeding.
The report was produced at a time when Telstra was in the process of preparing a request for tender for the ongoing supply to it of acoustic shock protection devices.
Plantronics and Polaris proposed to put in tenders.
The Telstra tender was worth a considerable amount to the successful tenderer.
The quantum is confidential.
At the time of the report SoundShield was the dominant product in the market, having achieved a very large number of sales, a substantial proportion having been made to Telstra.
The number and proportion are confidential.
COMPARISON REPORT 
 The report is four pages in length.
Apart from the title, the first page contains only Dynamic's name and logo, the names of the authors, Christi Wise, Bonar Dickson, Hayley Fiket and Peter Blamey, and a footnote by which Dynamic claims copyright in the report.
The authors were all Dynamic employees when the report was prepared and distributed.
Ms Wise conducted the testing the subject of the report.
On page 2 of the report, under the heading "Background", appears the following: 
 
 Superior sound processing is especially important in call centres where essential information is being conveyed.
The open plan office layout typical of a call centre exposes phone operators to distracting background noises such as ringing phones, voices of fellow operators, and noise produced by office equipment.

 

 
 
 When background noise contains speech or speech-like content, its distracting effect on intelligibility is greater than from other types of noise of equivalent intensity.

 

 After noting the negative effect of background noise --- loss of efficiency in working memory capacity, slower reaction times, reduced accuracy and greater degree of perceived effort, the report continues: 
 
 A distorted speech signal will exacerbate the problems associated with speech perception in noise.
When the level or quality of the line signal is poor and the ambient noise level is high, speech can be hard to understand, even when the overall level of the speech is increased using the volume control.
At high intensity levels, speech can sound distorted and become difficult to understand.
This can cause fatigue and stress for the listener when straining to understand over long periods of time in these environments.

 

 The next heading is "ADRO".
It will be recalled that the title of the report includes the words "Plantronics ADRO M15D".
The Plantronics device was referred to by the parties and by witnesses as both ADRO and M15D interchangeably.
I will refer to it as M15D.
Under the ADRO heading the report states: 
 
 The ADRO processing scheme developed by Dynamic Hearing Pty Ltd is designed to deal with these difficult listening situations without degrading or distorting the sound.
ADRO was developed to meet specifications for acoustic shock protection whilst also providing superior sound quality and intelligibility in comparison to existing products.
It uses a set of fuzzy logic rules to adjust gain so that the output signal is always within the comfortable and audible range of the listener.
The system produces a high level of speech understanding, while also maintaining a comfortable loudness level and a high sound quality.

 

 The report then describes the test that was carried out: 
 
 To demonstrate its superior abilities, ADRO was compared with SOUNDSHIELD in a simulated call centre environment.
The SOUNDSHIELD is a handset amplifier commonly used in Australian call centres to provide protection from acoustic shock.
The Plantronics Supra Monaural H51-TT3 headset was used with both ADRO and SOUNDSHIELD.
Both headset amplifiers were adjusted to the lowest limiting setting and the maximum volume setting, as is typically done by phone operators to provide maximum intelligibility in quiet and in noise.
The receive signal level was the same for both devices.

 

 Under the heading "ADRO improves the intelligibility of speech", the report states: 
 
 The Phonetically Balanced Monosyllable (PBM) word test was presented in typical call centre background noise levels (55-66dBA) to eight adults with normal hearing who were asked to repeat all the words that they heard.

 

 
 
 In low level ambient noise (55dBA), the error rate for SOUNDSHIELD (18%) was double that of ADRO (9%).
In moderate level background noise (65dBA), the error rate for SOUNDSHIELD increased to 26%, whilst the error rate for ADRO only increased to 12%.

 

 
 
 Extrapolation of the PBM results for different background noise levels are shown in Figure 1.
To achieve an intelligibility score of 90% with the SOUNDSHIELD, the background noise level of the call centres would have to be reduced to an unrealistic level of about 40dBA.
ADRO on the other hand, easily achieved 90% intelligibility with call centre background noise at a level of 55dBA.

 

 
Page 3 of the report contains Figure 1 referred to above.
The graph is described as "Percentage Correct on PBM Word Lists as a Function of Background Noise".
The expression "dBA" in the Figure and in the report is a specific variety of decibel (dB), described in the Australian Communications Industry Forum (ACIF) Guidelines referred to at [14] as "Logarithmic measurement of sound pressure level measured through an 'A' curve filter".
A more readily understood description is that "dBA" is used for measuring sound in the environment, often called "in free field".
Under the heading "ADRO was preferred by listeners" the report states: 
 
 Without knowing which headset amplifier they were listening to, the eight normally hearing adults were asked to rate their impressions of loudness, sound quality, and overall impression for two levels of background noise (55 and 65dBA).
Figure 2 illustrates that 95 to 100% of the responses were in favour of ADRO in background noise at a level of 65dBA.

 

 
Then appears Figure 2 which is described as "Preferences in 65dBA of noise in percentage of times chosen for perception of loudness, quality preference, and overall preference".
The report continues:
 
 
 These results are highly statistically significant indicating that the sound quality differences were obvious to the listener.

 

 The material under the next heading, "ADRO will increase the efficiency of phone operators", is: 
 
 This data demonstrates that the use of ADRO in call centre environments allows for typical call centre background noise levels whilst maintaining good speech intelligibility and superior sound quality.
Being able to hear well under such challenging conditions, will result in: 
 

 reduced stress, fatigue and anxiety of phone operators fewer mistakes by phone operators reduced call costs due to less repetition better customer service leading to higher levels of customer satisfaction
 
 
 ADRO is G616 compliant and suitable for TT4 compliant operation.

 

 
TT4 is referred to at [3] above.
G616 is ACIF Guideline "Acoustic safety for telephone equipment": ACIF G616: 2004 (G616).
G616 is an industry wide document, whereas TT4 is Telstra specific.
Under the heading "Acknowledgments" the report states: 
 
 The research that resulted in this report was conducted at Dynamic Hearing, Richmond, Australia.
The work was covered by ethics approval from the Royal Victorian Eye and Ear Hospital Human Research and Ethics Committee (Project 03 529H).

 

 Page 4 of the report contains a list of reference works linked by number to various parts of the report set out above.
Underneath the references are statements that ADRO is a registered trade mark of Dynamic and SOUNDSHIELD is a registered trade mark of Polaris Acoustics Pty Ltd. At the foot of the page is the copyright note that also appears at the bottom of page 1.
THE PLEADINGS 
 The amended statement of claim identifies four representations or sets of representations alleged to have been made by Dynamic in the comparison report: the lowest limiting setting representation the ethics approval representation the unsuitability representations the test set up representations.

Only the first two were pleaded in the original statement of claim (June 2006).
The others were added in May 2007.
Lowest limiting setting representation
 This is that the testing of SoundShield and M15D at their lowest limiting settings provided an appropriate comparative basis for testing for intelligibility of speech.
Dynamic and Plantronics admit making the representation.
Polaris alleges that the lowest limiting setting representation was misleading or deceptive or likely to mislead or deceive because the lowest limiting setting at which SoundShield was tested was significantly lower than that for M15D, and the test results consequently conveyed a misleading assessment of the comparative performance capabilities of SoundShield.
This allegation is denied by Dynamic and Polaris.
Ethics approval representation
 This is the statement at [15] that the research that resulted in the comparison report was covered by ethics approval from the Human Research and Ethics Committee (the Ethics Committee).
Dynamic and Plantronics admit that the ethics approval representation was made, but deny that it was misleading or deceptive or likely to mislead or deceive.
Unsuitability representations
 The background to the unsuitability representations is pleaded as follows: 
(a) at all material times there were two guidelines for acoustic shock protection devices in Australia, namely G616 and TT4;
 
(b) in December 2005 Telstra released a request for tender for the supply to it of acoustic shock protection devices and telephone headsets (Telstra's RFT);
 
(c) Telstra's RFT included a requirement, as specified in TT4, that any acoustic shock protection device supplied to Telstra must have 90% intelligibility in call centre environments with conversation chatter to 55dBA (the Telstra intelligibility requirement);
 
(d) at least since July 2005 Dynamic and Plantronics were aware of the Telstra intelligibility requirement and that Telstra was intending to release Telstra's RFT; and
 
(e) the comparison report was prepared by Dynamic and amended at the suggestion of Plantronics for the purpose of providing it to Telstra in response to Telstra's RFT.
As to [21(a)] Dynamic and Plantronics admit the existence of G616 and TT4.
Plantronics admits the allegation in [21(d)].
Otherwise they both deny or substantially deny the allegations in [21].
Polaris then identifies the three unsuitability representations: 
(a) SoundShield is unsuitable for use in call centres because of its poor intelligibility where background noise is present;
 
(b) SoundShield does not comply with the Telstra intelligibility requirement; and
 
(c) SoundShield is not suitable for TT4 compliant operation and is not G616 compliant.
These, it is said, are to be implied.
In its particulars Polaris says why the implication is to be made.
I will return to the particulars at [201].
Dynamic and Plantronics either deny or substantially deny the above allegations.
Polaris alleges that the unsuitability representations were misleading and deceptive or likely to mislead or deceive because SoundShield did have the attributes the representations claimed it did not have.
Dynamic and Plantronics deny these allegations.
Test set up representations
 Polaris alleges that the comparison report represents that: 
(a) the test on which it was based was a properly conducted scientific test designed and undertaken with an appropriate level of skill, independence and expertise for the purpose of a proper comparison of the two devices tested;
 
(b) the test conditions were not biased to favour one device over the other, but instead were an accurate reflection of the conditions normally experienced in call centres;
 
(c) both devices were appropriately set up for the test conditions; and
 
(d) the results of the test were an accurate reflection of the relative performance of the two devices in call centres.
These representations, it is said, are to be implied.
In its particulars Polaris says why that is the case.
Dynamic admits the making of the representations.
Plantronics does not.
Polaris alleges that the test set up representations were misleading or deceptive or likely to mislead or deceive because the test did not have the characteristics represented.
In extensive particulars which are considered at [135] to [200], Polaris sets out the bases for the allegations.
Dynamic and Plantronics deny the allegations.
Balance of the pleading
 Polaris contends that: 
(a) Plantronics caused the comparison report to be published and distributed, and thereby adopted and disseminated the statements and representations pleaded;
 
(b) by causing the publication and distribution of the report Dynamic and Plantronics engaged in conduct in the course of trade and commerce;
 
(c) by making the various representations Dynamic and Plantronics engaged in conduct that was misleading and deceptive or likely to mislead or deceive in contravention of s 52 of the Trade Practices Act 1974 (Cth) (the Act);
 
(d) in the alternative to (c), Dynamic and Plantronics falsely represented in connection with the supply or possible supply of goods that the M15D and SoundShield devices were each of a particular standard, quality or grade;
 
(e) the events that constituted a contravention of s 52 also resulted in a contravention of s 53(a) of the Act; and 
 
(f) it has suffered loss and damage by reason of the contraventions.
The hearing the subject of these reasons was concerned only with whether there had been contraventions.
Plantronics admits that it provided a copy of the report to Westpac and Siemens, but otherwise denies [27(a)].
It admits that its provision of these copies was conduct in trade and commerce, but otherwise denies [27(b)].
It denies the other allegations.
Dynamic does not plead to [27(a)] and denies the other allegations.
COMPARATIVE ADVERTISING 
 In Gillette Australia Pty Ltd v Energizer Australia Pty Ltd [2002] FCAFC 223 ; (2002) 193 ALR 629 the Full Court made some helpful observations about comparative advertising.
Gillette and Energizer manufactured and distributed batteries.
Gillette used the brand name "Duracell", and supplied alkaline batteries.
Energizer used the brands "Energizer" and "Eveready".
It supplied both alkaline and carbon zinc batteries.
Alkaline batteries last longer but are more expensive than carbon batteries of the same size.
Energizer sought to restrain Gillette's television advertisement which claimed that the Eveready Super Heavy Duty Battery (a carbon zinc battery) "just can't keep up", and that "with up to three times more power Duracell will always win", on grounds that included that the advertisement did not reveal that there was a substantial price differential between the two batteries, and thus consumers could be misled in comparing the value of the two.
On that basis the trial judge granted an injunction.
The Full Court allowed Gillette's appeal.
Heerey J said at [20]: 
 
 The characterisation of advertising as comparative does not of itself have legal significance, or create any kind of presumption in favour of a party alleging a breach of Pt V of the TPA.
There is no basis in the TPA for regarding comparative advertising as an inherently disreputable form of commercial conduct, to be viewed with suspicion by the courts.
On the contrary, to the extent that comparative advertising provides consumers with accurate hard facts about competing products, it assists in the making of better informed consumer choices and thereby results in more effective competition.
Of course, the more actual comparisons that are used, the more potential there is for error (and half-truth).
So advertisers have to be careful ...
Assertions of factual inaccuracy have to be carefully considered by courts in comparative advertising cases, no differently from any other cases.

 

 Heerey J then rejected Energizer's contention that to compare the products without mentioning the price was not to make a full comparison and was thus unfair.
His Honour said at [22]: 
 
 [The] textual basis [for the contention] is the heading of Div 1 of Pt V , "Unfair practices".
But to use general notions of unfairness, which bring to mind the concept of unconscionable conduct appearing elsewhere in the TPA, is to put an unwarranted gloss on the plain words of provisions of Pt V such as ss 52(1) and 53 (a).
Provided the factual assertions are not untrue, or misleading half-truths, an advertiser can lawfully compare a particular aspect of its product or service favourably with the same aspect of a competitor's product or service.

 

 His Honour then considered an example that had been discussed in argument where airline X advertised that its economy class seats provide 20 cm more leg room than those of airline Y.
If that claim is true, s 52 does not oblige airline X to provide in its advertisement detailed information as to the other factors which might influence consumers choosing between airlines.
And if airline Y wanted to advertise that its fares were cheaper, its aircraft more modern, and its flights more frequent, that would be legitimate so long as "no untruths or misleading half-truths are stated": at [23].
Returning to the facts before him, Heerey J concluded at [24]: 
 
 A consumer, informed by the advertisement (correctly, it must be assumed for present purposes) that the Duracell battery lasts three times longer than the Eveready Super Heavy Duty battery, can make his or her decision at the point of sale whether the extra power of the Duracell is worth the higher price.
I do not see how it could be said that such a consumer has been misled or deceived.
Indeed, it would be inconsistent with the policy and objectives of the TPA to restrict a trader from publicising, truthfully, a feature of its product which is superior to the same feature of a competitor's product.

 

 
His Honour went on to explain why that was so.
The other members of the Full Court were of the same opinion: Lindgren J at [53] (pages 646-647 point (7)) and Merkel J at [85], [91] and [93].
THE WITNESSES 
 Polaris
 Trevor Guest established Polaris in 1981.
It first manufactured SoundShield in 2001.
Mr Guest has over 25 years experience in the sale of telecommunications equipment in Australia.
He has no formal technical or scientific qualifications.
However his experience in the manufacture, importation and sale of this equipment has exposed him to a wide variety of technical matters associated with sound regulation.
He said he is familiar with the various technical standards that apply to telecommunication devices in Australia.
He has personally installed SoundShields and other telecommunications equipment in a range of customer premises, has programmed SoundShield on numerous occasions and is familiar with the device and the settings contained within it.
Mr Guest swore four affidavits and wascross-examined at length.
He came across as an honest witness.
On one occasion, when he was describing a test he had done of SoundShield, he seemed to gild the lily by describing it as a comparative test of SoundShield and M15D.
However, I think this was attributable to confusion on his part and was not an attempt to mislead the Court.
He conceded that he was wrong to characterise his test as a comparative one.
Mr Guest accepted that his lack of formal technical qualifications meant he could not express authoritative opinions about scientific, electronic and audiological matters.
However, his long involvement in the acoustic protection device industry, his participation in the formulation of industry standards, and his hands on experience, provided sufficient basis for the evidence he gave as to the industry, the general effect of the standards and the mechanisms of SoundShield.
I have emphasised the word "general" because Mr Guest was not seised of the detail of the standards or of the technical attributes of the various devices.
The best example of this was his confusion about the headset profiles, when he was at odds with his own experts.
In addition, Professor Blamey took exception to many of Mr Guest's measurements, in particular his unexplained transition between the different types of decibels --- dB, dBA, dB SPL at DRP --- as though they were all the same.
Thus, on matters of a technical nature, I do not regard him as having the expertise to express opinions that can compete with those of acknowledged experts.
Ben Minski joined Polaris in 2004 as an account manager.
More recently he has been the project/implementation manager of the major roll outs of SoundShields into call centres nationally.
His experience includes installing over 20,000 SoundShields in approximately 80 call centres Australia wide, and he was consequently familiar with the device, the different technical settings contained within it, which settings best suit particular technical environments and users, and what happens if a device is not correctly customised to its particular environment and user.
His evidence was largely uncontroversial.
He was cross-examined.
I thought him an honest witness, a conclusion that was confirmed by the fact that on one topic his evidence did not assist Polaris' case.
Rodney Thompson was in charge of the technical side of Polaris' business.
He has tertiary electronic engineering qualifications, and experience as an engineer with Telstra and since 2006 with Polaris.
He is familiar with the measurement of sound signals and signal levels generally, the various telecommunications standards in use in Australia, and what those standards mean in technical terms for the Australian telephone network and devices that operate in conjunction with it.
He was cross-examined, and the concessions he made in the course of his evidence made it clear that he was giving a truthful account of matters on which he spoke.
Philip Newell is an Emeritus Professor at the Speech, Hearing and Language Research Centre, which is part of the Linguistics Department at Macquarie University.
He is a qualified audiologist with postgraduate degrees in biomechanics and audiology.
As a result of his qualifications and experience over nearly 30 years, he has a detailed understanding of the different factors that affect speech, sound and signal quality generally, including the way devices such as hearing aids, amplifiers and telephone equipment operate to modify sounds and signals, and the effects of those modifications on human hearing and speech intelligibility generally.
Professor Newell's expertise was not challenged by the respondents, though they claimed he was not truly independent of Polaris.
I preface my discussion of this issue by saying that this was the first time Professor Newell had given expert evidence, and I sensed that he found it somewhat of an ordeal.
In his first affidavit he disclosed his several letters of instruction.
In the letter dated 11 September 2007 Professor Newell was told that Michael Fisher of National Acoustic Laboratories (NAL) had undertaken a further intelligibility study and that the Professor had "kindly agreed to verify and confirm these results".
These were the results of a test Mr Fisher carried out in July 2007.
Professor Newell had earlier been provided with a report detailing the results of tests Mr Fisher made in January 2006.
The letter went on to say that arrangements had been made for Professor Newell to attend NAL's premises and undertake the following: Supervise the repetition of the intelligibility test undertaken by Mr Fisher.
Verify the testing protocols used are in accord with Telstra TT4 Specifications and associated documents.
Confirm the results of the tests.
Provide a report of your findings ...
 This was a most incautious letter of instruction.
Polaris' solicitors were obviously happy with Mr Fisher's July 2007 test.
But because of his closeness to SoundShield --- he was its inventor --- I infer that they thought the results needed some independent imprimatur.
Professor Newell was to "verify and confirm" Mr Fisher's results.
Of course Professor Newell cannot be blamed for his letter of instructions.
In cross examination he was challenged about his independence, and I accept his response that, notwithstanding the unfortunate verbiage of his instructions, he did not see his task to be simply to endorse or confirm Mr Fisher's results.
He said that if the results of his test differed from those earlier obtained by Mr Fisher, he would say so in his report.
However, my acceptance that Professor Newell would report his results as they were, even though they may not have corresponded with Mr Fisher's, is not the end of the matter.
The respondents also submit that Mr Fisher had such an input into the setting up of the test that Professor Newell was not truly independent.
Professor Newell's description of his commission confirms Mr Fisher's close involvement in what the Professor subsequently did.
He agreed that: the test was set up mostly by Mr Fisher, though he did have some input the word list used in the test was suggested by Mr Fisher, and the Professor agreed with the suggestion Mr Fisher made a large number of suggestions, but the Professor was generally very happy with them Mr Fisher had significant input into the design of the experiment and the setting up of the equipment Mr Fisher suggested the input voltage the Professor should use in the tests, namely in the order of 40 to 60mV he relied completely on what Mr Fisher told him about the various inputs to SoundShield he took "on trust" what Mr Fisher told him was the appropriate input voltage level and the appropriate setting.

Professor Newell also agreed that he accepted Mr Fisher's assurance that provided SoundShield was set to HIGH, it would perform correctly with 100mV input, though he had not done any measurement himself.
Professor Newell did not attempt to hide Mr Fisher's involvement in the setting up of the tests.
He stressed, however, that he only implemented Mr Fisher's suggestions because he agreed with them.
He said he was given the opportunity to disagree with Mr Fisher's suggestions or modify them if he wished.
He also said that although when he went to the laboratory the test was all set up, he had to spend quite some time with Mr Fisher looking in great detail at how the equipment was attached together and what the control settings were.
It "was almost as if I had set it all up myself".
I have concluded that Mr Fisher's involvement does not establish that Professor Newell's test was not independent.
However, I bear in mind in assessing the weight to be accorded to the results that Mr Fisher had an important input into the construction of the test.
The respondents also relied on the fact that Professor Newell was one of the supervisors of Mr Fisher's ongoing research for a PhD to show his closeness to Mr Fisher.
In an affidavit the Professor said the research was "not related to the subject matter of this proceeding".
An extract from the university website's description of Mr Fisher's research topic was put to him.
It included this passage: 
 
 Headset users within call centres face numerous problems related to their headset usage, such as: limited telephone speech intelligibility amidst background noise of the call centre, acoustic discomfort, acoustic shock injury, acoustic isolation from colleagues and vocal strain.
Many of these problems are interdependent.
The aim of this research is to investigate aspects of these problems and to develop methods for improving the outcomes of headset use.

 

 Professor Newell's response was unconvincing.
His statement that Mr Fisher's PhD was "not related to the subject matter of this proceeding" became "there are many areas of the PhD which have relevance to the court proceedings, and that is what I meant".
However this issue has not led me to think that the Professor's involvement in Mr Fisher's research project, with its partial overlap with some of the issues in the case, would lead him to carry out his tests with any partiality or to give evidence that was not impartial.
Michael Fisher is a senior research engineer employed by Australian Hearing at NAL.
He has a broadcasting certificate, a broadcast operator's certificate of proficiency and is a Bachelor of Communication Engineering from RMIT.
In his thirteen years with NAL he has undertaken research in audio signal processing, acoustics, digital signal processing, hearing, hearing impairment, psychoacoustics and speech analysis.
Mr Fisher is listed as the inventor on Australian Standard Patent 2002318963 entitled "Digital Signal processing system and method for telephony interface apparatus" that covers various algorithms, including a method of reducing the amplitude of "shrieks" (the shriek rejection algorithm) that are the major source of acoustic shock injury.
The patentee is HearWorks Pty Ltd and Polaris is now the licensee from HearWorks of software designed to instruct a digital signal processing device to perform the shriek rejection algorithm.
Mr Fisher receives from HearWorks a small distribution of the royalties paid to it by Polaris.
He has assisted Polaris with implementing the software in the SoundShield device.
I do not doubt Mr Fisher's expertise.
He was the inventor of SoundShield, and admitted that he was affronted by the results of the comparison test.
He was, I think, anxious to prove it wrong.
In that behalf he carried out two tests of his own, and helped set up Professor Newell's test.
His affront manifested itself in expostulations, noisy exhalations and gestures of bewilderment.
When he sensed that Table 5.9 of TT4 (see [145] below) was being used to suggest that SoundShield may not be TT4 compliant, he described the table as "absolutely crazy".
I do not think that the fact that he was offended by the comparison report affected the quality of his evidence on the technical matters with which it dealt.
He was subjected to very lengthy trenchant cross-examination, and this, coupled with the fact that he was obviously suffering from a cold, may have contributed to his expostulations etc. Plantronics
 Ian McNeill is an audio electronics engineer who graduated from the University of Manchester Institute of Science and Technology with the degree of Bachelor of Science (Electrical and Electronics Engineering).
He was employed by Plantronics Inc (US) between 1992 and 2007 as a senior electronics engineer/project lead.
In that role he designed the hardware of the M15D and led the project team which developed its firmware.
In February 2008 he performed a measurement of what he called the "acoustic limit for speech" for a M15D and a SoundShield.
Mr McNeill was cross-examined by video link to California in the United States.
His expertise was not in doubt.
He gave his evidence concisely and authoritatively.
Although he had until recently a Plantronics background, I saw no reason to doubt his credibility, and have for the most part accepted his evidence.
Graeme Gherbaz has been Plantronics' Managing Director for more than ten years.
Before then he was employed by Siemens and earlier by Telstra in sales and marketing and product management roles relating to telecommunications headsets.
He has a certificate of technology in electronics from Footscray Technical College and is a Bachelor of Business Management from RMIT.
He has over 25 years experience in the telecommunications industry, in technical, sales and management roles.
Mr Gherbaz's evidence was largely about the development of M15D, collaboration between Plantronics and Dynamic and the development of the comparison report and its distribution.
It was largely uncontroversial.
I have generally accepted his evidence as credible, notwithstanding that he had a strong interest in the outcome.
Dynamic
 Peter Blamey was formerly Chief Technology Officer and a director of Dynamic.
He ceased to be a director in December 2007.
He is still an adviser to Dynamic.
Since 2002 he has been a Professorial Fellow in the Department of Otolaryngology at The University of Melbourne.
Before then he had research appointments in that Department from 1979.
His academic qualifications are in Physics.
His business interests are in the commercial application of digital signal processing for hearing aids, headsets and telephony products.
Professor Blamey was cross-examined at length.
He displayed an impressive grasp of the topics upon which he gave evidence, and handled with ease the volume of documentary material he was asked to consider and review in the witnesses box.
He retained his composure through some gruelling technical cross examination.
He refused to be hurried in his responses, and when necessary called for a document in order to be sure he understood what was being asked of him.
He asked that corrections be made to parts of his affidavit which he had discovered since swearing it to be wrong.
Polaris criticised him for occasional lapses of recollection, but I attach no importance to that having regard to the length of his evidence and the topics covered.
Professor Blamey was involved in the comparison test and the compilation of the ensuing report.
He was then a director of Dynamic and is still an adviser to the company.
In those senses, he is partisan.
Nevertheless, I regard him as a witness of truth, and have for the most part accepted his evidence.
He and Mr Fisher were at odds on many points.
Bonar Dickson is Chief Technology Officer of Dynamic.
He was the engineer for the Tecate project in which the digital signal processing software was developed for the M15D.
The software has been referred to as ADRO in the proceeding.
Mr Dickson's affidavit evidence dealt with but one issue.
He was cross-examined briefly.
I have no reason to doubt the truth of his evidence, and I accept the central point of it, namely that the graph he prepared in December 2005 containing output levels of two settings of the M15D, two settings of SoundShield and one setting of another device shows the same output levels that would have applied in May 2005 when the comparison was carried out by Dynamic.
READERS OF THE COMPARISON REPORT 
 Whether conduct is misleading or deceptive or likely to mislead or deceive is a question of fact to be determined having regard to the entire context of the conduct including the background of all surrounding circumstances.
One of those circumstances, in a case such as the present, is the class of persons to whom the conduct was directed.
In Campomar Sociedad, Limitada v Nike International Ltd [2000] HCA 12 ; (2000) 202 CLR 45 at [103] the whole Court said: 
 
 Where [the class of consumers] are not identified individuals to whom a particular misrepresentation has been made ... but are members of a class to which the conduct in question was directed in a general sense, it is necessary to isolate by some criterion a representative member of that class.
The inquiry thus is to be made with respect to this hypothetical individual why the misconception complained of has arisen or is likely to arise if no injunctive relief be granted.

 

 Gleeson CJ, Hayne and Heydon JJ returned to the question in Butcher v Lachlan Elder Realty Pty Ltd [2004] HCA 60 ; (2004) 218 CLR 592 ( Butcher ) at [36]-[37]: 
 
 The relevant class addressed.
Questions of allegedly misleading conduct, including questions as to what the conduct was, can be analysed from two points of view.
One is employed in relation to "members of a class to which the conduct in question [is] directed in a general sense".
The other, urged by the purchasers here, is employed where the objects of the conduct are "identified individuals to whom a particular misrepresentation has been made ..."; they are considered quite apart from any class into which they fall.
Adoption of the former point of view requires isolation by some criterion or criteria of a representative member of the class ... 
 

 
 
 The former approach is common when remedies other than those conferred by s 82 (or s 87) of the Act are under consideration.
But the former approach is inappropriate, and the latter is inevitable, in cases like the present, where monetary relief is sought by a plaintiff who alleges that a particular representation was made to identifiable persons, of whom the plaintiff was one.

 

 The present case requires what in Butcher their Honours called the former approach --- looking at the impugned conduct through the eyes of members of the class to which it was directed in a general sense.
Polaris is not complaining that it was misled by the representations in the comparison report.
It is worried that whoever might have received the report could be misled.
Thus it is necessary to identify the class of persons who, having received the report, are likely to be influenced by it.
The market for noise suppression devices of the kind referred to in the report consists of businesses which conduct call centres in Australia.
Telstra is one such business.
Mr Gherbaz, Plantronics' managing director, said the M15D was being developed for both the forthcoming Telstra RFT and for the general market.
The comparison report was intended to be used and was used for the general market as well as to assist Plantronics in relation to the tender.
He said the potential readers of the report would be Occupational Health and Safety (OHS) managers in organisations and call centre managers.
They were the officers with whom Plantronics would deal in connection with enquiries about its devices and sales of them.
Thus it was the OHS manager of Westpac who enquired of Mr Gherbaz about its products and what path to go down.
He sent her a copy of the report.
The report was not made available to the general public.
It was common ground that call centres have staff with technical skills and qualifications who can deal with headset or computer problems.
Often call centres will have access to audiologists.
According to Mr Gherbaz, when a call centre encounters an acoustic shock protection problem, or seeks information about protection devices, its information technology telephony people will contact suppliers such as Plantronics or Polaris.
Accordingly, those who read the comparison report would have an understanding of call centre operations and the difficulties encountered by telephone operators, such as those summarised in the "Background" part of the report.
Because readers will be of a managerial class accustomed to dealing with noise and other problems encountered by their operators, they are likely to have some understanding of the technical issues with which the report deals.
They are likely also to have access to experts, including audiologists, to discuss issues raised by the report.
In short, the likely reader of the report will have a much greater ability to understand and assess the report, and the technical matters with which it deals, than an ordinary member of the public.
The potential reader would thus be in a good position to determine whether a statement in the report about an attribute of one device carried with it an implication that the other device did not have that attribute.
The reader would also pick up that the report was dealing only with intelligibility and not with the overall attributes of the two devices.
GENERAL FINDINGS OF FACT 
 Markets for acoustic shock protection devices
 At the time of the comparison report test (May 2005) there were two types of call centres that were potential markets: those conducted by Telstra and the general market conducted by entities other than Telstra.
Telstra made up approximately one third of the overall market and the other entities approximately two thirds.
Since December 2001 Polaris had been the sole supplier to Telstra.
That arrangement was to have come to an end in December 2004, but in fact continued until mid 2005.
SoundShield was also sold widely in the general market.
Dynamic and Plantronics developed the M15D device during 2005 with a view to it competing in the Telstra and general markets for acoustic shock protection devices.
The name ADRO was often used to describe the M15D because the ADRO software that had been developed by Dynamic for use in hearing aids was later used in the M15D.
Dynamic and Plantronics were aware that the Telstra RFT would be issued in 2005, and Plantronics intended to submit a tender.
Standards, guidelines and specifications
 Telstra's TT4 specification contained a range of technical requirements which acoustic shock protection devices had to satisfy if they were to be purchased for use in Telstra's call centres.
It required the output of the devices to be limited to 85dB SPL (see [70]).
The stated intent of TT4 was to minimise the symptoms of acoustic shock whilst maintaining speech intelligibility of not less than 90% with background voice chatter to 55dBA and with acoustic treatment to provide 49dB acoustic attenuation between adjacent workstations: clauses 3 and 5.2.2.
The parties were at odds as to whether the intelligibility requirement was operative at the time of the test the subject of the comparison report (May 2005).
Dynamic maintained that, on Polaris' pleading, the requirement did not come into existence until December 2005, when Telstra's RFT was published and introduced it.
Dynamic said that prior to that, 90% intelligibility was only an objective or recommendation.
I do not think that is the effect of the pleading.
Paragraph 10C of the statement of claim alleges that Telstra's RFT "included a requirement, as specified in TT4", that any device supplied to Telstra must satisfy the intelligibility requirement.
The copy of TT4 in evidence, issued in June 2001, contains the intelligibility requirement.
The copy of Telstra's RFT in evidence is incomplete, but I would infer from clause 1.1 of Schedule 9, which requires products supplied to meet "the requirements of the specifications and addendums provided", that the provisions of TT4 formed part of the specifications.
"Specification" is defined by reference to a Schedule that is not part of the document in evidence.
I proceed on the basis that the intelligibility requirement was in place in May 2005.
In May 2005 Australian Standard S004, administered by the Australian Communications and Media Authority, required the output of acoustic shock protection devices to be limited to 118dB.
S004 is a mandatory standard.
It does not have an intelligibility requirement.
G616 was published in 2004.
It is a non-binding general Australian guideline for acoustic safety for telephone equipment.
As a condition of a device being marketed as an acoustic shock protection device, it imposes an acoustic limit of 102dBA SPL at DRP measured by the use of pulsed tones over a time interval of 125 milliseconds.
The symbol dBA is explained at [12].
SPL means Sound Pressure Level and DRP means (ear) Drum Reference Point.
Shortly after Polaris entered into the 2001 contract with Telstra, Telstra relaxed its limiting requirements for Polaris by five decibels (TT4+5) (ie 90dB).
Details of the relaxation were not published.
In the weeks preceding the 10 May 2005 comparison test Dynamic and Plantronics made enquiries with a view to discovering the settings used on the SoundShield device in call centres.
Testing and trialling M15D
 In developing M15D Dynamic and Plantronics undertook testing through a technical testing organisation, Trillium Technology Pty Ltd (Trillium), for the purpose of determining whether the device complied with the specific technical requirements of the relaxed form of TT4.
This did not involve intelligibility testing.
Trillium reported that M15D complied with TT4+5 for acoustic limiting.
At some time after May 2005 Plantronics carried out two call centre trials of M15D, including centres which used SoundShield.
One trial was done in Australia and the other in the United States.
On 10 May 2005 Dynamic undertook the speech intelligibility test the subject of the comparison report.
The test used a Plantronics H51-TT3 headset with each of the devices set to the lowest limiting setting.
Headset profile 1 was used in SoundShield.
The combination of lowest limiting setting and headset profile 1 in SoundShield was its general market mode and not that used in Telstra call centres.
Similarly, the lowest limiting setting of M15D was its proposed general market mode and not the proposed Telstra mode.
The testing used the same input levels for each device.
Before carrying out this test, Professor Blamey did a pre-test for intelligibility with himself as the subject.
This test is considered in more detail at [161]-[165].
Testing SoundShield
 In January 2006 Mr Fisher tested SoundShield Mk1 (the model used in the comparison test) and a more recent model at both the limiting setting required by Telstra (TT4+5) and at the highest limiting setting of 95dB, with background noise levels of 55 and 65dBA.
He found an average intelligibility across all conditions of 96%.
The intelligibility scores were reported as phonemes correct and not whole word correct.
In July 2007 Mr Fisher again tested SoundShield Mk1 on the same basis as the January 2006 test, except that the intelligibility scores were reported as whole word as well as phonemes correct.
The results were 97% correct on monosyllabic words, using phonemic scoring, and 93% correct using whole word scoring.
Set to TT4+5 the device met Telstra's intelligibility requirement under both scoring methods.
In October 2007 Professor Newell did a test of SoundShield Mk1 on substantially the same basis as Mr Fisher's July 2007 test.
The end results of the test appear from the following table which also shows Mr Fisher's tests and Dynamic's test: Condition 1 2 3 4 Background Noise Level 55 dBA 55 dBA 55 dBA 65 dBA Device Direct to Plantronics H51 TT3 SS MK1 TT4+5dB  
 Plantronics H51 TT3 SS MKI 95 dB  
 Plantronics H51 TT3 SS MKI 95 dB  
 Plantronics H51 TT3 Philip Newall October 07 Test 
 Word Score 
 95% 
 90% 
 91% 
 90% NAL July 07 Test --- Word Score 94% 93% - - Dynamic Hearing --- Word Score - - 82% 76% 
 
 
 
 
 Philip Newall October 07 Test 
 Phoneme Score 
 98% 
 96% 
 97% 
 96% NAL July 07 Test --- Phoneme 
 Score 
 98% 
 97% 
 
 NAL January 06 Test --- Phoneme Score 
 
 96% 
 94% 
 97% Other comparative testing
 In July 2005 Plantronics carried out a comparison of SoundShield and M15D in a call centre environment with 12 subjects.
There was very little difference between the responses of the two devices, though SoundShield scored better on overall receive quality.
In August 2005, as part of his work in the development of M15D, Mr Dickson carried out tests of two settings of M15D, two settings of SoundShield and one setting of another device, and measured their respective output levels.
The graph recording the results showed much the same output levels for M15D and SoundShield as in the comparison test (91.7 and 91.4dB SPL at DRP respectively).
The SoundShield device was that used in the May 2005 comparison test.
Version 13a of the ADRO software was used in the August 2005 test of M15D whereas version 1.10a was used in the May test.
Mr Dickson said there were minor differences between those two versions of the software, which did not affect output levels or speech intelligibility.
Thus, he said, the graph showed the same output levels for the devices that would have applied in May 2005.
In 2006 Mr Fisher tested three devices for acoustic level: the M15D, what has been called "the technically equivalent device" to that used in the comparison report (DM15), and the SoundShield Mk1, all in combination with a Plantronics H51 headset.
He observed that the DM15 increased its output when the background noise level increased.
This was a test applying pulsed tones according to the G616 method.
It did not involve speech input.
The DM15 technically equivalent device was delivered to Polaris pursuant to a consent order of the Court made on 26 April 2006 under Order 15A rule 12 of the Rules that the respondents produce to Polaris for inspection and analysis the M15D device used in the carrying out of the May 2005 comparison test or a technically equivalent device to that used.
In February 2008 Mr McNeill carried out a measurement of what he called the "acoustic limit for speech" for a M15D and a SoundShield, using a Plantronics H51N-TT3 headset.
The two devices were set to the same settings as were used in the test for the comparison report: limiting mode 1 for SoundShield and limiting mode 3 for M15D (the setting with the least amount of limiting).
The results are set out in the table below: 
 Polaris SoundShield Plantronics M15D Instantaneous Peak 107.8 dBSPL 107.4 dBSPL Maximum of 125ms RMS Average 96.3 dBSPL 94.7 dBSPL 5s RMS Average 87.1 dBSPL 86.6 dBSPL Active Speech Level 87.1 dBSPL 87.2 dBSPL 
 Technical matters
 The measurement of limits, inputs and outputs in acoustic terms uses the unit dB.
These are units used to measure sound pressure level as a ratio compared to a known reference level.
There are different kinds of dBs.
As already indicated, one of them, dBA, is typically used for measuring sound in the environment, and so is used for OHS limits in factories.
Professor Blamey said there were four or five other types of dB that appear in the material before the Court.
They express different concepts and are not directly comparable without an appropriate translation factor.
It is therefore important to identify the precise concept in use to ensure that any comparison is meaningful.
Limits, inputs and outputs in acoustic terms can be measured in different ways.
Thus the points of measurement may differ.
The point may be in the environment (free field) expressed as dBA, ear reference point (ERP) and drum reference point (DRP).
Measurements can be made over different time intervals (for example, 125ms, 32ms and instantaneous).
These differences are reflected in Table 7.3 of TT4 (page 38).
Again it is important to identify and use comparable parameters of measurement in order for comparisons and observations about acoustic limits, inputs and outputs to be meaningful.
The lowest limiting setting prescribed by TT4 as it operated in 2005, in order to avoid hearing damage to a call centre operator, was 88dB, relaxed for Polaris to 88dB + 5dB.
To achieve that outcome when SoundShield was used in TT4 mode, the device was set to limiting mode 2, which imposed a limit of about 90dB, and headset profile 18.
That profile was developed specifically to comply with the requirements of TT4 and was not made available to the general market, which did not require it.
In the general market (95dB), limiting mode 1 was used for SoundShield by most non-Telstra customers.
For the Plantronics H51 headset, profile 1 was the correct profile.
That was also the case with the Plantronics H51 TT3 headset, when used in the general market mode.
(This headset could be set to either mode.
) During 2005 there were two alternative settings for the M15D which were programmed into each device separately.
These were the G616 (general market) mode which used the least amount of limiting, and a TT4 mode.
During 2005 both were in the process of development and testing.
In the testing for the comparison report the M15D was used in its general market mode, as was SoundShield.
Both modes in the M15D were achieved by the operation of software.
This included Xenica speech processing software developed by Dynamic.
The G616 mode software versions of the Xenica software had the suffix 'a' and the TT4 mode versions had the suffix 'b'.
A numbering system was used to identify the version of the software.
Thus version 1.9 preceded version 1.10a and 10b (the versions under development and testing during 2005).
There were slight changes between release 1.10a and release 1.13a of the M15D, but they had no impact on the way the software dealt with speech inputs.
The comparison report testing was of speech with simulated background noise and no other signal.
CONSIDERATION 
 Lowest limiting setting representation
 A difference in the limiting settings?
It is not disputed that Dynamic represented that the testing of the two devices at their lowest limiting settings provided an appropriate comparative basis for testing for intelligibility of speech.
The s 52 contravention pleaded is that the lowest limiting setting at which SoundShield was tested was significantly lower than that for M15D, and the test results consequently conveyed a misleading assessment of the comparative performance capabilities of the SoundShield device.
This is particularised as follows: 
(a) SoundShield has four settings, namely 80dB, 85dB, 90dB and 95dB.
The lowest limiting setting is 80dB, and it was to the lowest limiting setting that the comparison report states that the device was set.
However the longer form of the comparison report (dated 31 May 2005) states that during the test the device was set at "Limiter Setting 1", which is 95dB.
(b) M15D has an absolute acoustic ceiling, and therefore a lowest limiting setting, of 102dB.
Mr Guest's initial complaint seems to have been that the report wrongly said that SoundShield was set to 80dB, which was its "lowest limiting setting", whereas it was in fact set to 95dB, which was its "least limiting setting" (ie setting 1).
On Professor Blamey's evidence, which I accept, there is no difference between "lowest limiting setting" and "least limiting setting".
Both mean the setting that provides the least limiting, namely 95dB, being the setting chosen.
In any event, Polaris' case was not conducted on the basis of Mr Guest's initial understanding of the position, but on the basis that SoundShield was tested on a limiting setting of 95dB whereas M15D was tested on a limiting setting of 102dB.
Polaris' contention was that a louder sound was heard on the M15D, which would enhance intelligibility.
This was the way Mr Guest put Polaris' complaint in his second affidavit: the M15D device used in the comparison test had an acoustic ceiling of at least 7dB more than SoundShield, and this difference "would have resulted in the device with the higher limit being easier to hear with ie have higher intelligibility".
As appears from [70], the voluntary G616 standard prescribes an upper limit of 102dBA SPL at DRP.
It was common ground that SoundShield's lowest limiting setting was setting 1 or the 95dB setting.
The M15D was a pre-release prototype.
The M15D ultimately released to the market was advertised as having a limit of 102dBA.
Mr Gherbaz and Mr McNeill both said the M15D used in the comparison test had a lowest limiting setting of 102dBA.
Thus, says Polaris, the comparison was between SoundShield with limiting of 95dBA and the M15D with limiting of 102dBA.
This comparison was said to be unfair because the M15D provided less limiting, and thus the listener received more sound than a listener to SoundShield, "with a resultant likely effect on intelligibility" --- the SoundShield caused sound to be heard more quietly.
Polaris relied on Professor Newell's evidence to establish these matters.
The respondents relied on Mr McNeill's test, which is described at [83].
They said this showed that both devices were limiting speech signals at the same level: around 95dBA SPL at DRP (94.7 for M15D and 96.3 for SoundShield) measured at 125ms RMS.
Polaris took issue with the relevance of Mr McNeill's test.
It said that although he described the test as "a measurement of the acoustic limit for speech" of the two devices, it was not that, but a measurement of their outputs with a single 100mV input, which did not test the limiting of the devices.
In cross-examination Mr McNeill accepted that he had measured the devices' acoustic outputs at the ear drum.
He was not trying to verify compliance with any specification.
He was trying to reproduce the conditions of the Dynamic test to verify that it was fair in that both headsets were putting out "similar output levels, acoustic levels".
In my view Mr McNeill's test does not displace the prima facie 7dB gap between SoundShield's limiting of 95dBA and M15D's limiting of 102dBA.
Putting the matter another way, the test does not establish that the M15D tested by Dynamic had the same limit as the SoundShield tested, namely 95dBA as opposed to its published limit of 102dBA, the limit Mr Gherbaz, and Mr McNeill in another connection (see [93]), said it had.
As Mr McNeill conceded, it was not a test of the acoustic limits for speech, but of output levels.
As appears at [96], Mr McNeill was trying to reproduce the conditions of the Dynamic test to verify that it was fair in that both headsets were putting out similar output levels.
Polaris drew attention to many respects in which Mr McNeill's test did not replicate Dynamic's.
I mention only one of them.
The Dynamic test was done with background noise.
Mr McNeill's was not.
This is an important difference for present purposes because, as Mr McNeill pointed out, it was a feature of the M15D (not shared by SoundShield) that when it detected an increase in ambient background noise, it attempted to increase the output volume level "so long as that does not exceed the limiting profile selected".
In other words, the measured output for the M15D in the absence of background noise is likely to be lower than the output in otherwise the same conditions but with background noise.
As Polaris points out, this would explain the difference in perceived loudness recorded by the subjects in the Dynamic test (Figure 2), with the M15D increasing its output in background noise.
More importantly, for present purposes, because a higher output could be achieved in different test conditions (with background noise), Mr McNeill's test is not a test of any limit of the M15D.
The respondents also relied on Mr Dickson's August 2005 test described at [80], which showed much the same output levels for M15D and SoundShield --- 91.7 and 91.4dB SPL at DRP respectively.
Mr Dickson's test was of the same character as Mr McNeill's.
It tested output levels and not acoustic limits for speech.
He agreed that what his graph demonstrated was output measurements, and that they did not directly give any information about the acoustic limits of the devices.
His test was done without background noise, and he agreed with Mr McNeill that the M15D had attributes that improved loudness in noise.
Confirmation that Mr Dickson tested for output levels and not limiting levels is contained in the note of a telephone call made by Professor Blamey in December 2005 to Dr Harvey Dillon of NAL in response to an enquiry as to the limiting level for the M15D tested in May 2005.
The note is in part as follows: 
 
 HD indicated that he wanted to discuss the SoundShield/ADRO study, and that he had seen a copy of the document that [Dynamic] had supplied to Plantronics.
HD asked what was the limiting level for the ADRO device tested.
He inferred that the poorer performance of the SoundShield device may have been caused by using a lower limiting level than was used for the ADRO device.

 

 
 
 PB replied that the limiting levels for the devices had not been measured or compared as part of the study.
The output levels for the two devices had been measured and matched at the start of the study.
SoundShield was set to the typical settings used in Australian call centres as stated in the document.
The ADRO device was set to a similar output level.

 

 It was on receipt of the enquiry from Dr Dillon that Professor Blamey asked Mr Dickson to provide him with the measurements of the output levels used in the May comparison test.
Mr Dickson's graph was provided to Professor Blamey in response.
Professor Blamey said it showed output levels or spectra for speech averaged over 10 seconds.
It is clear therefore that the measurement referred to in the fifth sentence of the passage quoted at [100] is Mr Dickson's, and that it was not a measurement of limiting levels.
The respondents have not established, by resort to Mr McNeill's or Mr Dickson's tests, that in the Dynamic test both devices had more or less the same acoustic limits.
SoundShield was tested on a setting of 95dBA and M15D on 102dBA.
Professor Blamey agreed that his statement that the acoustic limit for speech for the M15D in the measurements performed at Plantronics was 95dB SPL at DRP was based on Mr McNeill's test and that he was not aware of any other test "for acoustic limit for speech" for the M15D that had been performed for this litigation.
He also agreed that the only tests for the output levels for the devices were those of Mr McNeill and Mr Dickson.
Polaris claimed that Dynamic could have done a "fair" test by setting both devices to TT4 limiting settings or TT4+5dB.
In this connection it relied on an email from Trillium (Mr Hecker) to Plantronics (Mr Gherbaz) of 20 April 2005 in which Mr Hecker expressed "concern" that Plantronics was "trying to benchmark against something that isn't TT4".
Mr Hecker said he had tested SoundShield to TT4 and it appeared to be "behaving properly".
Polaris also relied on an email from Mr Dickson to Mr McNeill of 29 April 2005 which disclosed that the former was "currently finalising two versions of Tecate/Xenica software".
One was M15D version 1.10a to compete with SoundShield on non-Telstra setting, and the other, version 1.10b, to compete with SoundShield "for full TT4 compliance test at Trillium".
On this basis Polaris contended that Dynamic could have done a test comparing like with like, but chose not to.
This, it said, left the reader of the report to infer that the lowest limiting setting was the same for each device, when it was not.
That was what was misleading about the report.
In this same connection Polaris relies on Mr McNeill's evidence in cross-examination.
He was asked what he understood Mr Hecker meant in the 20 April 2005 email that Plantronics was "trying to benchmark against something that isn't TT4".
He replied: 
 
 this comes back to the relaxation of the space that Polaris had negotiated with Telstra, and if we were benchmarking our product with a limiting profile of TT4 against SoundShield, with a limiting setting of TT4+5, then they wouldn't match.
They wouldn't be a fair benchmark.

 

 Dynamic propounded three reasons for rejecting Polaris' case.
The first was that "both devices were set at the lowest limiting setting", which meant that the volume of the sound heard by the listener was least restricted by the devices.
It is true that SoundShield was set to its lowest limiting setting of 95dB and that M15D was set to its lowest limiting setting of 102dB.
However, Polaris' grievance is that the report misleadingly represented that the two devices were set to the same lowest limiting setting, when they were not.
As appears above, I have concluded that they were set to different settings.
Dynamic's second reason for asserting that Polaris' claim must fail was that both devices were set to the lowest setting each was capable of giving for speech, namely 95dB, which on both is the point at which their speech limiting capacities commence to operate.
As I have found, the devices were not set at the same 95dB setting.
Dynamic's third reason was that both devices were tested by measurement of their sound output level at 91.4dB SPL at DRP (M15D) and 91.7dB SPL at DRP (SoundShield) in the conditions used, the effect of which was that the sound used was below the sound limiting capacities in each device.
This contention is based on Mr Dickson's measurements of December 2005 and his supporting graph.
As appears from what I have said at [99], Mr Dickson, as he conceded, was measuring outputs and not the acoustic limits of the devices.
Dynamic's third reason is itself predicated on a sound output level measurement.
Dynamic's other related submissions founder on the failure to distinguish between maximum sound outputs and acoustic limits.
Polaris' complaint relates to the latter.
The admitted representation is that the testing of the two devices at their lowest limiting settings provided an appropriate comparative basis for testing for intelligibility of speech.
The representation is said to be misleading because the lowest limiting setting at which SoundShield was tested was significantly lower than that for M15D.
This does not involve a comparison of maximum sound outputs, but of acoustic limits.
Thus Dynamic's assertion that Mr Dickson's evidence that both devices produced the same level of sound to listeners rebutted Polaris' contention that the M15D was tested at a higher volume than SoundShield, does not meet Polaris' point.
Similarly, Dynamic's concluding submission that Polaris has failed to establish that the devices were tested "at unequal volumes" also misses the point, based as it is on Mr McNeill's and Mr Dickson's tests of sound outputs.
Plantronics relied on a passage in Mr McNeill's second affidavit in which he said that from his role in leading the design team for the M15D, he was aware that "the limiting regime provided for by limiting mode 3 causes the 125ms RMS speech average for the M15D to be limited to 95dB SPL at the drum reference point".
Mr McNeill provided no reasoning or explanation to support this bald assertion.
He was not in this affidavit relying on his February 2008 test, which had since his earlier affidavit been subjected to criticism by Mr Fisher.
In Cadbury Schweppes Pty Ltd v Darrell Lea Chocolate Shops Pty Ltd [2007] FCAFC 70 ; (2007) 159 FCR 397 at [108] the Full Court said: 
 
 unless a witness states in his or her evidence in chief the grounds and reasoning that have led to the opinion, the opinion is valueless.
Before the Court can assess the value of an opinion, it must know the facts on which it is based.
If the opinion is based on irrelevant facts or facts that are clearly not going to be proved, the opinion is likely to be valueless.
It should not be for a cross-examiner to endeavour to elicit the facts or assumptions upon which an opinion is expressed, and it would be unfair to leave such matters to the cross-examiner.
Except in a straightforward, uncomplicated case, where the facts are admitted or otherwise readily identified, opinion evidence would normally be rejected under s 135 if the facts or assumptions upon which the opinion is based are not expressly stated.

 

 
 
 It is for the Court to judge the reliability of, and the weight to be given to, particular evidence.
Opinion evidence, like any other evidence, must be comprehensible and reach conclusions that are rationally based.
The process of inference or reasoning that leads to conclusions ought to be stated or revealed in a way that enables the conclusions to be tested and a judgment to be made about their reliability and the weight that should be given to them.

 

 Polaris urged me to attach no weight to Mr McNeill's statement of his "awareness".
This is far from being a "straightforward, uncomplicated case", and the evidence in issue is of central importance to the lowest limiting setting issue.
Mr McNeill's assertion amounts to no more than that he knows something because of his expertise.
I attach no weight to the assertion.
Loudness and intelligibility
 The difference between the two limiting settings was relied on by Polaris to show that louder sound was being heard on the M15D, which would have enhanced intelligibility compared with the sound heard at a lower level on SoundShield.
Polaris relied primarily on Professor Newell's evidence to establish this.
In his initial report (3 November 2007) Professor Newell said that a device set to an acoustic limit of 100 or 102dBA SPL at DRP will result in "potentially better speech intelligibility ... especially in background noise" than one set to "an average maximum of 95dB SPL at DRP" (presumably 95dBA SPL at DRP).
Polaris' solicitors later asked him whether, assuming everything else about the two devices was the same, the difference in speech intelligibility would be significant.
His answer was that, if three conditions were met, it would be significant.
The first was that the two devices were identical in all respects other than the acoustic limiting level.
The second was that the devices were driven to a level in which there was significant limiting of the speech by the device with the lower acoustic limit.
The third was that the background noise in the room and on the line was of a significant level.
Professor Newell's answer is theoretical and unhelpful.
He makes no attempt to apply it to the facts of the case.
Polaris did not point to any evidence that Professor Newell's first condition was satisfied, namely that the two devices were identical in all respects other than the acoustic limiting level.
Indeed the evidence disclosed many respects in which they differed.
The only matter it relied on in relation to the second condition was that in the comparison report test both devices were in limiting.
That does not establish that SoundShield was driven to a level at which there was significant limiting.
After all, the SoundShield setting was the least limiting setting.
As to the third condition, Professor Newell did not identify the level at which background noise becomes significant.
So we are left with Professor Newell's default position (where the conditions are not satisfied) that a device set to 100 or 102dBA will not result in significantly better speech intelligibility than one set at 95dBA.
The difficulty with Polaris' case on this point is that it did not carry out a test of the two devices with speech input, and thus was unable to show whether there was "significant limiting" of SoundShield, or more generally whether intelligibility in fact increased as a result of M15D's extra 7dB.
The respondents relied on Mr Fisher's test of January 2006 to show that a 5dB difference in limiting in SoundShield MK1 had no effect on intelligibility in test conditions.
The results of the test using ten subjects is shown in the table below: 
 Noise level = 55 dBA Noise level = 65 DBA
 
 TT4 General TT4 General Subject # % Correct % Correct % Correct % Correct 1 97 97 100 93 2 100 93 100 97 3 90 93 90 93 4 100 93 100 97 5 100 87 100 93 6 90 97 97 97 7 90 90 93 97 8 90 97 100 100 9 100 97 93 100 10 100 97 97 100 Average 96 94 97 97 
 Table 1.
Speech intelligibility scores for
SoundShield MK1 (% correct)
 
 "TT4" in the second and fourth columns indicates limiting of 90dB and "General" in the third and fifth columns indicates limiting of 95dB.
If it were correct that an extra 5dB enhances intelligibility, one would expect that to be shown by the table.
Instead, in the test done with a noise level of 55dBA, the average percentage correct at 95dB is lower than that at 90dB, and with a noise level of 65dBA, the average scores are the same.
Mr Fisher's evidence contradicted the proposition that hearing a louder sound on the M15D would have enhanced intelligibility.
He rejected the proposition put to him in cross examination that "for the purpose of providing the best speech intelligibility, a louder sample will be more intelligible than a softer".
He agreed that one reason for this was that the louder sample may be distorted by the device that is reproducing the sound.
He also said that as sound gets louder and louder, the listener doesn't understand it as well; that is to say, intelligibility decreases.
His opinion was that speech intelligibility is best at a speech level of around 73dBA in the free field.
If there was background noise of 55dB, intelligibility would be best at 67dBA.
The topic was not touched on in re-examination.
Polaris submitted that Mr Fisher was dealing with face to face and not telephone conversation.
His reference to distortion shows that he was initially dealing with telephone conversation.
Then he shifted to face to face (free field) conversation.
But it is apparent from a reading of ensuing responses that Mr Fisher was making the loudness point in relation to speech generally, and not limiting it to face to face conversation.
Mr Guest's evidence was not entirely consistent.
In his second affidavit he said he had listened to SoundShield set at each of its different limiting settings, all 5dB apart.
He said a five dB increase was clearly noticeable.
Even with all other settings appropriately adjusted, SoundShield's intelligibility improved each time the acoustic limit was increased.
The 95dB setting was the one easiest to hear with.
The account Mr Guest gave in cross-examination about the test he carried out was to a different effect.
Here he said he listened to the M15D and SoundShield and "the M15D sounded louder to me".
When pressed as to why he had not mentioned this comparative test in his affidavit (which referred only to testing SoundShield), he departed from the claim that he had listened to M15D as well as SoundShield.
It was put to him that he had not in fact listened to M15D to make a comparison.
He replied that he made the comparison "based upon knowing that SoundShield had an absolute limit of 95dB and either the testing of Fisher at 102 and/or the published information of Plantronics".
He ultimately accepted that his opinion about intelligibility was simply based on two numbers --- 95dB and 102dB and nothing else.
Mr Guest's evidence was unsatisfactory.
He claimed to have conducted a test that he had not in fact carried out.
His evidence does not establish that the 5dB difference between SoundShield and M15D increased the intelligibility produced by the latter.
Mr Guest is not an expert in speech, audiology or acoustics, and did not pretend to be.
On the other hand, Professor Newell is an expert audiologist, and Mr Guest's evidence cannot be used to fill the gaps caused by Polaris' failure to satisfy the conditions attached to Professor Newell's opinion.
I accept Mr Fisher's evidence that loudness does not necessarily increase intelligibility, and Professor Newell's evidence that it does so only if certain conditions are satisfied.
There is no evidence that they were satisfied.
However, even accepting the test Mr Guest actually did (ie listening to SoundShield alone), it says nothing as to whether a 102dB limit on a different device would be easier to hear with than 95dB on SoundShield.
Mr Fisher's evidence shows that one cannot by extrapolation from 95dB upwards expect to achieve greater intelligibility.
As part of their attack on Mr Guest's evidence the respondents relied on the contents of his email to Dynamic's former Chief Executive Officer, Elaine Saunders, of 16 January 2006.
Mr Guest asked Dr Saunders for the acoustic limiting level for the M15D used in the comparison test.
Mr Guest told her that the 7dB difference between SoundShield's acoustic limit of 95dB and the European version of M15D (Polaris did not have an Australian version) meant that it had the "theoretical potential to be more intelligible than SoundShield, though he doubted that "in actual use it is effectively more intelligible".
In cross examination, after attempts to explain away what he had written, he eventually conceded that what he had said was "true", and that he doubted whether in actual use M15D would be effectively more intelligible as a result of the extra 7dB.
Mr McNeill's statement that SoundShield's limiting setting 1 produced a louder output than settings two, three and four speaks only of loudness, and not intelligibility for speech.
Polaris posed the correct question to Professor Newell: whether the difference in speech intelligibility would be significant in the circumstances posited.
However his heavily conditional answer did not provide the answer Polaris needed.
Nor does Polaris derive assistance from Mr McNeill's observation that if Plantronics was benchmarking the M15D with a limiting profile of TT4 against SoundShield with a limiting profile of TT4+5, there "wouldn't be a fair benchmark".
Again, this opinion was based on Mr McNeill's earlier statement about loudness or output.
Even if he had gone on to relate loudness/output to speech intelligibility, I would have preferred Professor Newell's evidence recorded at [112].
He has had some 30 years experience working and teaching in audiology, including speech intelligibility generally.
I have earlier referred to the respondents' submission that Professor Newell's evidence on certain topics was not that of an independent expert because of Mr Fisher's involvement in the testing.
His intelligibility for speech evidence was not one of those topics.
Professor Newell's expertise in audiology and intelligibility for speech is much greater than Mr McNeill's.
Polaris has not established that the difference between the lowest limiting settings of the devices would have made M15D more intelligible than SoundShield.
Lowest limiting setting - conclusion
 Polaris has established that in the comparison test SoundShield's lowest limiting setting was 95dBA and M15D's was 102dBA.
However, it has not established that the difference between the two settings made speech heard through the M15D significantly more intelligible than that through SoundShield.
Thus it has not established that the testing of the two devices at their lowest limiting settings provided an inappropriate comparative basis for testing intelligibility of speech.
To use the language of Polaris' submission, the 7dB difference did not confer a relevant "benefit" on the M15D.
The same applies to Mr Fisher's 5dB difference.
Ethics approval representation
 The representation, which is admitted by the respondents, is that the research that resulted in the comparison report was covered by ethics approval from the Ethics Committee.
Polaris contends that this was misleading because the research was not covered by ethics approval.
The confidential particulars provided throw no light on why the research was not covered.
Polaris propounded this claim on the basis that the research was covered by ethics approval, but the approval was obtained by amendment after publication of the comparison report.
In my view this claim has no substance.
On 11 June 2003 Dynamic applied for ethics approval for "investigations with digital signal processing strategies in audio applications for normally hearing listeners and individuals using hearing aids".
On 7 July 2003 approval was granted.
The project was given the number 03/529H.
The approval letter stated that the Committee required an annual progress report, and that any proposed amendments to the protocol that accompanied the application required its approval.
A final report was required at the conclusion of the research.
On 23 June 2006 Dynamic wrote to the Committee stating that it would like to use university students in the listening experiments and pay them a fixed hourly rate.
It asked the Committee to confirm that the recruitment of normally hearing listeners in this way was acceptable.
On 27 July 2006 the Committee replied requesting clarification of the purpose of the tests on normal hearing volunteers and why they were to be conducted.
On 30 July Dynamic provided the information sought.
On 10 August 2006 the Committee wrote to Dynamic as follows: 
 
 I am writing in response to your request for an amendment for the above project.

 

 
 
 Your letter of 30 July 2006 makes clear the aims of the project, and is consistent with your original application.
The letter, however, does not mention the type of study that was recently brought to our attention by your legal advisors, Griffith Hack.
That study compared two competing commercial devices, and there was an implication that the results would be used in the marketing of those devices.

 

 
 
 The Committee has requested further clarification of this part of the project before approving the amendment requested.

 

 By letter of 18 August 2006 Dynamic informed the Committee of the comparison report, Polaris' complaint that the report was misleading and that the study was not covered by project 03/529H.
Dynamic said that "the most effective way for us to counter" would be to have a letter confirming that it did have cover for the study.
On 25 August 2006 the Committee informed Dynamic that the testing of a variety of devices using normal hearing subjects was covered by the approval for project 03/529H.
Later on the same day Dynamic emailed the Committee thanking it for the response, and posing another question: 
 
 It is our opinion that the research study in which normally hearing listeners compared speech intelligibility and sound quality judgments for the SoundShield and the M15D devices, that was conducted in 2005 by the investigators listed in the application and reports for Project 03/529H falls within this scope.
Do you agree?

 

 The Committee's response on the same day was in the affirmative: 
 
 That particular component of the study was covered by the HREC approval for the abovenamed study.

 

 The above account discloses that there was no amendment or change to the project.
There was no retrospective approval of the study.
The Committee's final communication makes clear that the study specified in Dynamic's letter of 25 August 2006 was covered ab initio by the approval granted in 2003.
Polaris drew attention to the fact that Dynamic had not replied to the query raised in the Committee's letter of 10 August about the results of the study being used in the marketing of the two competing commercial devices.
Dynamic's letter of 18 August explained the litigation context, and asked for a letter confirming that it did have approval for the study.
The Committee was obviously satisfied with the response, and provided two letters of approval.
Polaris has not established that the ethics approval representation was misleading or deceptive.
Test set up representations
 Dynamic admits the representations.
Plantronics denies them.
However, in its closing submissions Plantronics said that in view of Dynamic's admissions, it would make no submissions on whether the representations were made.
In par 6 of the statement of claim Dynamic is alleged to be the publisher and distributor of the comparison report.
Plantronics is alleged to have requested and approved the publication.
I find the representations were made.
Receive gain setting --- input signal
 The receive gain setting adjusts the level of amplification of the incoming signal, so that lower level signals are made louder and higher level signals are reduced.
This is done in order to improve intelligibility.
Both Mr Fisher and Mr McNeill likened receive gain setting to a motor vehicle's gears, with SoundShield being a manual car with three gears (LOW, MID and HIGH) and M15D an automatic.
The appropriate receive gain setting depends on the input signal to which the device is exposed.
Acoustic shock protection devices are installed between the telephone and the headset of the call centre operator.
The input signal to a device is the output signal from the telephone.
It was Polaris' case that exposing SoundShield to a higher input signal than that for which it was programmed causes distortion which in turn decreases intelligibility.
Polaris' Administrator Programming Manual (Manual) describes the device's settings by reference to the type of telephone in use rather than as a particular measured output in millivolts.
Five telephones are listed in Appendix 1, all with the MID receive level.
The Manual states that if the receive setting for the host equipment is not listed in the Appendix, the setting must be tested and created.
In other words, there is no general mode setting for non-listed host equipment.
Mr Fisher's evidence was that the LOW setting was designed for input signal levels up to about 15mV, the MID setting for signals up to 40mV, 50mV as a maximum, and the HIGH setting for signals in excess of 50mV up to 272mV.
Mr Thompson's evidence of average inputs was 12mV for LOW, 33mV for MID and 80mV for HIGH.
The comparison report testing was done with a 100mV input signal.
There is no evidence as to the basis for the selection of this signal.
Professor Blamey said Dynamic used the MID receive gain setting for the SoundShield, based on information received from a call centre the name of which he provided on a confidential basis.
His evidence was not clear, because he also referred to an email which stated that the appropriate setting "varies by agent", the agent being the operator.
He also said that the information as to the MID setting "may have come from another source or an additional source to this".
It is not clear whether "this" referred to the call centre or the email.
Professor Blamey accepted that when the comparison test was done, Dynamic did not know what Polaris' recommendations were in relation to the receive gain for the input signal used.
Mr Gherbaz explained what was meant by "varies by agent".
He said that at this particular (confidential) site the agents had a number of headsets, and as they moved from desk to desk, the supervisor would reprogram the SoundShields, and so "there was quite a bit of variation from setting to setting from SoundShield to SoundShield".
Mr Gherbaz also said that he did not know the receive gain setting for this particular customer.
Mr McNeill gave evidence on a confidential basis of global studies that led Plantronics engineering community worldwide to select an input that supported Dynamic's selection.
However he did not say that was why the 100mV input was selected for the comparison test.
Clause 5.3.2 of TT4 lists several telephones whose requirements "are to be accommodated by an acoustic protection device".
They include Nortel P-phones, Exicom BT450 and Alcatel TF200.
Polaris arranged for Trillium to test the Nortel P-phones.
Mr Thompson converted Trillium's measurements of the output of the phones to millivolts --- between 33 and 36mV.
Mr Fisher carried out a similar test of the Exicom and Alcatel phones and found that their speech signal level was typically 25mV.
Professor Blamey took issue with this measurement on the ground that it assumed, without justification, that the output of handsets can be compared directly to the output of headsets.
He did not explain why this was so, or what a proper "indirect" comparison would show.
I attach no weight to this unhelpful evidence.
Mr Fisher said that the 100mV signal used by Dynamic was a particularly high input signal level, and that if SoundShield was exposed to that signal the most appropriate receive gain setting would be HIGH, as that would moderate the high input signal and avoid distortion of the signal which causes decreased intelligibility.
Professor Newell said while the 100mV input used by Dynamic was within the highest level of the specification in TT4 (see Table 5.9), it was generally recognised that such a level was unrealistic and never encountered in call centre equipment.
He was asked on what he based that opinion, and responded: 
 
 I base my view on data on receiver sensitivities (ie the sensitivity of the speakers in headsets and handsets).
This data is relevant because the SoundShield connects to either the headset or handset part of a telephone console in place of a direct connect headset or handset.
Headsets and handsets produce high sound levels when speech signals with an average level of 100 mV are applied to them.
Michael Fisher has calculated this average speech level to be equivalent to around 89 dBA SPL in the field which is well in excess of the average speech level people in call centres listen to which was found to be 77 dBA by Patel and Broughton.
None of the headset users in the Patel and Broughton study listened at a level as high as 89 dBA SPL in the field.
It is the fact that people do not (or very rarely) listen to speech at these high average sound levels (ie 89 dBA SPL in the field) that tells me the input speech signal level (ie 100 mV) into these devices that causes such high sound levels is not being applied.

 

 The respondents relied on Table 5.9 in TT4 to justify the selection of the 100mV input.
It is a complicated document which is prefaced by the explanations in clause 5.2.8 --- "Levels at Input to Limiting Amplifier" which is in part as follows: 
 
 The limiter/headset combination must accommodate the signal levels at the interface to a typical range of CPE.
...
It is essential that correct operation be achieved with the typical range of inputs from the various CPE as tabulated below.

 

 
 
 The unit will perform within specification for the range of levels below.
This may be achieved by the use of internally settable controls or by other means as determined by the manufacturer.

 

 
CPE stands for Customer Premises Equipment.
The table, part of which is rendered below, includes columns dealing with "Level at input to limiter".
Column 1 deals with CPE with low level output to limiter input.
Column 2 deals with CPE with mid level output to limiter input.
Column 3 deals with high level output to limiter input.
The introductory column describes the material in the numbered columns: 
 (Col 1) (Col 2) (Col 3) Long Term Max Active Speech ... 192mV RMS 272mV RMS 700mV RMS Long Term Mean Active Speech ... 48mV RMS 68mV RMS 175mV RMS Long Term Min Active Speech ... 12mV RMS 17mV RMS 44mV RMS 
The description of the table located at its foot is:
 
 
 Table of amplifier input levels available at the headset or handset port of the typical range of CPE.
CPE introduces a variable level between the input from the network and the port to which the amplifier is connected.
To be able to function with a range of CPE the amplifier/headset combination must have a range of settings, which can accommodate the level and wire function requirements.
The settings to accommodate the various CPE must be internal settings, which are not accessible in day to day operation ... Note: Column 3 requirement may not be required.
Check with Product Manager.

 

 Professor Blamey's position was that because 100mV was within the range in the table as being typical ranges for telephones in use in Telstra's call centres, it was appropriate to have selected it as the input level.
He also said that because it was also within the range of all three columns (low, mid and high), the choice of the particular setting was "not particularly crucial".
In his oral evidence he expressed the view that the table "suggests that in every setting of the device which is designed to be used with typical telephones in call centres, the device ... should be able to accept 100mV input signal and achieve 90 per cent speech intelligibility with that input signal".
Professor Blamey accepted that 100mV was above the mid point in columns 1 and 2 (the mean or average signal level).
Accordingly, the signal chosen was above the signal specified for the low to mid range for the mean active speech levels.
These levels were what Mr Thompson called the levels "likely to be encountered".
For present purposes the only relevance of Table 5.9 is for the light it throws on input signals used in typical Australian call centres.
The comparison report test was not directed to ascertaining SoundShield's TT4 compliance.
It was not a test constructed so as to be able to do that.
In view of other evidence, the table throws very little light on input levels in fact used in call centres, especially non-Telstra centres.
There was no evidence that the table was used by any call centre or by any manufacturer of acoustic protection devices.
Professor Blamey's evidence about the confidential call centre's settings was confusing and unsatisfactory.
The settings were those identified in the exchange of emails referred to at [196].
They did not include the input signal.
So the 100mV input did not come from the confidential call centre.
Polaris' own evidence was that the table's low, mid and high levels were not the source of SoundShield's three settings.
The only clear evidence about a manufacturer's use of the table is that Mr Fisher consulted it when designing SoundShield, but did not ultimately use it.
His tests at Telstra call centres showed that the input levels encountered were considerably lower than those specified in the table, and accordingly SoundShield was modified to have a higher receive amplification.
There was no evidence that the table was part of Dynamic's decision-making process that led to the selection of the 100mV input signal.
If the table offers any guidance as to inputs in call centres, the mean active speech levels therein would be the obvious ones to apply --- 48mV for LOW and 68mV for MID.
Polaris' experts, Mr Fisher, Mr Thompson and Professor Newell, were clear that 100mV was a much higher input than that typically encountered in Australian call centres, though they did not all come up with the same range as to what was typical.
Mr Thompson said that the relevant figures in the table are those listed against long term mean active speech level for which the table ascribes a value of 48mV RMS as the likely input to a device for low output CPE, and a value of 68mV RMS for mid level output CPE.
He treated the table as stating that the range of likely inputs to devices in call centres was 48-68mV.
Mr Thompson's opinion was based on columns 1 and 2 of the table.
Column 3 deals with "CPE with high level output to limiter input".
It has a footnote that "Column 3 requirement may not be required.
Check with Product Manager".
There was no evidence as to the provenance of this note.
Mr Thompson's conclusion was that a 100mV input signal did not simulate the likely output signal from a telephone in a call centre in practice, which is instead in the range of 33-36mV, and is not within the likely range specified in the table (48-68mV).
Mr McNeill agreed with Polaris' witnesses that the receive gain settings were a matter for determination by the manufacturer.
Professor Blamey agreed that in making decisions about receive gain settings for the comparison test, it would have been very useful to know whether Polaris made any use of Table 5.9 in its settings.
Polaris' Manual disclosed that the HIGH setting should be selected for hosts/consoles with a high output level.
Mr Thompson said that on a 100mV input the HIGH setting was the appropriate one, because on a MID setting there would very likely be overamplification and distortion.
He agreed that he had not done a specific test to establish this, for want of the necessary equipment at Polaris' premises, but said that from measurements he was able to make, he could infer the likelihood of distortion.
In cross-examination he said that if set on MID with a 100mV input, SoundShield would perform less satisfactorily than if set on HIGH.
Professor Newell was of the same opinion.
He explained why: 
 
 A speech signal with an average level of 100 mV is a high level signal for a handset or direct connect headset to be exposed to as discussed above.
As limiting amplifiers are designed to accept the same signal that are provided to headsets and handsets these are also high level signals for limiting amplifiers to be exposed to.
It therefore is appropriate that a limiting amplifier should be set to a HIGH receive setting.
I am advised by Michael Fisher that this is the case for speech signals with average levels greater than 50 mV.

 

 
Asked why he regarded 100mV input as a high level signal, Professor Newell referred to the passage from his report quoted at [144] and said:
 
 
 As discussed above a speech signal with an average level of 100mV will produce very high sound levels (ie 89dBA free field equivalent) from standard handsets and headsets designed to directly connect to a telephone console.
100mV is therefore a high level rather than a normal level from a telephone console.

 

 On the basis of the material summarised at [142]-[143] and [149]-[153] I find that Dynamic selected a high input signal that was not typically used in Australian call centres.
Dynamic should have known from the Patel and Broughton article to which it referred in the comparison report, that 100mV was a high signal level.
Patel and Broughton's measurements at 15 call centres in the United Kingdom showed a mean output of 77dBA, with 70% of the measurement output levels being within the 72-82dBA range.
The maximum measured level was 88dBA.
Professor Blamey said that the mean of the output translated from 100mV to dBA was 84dBA, which he agreed was towards the upper end of the range.
Dynamic was aware of the importance of getting SoundShield's receive gain setting correct.
It did not have a copy of the Manual, which would have disclosed the need for a HIGH setting.
It did not seek to obtain the relevant information from Polaris.
Based on the evidence of Mr Thompson, Mr Fisher and Professor Newell, I find that the average input in typical Australian call centres was between 12 and 80mV: 12 for LOW, 33 for MID and 80 for HIGH.
On an input of 100mV, the appropriate setting was HIGH.
Polaris' case was not simply that an input of 100mV was too high.
It was that if with that input SoundShield was set to the MID receive gain setting, it would be overdriven and would distort, with a consequent deleterious effect on intelligibility.
That would have been avoided had the HIGH receive gain setting been selected.
Has Polaris established that with a 100mV input, SoundShield will be overdriven and distort with an adverse effect on intelligibility for speech?
In his principal affidavit Professor Blamey said that before the test was administered to the eight subjects he inspected the set up of the experiment and checked the equipment as set up.
He also listened to sound output of both devices in the settings that had been proposed and satisfied himself that they were appropriate for the use of both devices in a simulated call centre environment.
Professor Blamey elaborated on this in the course of cross-examination.
It was put to him that he had not done a pre-test for intelligibility.
He disagreed: 
 
 The test I did, involved actually going through the whole protocol, so I listened to both devices, and the words that I heard were scored in the normal way.
So that could be interpreted as a pre-test for intelligibility.

 

 
He said his scores had been recorded, but he no longer had the data.
He went on to say that the two devices were "very similar in loudness": one was slightly louder, though he had no way of knowing which it was.
In re-examination he repeated that before the subjects were tested he sat in the booth and the protocol was run through with him.
He agreed that: Many other tests, comparative and non-comparative, were in evidence.
Most of them were more or less readily distinguishable from the Dynamic comparison test.
The one test that cannot thus be put aside or distinguished is Professor Blamey's pre-test for intelligibility.
Obviously he used the same test set up as the eight subjects.
Although he was not asked about distortion, I infer from the fact that both devices appeared to be working, that he didn't hear anything to suggest that one was very different from the other, and that they were of similar loudness, though one was slightly louder, that there was no apparent distortion.
I have taken into account that Professor Blamey has an interest in the outcome of the case, but I cannot reject his evidence on that ground alone.
I have earlier said that I regard him as a witness of truth.
He said it was standard practice to test the equipment prior to an experiment.
While Polaris criticised Professor Blamey's recollection of facts and detail as "unreliable", it did not attack his credit.
It was not put that he had not carried out the pre-test for intelligibility or that he had fabricated the results of his experiment.
In any event, I accept that he did test the equipment and found it to be in working order.
I infer from the fact that he didn't hear anything to suggest that one device was very different from the other, and that they were of similar loudness, that neither was distorting.
In contrast to Professor Blamey's practical experiment, Polaris' expert evidence was largely of a theoretical character.
As indicated at [155], Mr Thompson's opinion that there would "very likely" be overamplification and distortion of SoundShield with a 100mV input on MID, was not based on any test to measure distortion on that input and that setting.
Nor had he done any measurements that would demonstrate that SoundShield was capable of accepting a 100mV input set on HIGH.
He said both those measurements could have been carried out, but Polaris did not have the necessary facilities for that to be done at its premises.
He said that distortion is a well known effect which is measurable using a Distortion Analyser or a Spectrum Analyser, which he had used extensively to measure signal distortion in acoustic shock protection devices.
The tentative nature of Mr Thompson's evidence on this issue is apparent from the following exchange in cross-examination: 
 
 And is it your view ... that if a 100 millivolt input voltage is used for SoundShield on the mid receive level, that the SoundShield will not perform satisfactorily?
--- No, that's not correct.

 

 
 
 It is your view that if the SoundShield receives an input signal of 100 millivolt when it's on its mid receive level 2 it will perform satisfactorily?
--- This goes to the question of what you mean by 'satisfactorily'.
...
 ...
The question I've asked is whether or not the SoundShield, if it receives a 100mV signal when it's set in receive level 2, the mid receive setting, whether it would perform satisfactorily with that input voltage?
--- Less satisfactorily than compared when used in the high receive gain setting.

 

 Professor Newell spoke generally about overdriving (too high a signal), saying that its effect is that the device will distort the signal resulting in a reduction in the intelligibility of speech.
Applying that to the present case he said it was "reasonable to suggest" that SoundShield's poor intelligibility result was due to overdriving which caused it to distort the signal.
In cross-examination Professor Newell said that if he had put in a 100mV signal, it would have been necessary to see whether SoundShield was being overdriven.
By this I took him to mean that it would have been necessary to carry out an appropriate test, perhaps using one of the analysers of which Mr Thompson spoke.
Mr Fisher's opinion that if SoundShield was exposed to a 100mV signal, the most appropriate receive gain setting was HIGH, as that would moderate the high input signal and avoid distortion causing decreased intelligibility, was theoretical.
He undertook no test with a 100mV signal on the MID setting, though he agreed he could have done this.
He relied on two matters for his opinion.
The first was his controversial interpretation of Mr McNeill's 2008 test.
The second was that he knew what SoundShield sounds like with an input level of 100mV, though he had not performed a test with subjects.
He said "I know what it sounds like and it doesn't sound good".
Otherwise he simply asserted, based on "lots of ... knowledge in this area", that there is overamplification with a 100mV signal.
Based on Professor Blamey's personal test carried out immediately before the comparison test with subjects, which is more persuasive than the Polaris evidence recorded at [166]-[168] for the reasons there given, I have concluded that Polaris has not established that at a 100mV input on MID receive level SoundShield is overdriven and distorts.
It was common ground that the relevance of distortion for present purposes lies in its adverse effect on speech intelligibility.
On that finding I am unable to hold that the test set up representations were misleading or deceptive or likely to mislead or deceive for any of the reasons alleged in par 10I of the statement of claim to the extent those allegations depend on the input signal used.
I have considered whether, despite the above finding, I could uphold the contention in par 10I(b) that the test conditions were not an accurate reflection of the conditions experienced in call centres, based on the evidence, which I have accepted, that input signals of 100mV were not encountered in call centres.
However, I consider par (b) to be a composite plea --- that as a consequence of the test conditions not accurately reflecting call centre conditions, the test conditions were biased to favour M15D.
This reading of par (b) is supported by the companion allegation in par 10H(b) that the report represented that the test conditions were not biased to favour one device over the other, "but instead were an accurate reflection of the conditions normally experienced in call centres".
Polaris' counsel drew attention to the unsatisfactory nature of the pleadings in this respect, but the matter was not otherwise addressed in submissions.
Headset profile
 Polaris' claim here is that headset profile 1 used in the comparison test should have been profile 18 as referred to in the Manual.
The Manual contains this information about "Headset Model Configuration" upon which Polaris relied: 
 
 The Headset Model Configuration is used by SoundShield to select a frequency response filter for each supported Headset Model used in SoundShield.
These filters are more commonly known as Head Profiles.

 

 
 
 NOTE: Each time a new Headset Model is plugged into SoundShield, the equivalent Headset Model Profile must be changed in SoundShield.

 

 
 
 See Appendix 2 of this document for Headset Models and the corresponding Digit LED setting.

 

 
 
 Headset Model profiles will assume values between 0 to 18.
This will accommodate a possible 18 different headset models.

 

 
Appendix 2 sets out profile model numbers for various headset models.
The only two numbers presently relevant are 1 for Plantronics H51 headset model and 18 for Telstra's TT4 model H51-TT3.
Polaris says the proper selection of the headset profile was acknowledged by the respondents to be an important issue.
Its case is that Dynamic used the H51-TT3 headset in the test using profile 1.
According to Polaris' Manual, the correct setting for that headset is profile 18.
Profile 1 was to be used with headset H51 and not for H51-TT3.
The former was for use in the general market and the latter for Telstra call centres.
The evidence of Polaris' own witnesses, Mr Guest and Mr Thompson, does not support this complaint.
Mr Guest accepted that profile 1 was correct for the general 95dB (non Telstra) setting.
He said "We could not deliver profile 18 to the general market because of the special acoustic limiting that Telstra wanted, which is lower than the Australian Standards".
The "special acoustic limiting" is of course 90dB as opposed to 95dB.
Mr Thompson agreed that when used in the general mode (95dB) the Plantronics H51-TT3 headset is set to profile 1, and on the 90dB setting, to profile 18.
That, he said, was because Telstra requires a greater limiting setting of certain frequencies likely to be encountered.
Mr Fisher maintained his stand that profile 18 was the correct profile.
He was unswayed by Mr Guest's and Mr Thompson's evidence.
He was clearly unhappy with the latter's evidence that if SoundShield was not to be used for Telstra, profile 1 should be used.
He did not want to say Mr Thompson was wrong.
Instead he said it was not for him to "pass comment on this", and that what Mr Thompson had said was "just poorly expressed".
I do not accept Mr Fisher's evidence on this point.
Polaris did not carry out any test with the H51-TT3 headset on profiles 1 to 18 so as to show that there was a difference between them for intelligibility.
Nor was there any evidence that the profiles were relevantly different.
There was no evidence of differences between the H51 and H51-TT3 headsets showing that they needed different profiles.
Plantronics, the manufacturer of both headsets, said through Mr Gherbaz that there were no significant differences between them: they were "in effect the same headset with the same speaker, although H51-TT3 has slightly higher production tolerances".
Mr Fisher agreed that the two models were the same except that "the manufacturing tolerances on H51-TT3 are narrower".
On the basis of Mr Guest's and Mr Thompson's evidence, I find that in general (non-Telstra) use, the correct profile is profile 1, which was that used by Dynamic in its test.
Relating this to the allegations in par 10I of the statement of claim, the position is that: 
(a) 10I(a) --- the comparison test used the correct headset profile 1
 
(b) 10I(b) --- the test was an accurate reflection of conditions experienced in call centres in that the headset profile matched the conditions likely to be encountered in call centres in the general market.
Use of profile 18 would have meant that those conditions would not have been reflected
 
(c) 10I(c) --- SoundShield was appropriately set up for test conditions in that the correct headset profile was used for the chosen headset in a call centre likely to be encountered in the general market
 
(d) 10I(d) --- there was no factor in connection with the headset profile to suggest that the results of the test were not an accurate reflection of the relative performance of the two devices in call centres.
SoundShield's proven record
 The fact that SoundShield had a proven record of acceptable performance in call centres would not, by itself, demonstrate that the test set up representations were misleading for any of the reasons alleged in par 10I of the statement of claim.
It does however lend support to other findings of misleading representations.
Commercial arrangement between Dynamic and Plantronics
 Polaris relies on the existence of this relationship, which covered the development and sale of the M15D device, to establish that the test set up representations were misleading.
It is not pleaded that the arrangement between the respondents was not disclosed.
In my view the mere existence of the arrangement, which Polaris pleads in par 5 of the statement of claim and repeats in its particulars, could not establish that the representations were misleading.
The comparison report disclosed that: In my view the intended recipients of the report, namely call centre and OHS managers contemplating the purchase of acoustic protection devices, could not have been misled in any relevant way by the mere fact of the disclosed relationship.
In and of itself, it does not provide a basis for finding that the test was not properly designed, that SoundShield was not properly set up, that the test conditions were not an accurate reflection of a call centre environment, or that the test results were not an accurate reflection of the relative performance of the two devices.
Polaris also claimed, though not in its pleadings, that the report made no sufficient disclosure of the commercial arrangement between Dynamic and Plantronics, in that the report did not disclose the existence of an agreement between them under which Dynamic derived a direct financial interest in sales of the M15D units.
The content of the agreement is confidential and I will record more about it.
Given the state of the pleadings, I need not deal with this claim of inadequate disclosure.
July 2005 comparative testing
 This testing was done by Plantronics.
It was conducted in a call centre.
Polaris claims that it demonstrated that there was "very little difference between the responses for the two units".
The result of the tests is described by Mr Shilton of Dynamic in an email to Mr Gherbaz of 8 July 2005.
It is in part as follows: 
 
 We've looked at the trial results and run some statistics.
Overall there is very little difference between the responses for the two units.
This is a good result, especially considering that the subjects were all acclimatized to the SoundShield.
We would have expected that people would be strongly biased towards the familiar product.

 

 
 
 The responses for transmit show no significant difference and do not indicate any problems for either device.
The responses to the question relating to receive noise levels indicate that Tecate may be better but the difference was not great enough to be statistically significant with only twelve subjects.
Both units were rated similarly in relation to protection against loud sounds.

 

 
Mr Shilton then told Mr Gherbaz about Dynamic's intelligibility test:
 
 
 Intelligibility testing of the two units under controlled conditions (including controlled volume settings) indicates that Tecate has significantly higher intelligibility in noise.
Blind A/B comparisons also indicated that Tecate is perceived to be louder (results attached).

 

 
The comparison report was not distributed until the end of July, some three weeks after the email.
The respondents point out that the nature and circumstances of the July 2005 test were different from those of the comparison report.
The July 2005 test was not a test in controlled conditions as was the comparison test.
The users tested were accustomed to their existing devices, and call centre operators tended to favour their existing devices.
The number of users tested was small (12 users).
The test used ratings rather than percentage correct items.
With only 12 users asked a single question about sound quality, only 12 data points are collected compared with 400 in the Dynamic test.
In an uncontrolled environment, context assists with intelligibility because whole sentences are being used, rather than random word lists.
The evidence of Mr Gherbaz and Professor Blamey, which I accept, establishes these differences between the circumstances of the July 2005 and the comparison test, and justifies the conclusion that the result of the former does not of itself show that the latter was misleading in any of the respects pleaded in par 10I of the statement of claim.
No check before publication
 The allegation here is that Dynamic's belief that SoundShield was "the headset amplifier currently used for acoustic shock protection in the majority of Australian call centres" together with the results of the July 2005 tests, should have led it to have carried out a further test to check its May 2005 results before publishing the comparison report.
It was said that this should have been done because the May 2005 results were "significantly inconsistent" with the "belief" referred to and the July 2005 results.
The "belief" relied on is found in an early draft of the comparison report, though not in the published report.
I accept Plantronics' submission that this complaint is not a particular about the test set up.
Rather, it is a contention that Dynamic ought not to have believed the results of its own testing.
In any event, Dynamic's failure to do a further test before publication could not lead a reader of the comparison report to be misled in any of the ways pleaded.
Polaris' contention to the contrary is bizarre.
No control condition
 Polaris claims that the comparison test did not include any suitable control condition, in that there was no testing without the use of either device to determine whether there was a proper correlation between the use of the devices and the intelligibility responses of the people tested.
Professor Newell gave evidence about the significance of a control condition.
He said: 
 
 A control condition is a standard against which other conditions can be compared in a scientific experiment.
In drug trials it is typically the condition in which the placebo is given.
In this experiment it is the condition that does not involve using the SoundShield device.
It is the reference condition which can be confirmed by others doing similar experiments.
It enables data ... from different experiments to be compared.
If there is a problem in a particular experiment set up or the subjects from a particular experiment are different from another experiment then this will show up in a change in the control condition results.

 

 
After noting that speech intelligibility test results can be affected by factors other than the conditions a tester wishes to evaluate, and giving examples of this, Professor Newell continued:
 
 
 Having a control condition I can compare my results with previous experiments done under the same conditions.
In the control condition the results of this experiment are almost identical to an earlier experiment done under the same conditions several months previously.
In the control condition the average percentage of words correct in the first experiment was 94% and in this experiment it was 95%.
The average percentage of phonemes correct in both experiments was 98%.
The variability in both experiments was very similar the resulting standard errors were 1% in both cases for words and 0.4% (October experiment) and 0.5% (July experiment) for phonemes.
The consistency in the control condition gives a high level of confidence that the experiment is reliably repeatable.

 

 
The earlier experiment referred to is Mr Fisher's July 2007 test.
Dynamic's own protocol for the comparison test did not require a control condition.
Professor Blamey claimed that SoundShield was itself the control condition.
To this Mr Fisher replied: 
 
 the experiment was designed to compare the attributes of two commercially competing devices that were being tested against each other.
The experimenters did not test for baseline performance (eg without any device) and therefore did not know the source of the errors and flaws in their experimental set up.

 

 In cross examination Professor Blamey was taken to a passage in Dynamic's protocol with the Ethics Committee, under the heading "Sound quality experiments", in which it was said that "Experiments will include control conditions without the algorithm applied and experimental conditions with the algorithm applied".
It was put to Professor Blamey that he had represented to the Committee that experiments would be conducted without the algorithm being applied.
His response was: 
 
 In this particular case, we're comparing the effectiveness of one of our algorithms, which is the ADRO algorithm with a device that does not include the ADRO algorithm.
In this condition, the condition without the algorithm was the SoundShield device.
The condition with the algorithm was the M15 device.
In other experiments that had been done under the same ethics approval, there has been one device which included the algorithm and another device that did not.

 

 
While Professor Blamey's explanation may be consistent with the sentence in the Ethics Committee protocol, I prefer the evidence of Professor Newell and Mr Fisher that a control condition is one which does not involve either of the devices under comparison.
In my view it is not appropriate to use a device with a different algorithm as a control to test a particular algorithm.
Accordingly, the comparison test was not a properly conducted scientific test, and the representation that it was such a test was misleading.
Failure to follow test protocol
 It is common ground that Dynamic's test protocol was not followed in the two respects pleaded: there were eight subjects rather than ten, and the results as recorded did not follow the randomisation table.
The representation was that the test was a properly conducted scientific test designed and undertaken with an appropriate level of skill, independence and expertise.
The mere fact of a departure from the protocol does not in my view establish that the test was not a properly conducted scientific test.
Professor Blamey explained why there were only eight subjects.
The particular design that was used required equal numbers of lists and subjects in each condition.
Because there were four conditions, the easiest way to design the test was to use a multiple of four --- either four, eight, twelve and so on.
More importantly, he rejected the suggestion that testing eight subjects was inadequate to be of high statistical significance.
This was because the software package used to do the statistical calculation took into account the number of subjects and the variability of the results, and at the end produced "an estimate of the statistical significance which was highly statistically significant".
Based on that data, Professor Blamey said there was no need for concern.
He agreed that eight subjects was a small sample, but said that even small samples can be highly significant if the difference is big enough.
If "you're looking for a very small difference, then you need more subjects".
That was not the case here; the difference was large enough for the result to be highly statistically significant.
Professor Blamey returned to the statistical analysis in re-examination in response to a question as to why the July 2005 test did not cause him to redo the comparison test.
He responded that there was no occasion to re-test because the statistical analysis indicated that there was a very low possibility that the results would have been obtained by chance if the two devices were actually performing at the same level.
That analysis gave him confidence that a similar result would be obtained if the test was repeated in exactly the same way.
He identified the computer program used to analyse the results statistically --- "Minitab" --- which became an exhibit.
He explained that the program is an analysis of variants, which means that it looks at the variability of the different groups of data.
One of the columns, which is labelled "P", is called the "significance level", or the probability that this particular result would have been obtained by chance.
It showed that the probability that the difference between the results would have been obtained by chance was less than one in 1000.
I accept this evidence, and conclude that Polaris has not established that the fact that there were eight rather than ten subjects had the effect that the test was not a properly conducted scientific test.
Whether the departure from the randomisation regime meant that the test was not a properly conducted scientific test is difficult to determine because of the paucity of evidence as to the object of randomisation and the significance of a departure from it.
Dynamic's protocol is not of much help.
Under the heading "Speech Intelligibility: NAL Phonetically Balanced Word Lists", it says that "Noise levels and starting conditions will be randomised".
Under the heading "Subjective Assessment", it says " all tests are performed in Random Order to test the systems capability of dealing with rapid change".
Later, under the same heading, the protocol says "All noise levels and conditions will be randomly varied and assigned to each participant".
It is not apparent whether the comments under the "Subjective Assessment" heading are relevant to speech intelligibility.
The randomisation table itself is uninformative.
It has a "Key" which might be expected to be explanatory of features of the table.
These include "MI = Male voice 1" and "F3 = Female Voice 3".
However neither appears in the table.
Doing the best I can on the meagre material available, I have concluded that randomisation was an important part of the test.
There must have been some significant reason for including it in the protocol.
The fact that the protocol says that all tests are performed in random order so as to test the systems' capability of dealing with rapid change, suggests that failure to follow randomisation may affect the result of the comparison.
Mr Fisher drew attention to what he described as three deficiencies in following the protocol.
One was that there were only eight subjects.
Professor Blamey gave an elaborate and persuasive response to this.
See [181]-[182].
The second was that there was an error in the calculation of the results.
This was not pleaded, though Professor Blamey explained that its impact resulted in a fraction of a percent change which could not have had a significant effect on the result.
He explained why this was so.
The third deficiency was that it appeared that the testing did not follow the randomisation table.
Professor Blamey made no response to this.
In his lengthy cross-examination on this topic, he conceded that there had been a failure to follow the table.
Unlike his response to the other defects alleged, he did not assert that this failure had no statistical or other significance to the end result.
On the basis of the foregoing matters, I infer that the departure from the table was of sufficient significance to result in the test not being a properly conducted scientific test.
For completeness, I should say that I did not understand Professor Blamey to have contended that the Minitab statistical analysis "cured" any departure from the randomisation table.
Failure to make enquiry of Polaris as to the settings
 This complaint has two related parts.
The first is that Dynamic was unfamiliar with the various settings contained within SoundShield when it conducted the comparison test.
The second is that it did not enquire of Polaris as to the appropriate settings.
In fact Dynamic knew of the existence of the internal settings, but not what to set them to.
By the assertion that Dynamic was unfamiliar with the various settings within SoundShield, I think the pleader meant Dynamic did not know how they should be set.
Polaris relied on a series of emails between the respondents as evidence that Dynamic did not know the proper settings.
Mr Gherbaz and Mr McNeill said that the correspondents were not seeking information for use in the comparison test, but in order to test whether M15D in TT4 mode, using version 6 of the Xenica software, was TT4 compliant.
In order to do this it was necessary to discover the settings actually in use by Telstra.
While Dynamic knew that Telstra's TT4 requirements had been relaxed, it did not know the extent of the relaxation.
Polaris disputed that the respondents' email enquiries about the proper settings were directed not to the upcoming comparison test, but exclusively to other tests as to M15D's compliance with TT4.
If that were true, it said, enquiries would not have been made as to the settings in use at the non-Telstra confidential site.
I do not need to resolve the dispute because, quite apart from the emails, I am satisfied that the respondents did not know all the proper settings before they did the comparison test.
In fact they selected the correct headset profile, but the wrong receive gain setting for the 100mV input signal.
Professor Blamey agreed that he did not know the correct receive gain setting for that signal.
Mr Gherbaz agreed that he did not know the receive gain setting used by the confidential call centre.
Mr McNeill agreed that the respondents had no direct knowledge of the settings in April 2005.
Nevertheless Dynamic carried out the test without either asking Polaris for the correct settings or doing another test on different settings.
Having regard to its incomplete knowledge of the relevant settings, the test set up representations were misleading because the test was not a properly designed and conducted scientific test, SoundShield was not appropriately set up for the test conditions and the results of the test were not an accurate reflection of the relative performance of the two devices in call centres.
As Mr McNeill said: "If you don't know what the settings are, then you probably shouldn't have done the test in the first place".
Subjects tested
 It is common ground that the eight subjects tested were employees of or associated with Dynamic.
Standing alone, this does not establish that the test results were unreliable.
Dynamic's Ethics Committee protocol contemplates that its employees may be used as subjects.
Further, it appears from an article by three of the authors of the comparison report (Ms Wise, Mr Dickson and Professor Blamey) describing the comparative test, that it was a "blind paired comparison" of devices.
That is to say the subjects did not know which device was being used to transmit the test material.
See "Adaptive Range Optimisation for Telephony", Acoustics Australia vol 34 (December 2006) 117.
Professor Blamey said the same thing in his oral evidence.
It was not a double blind test.
The tester knew which device was being tested.
No appropriately trained installer
 This complaint is that the SoundShield device was neither installed nor checked by an appropriately trained person familiar with the Manual and the various SoundShield settings.
What I have said at [198] is applicable here.
Dynamic did not know all the correct settings and did not have a copy of the Manual that would have filled in the gaps in its knowledge.
In those circumstances, to publish a report was misleading in the respects set out at [198].
Unsuitability representations
 Were they made?
These representations are set out at [23].
The particulars claim they are to be implied and arise from: 
(a) Figure 1 and Figure 2 of the comparison report;
 
(b) the statement in the report that "To achieve an intelligibility score of 90% with the SoundShield, the background noise level of the call centres would have to be reduced to an unrealistic level of about 40dBA"; and
 
(c) the statement in the report that M15D is G616 compliant and suitable for TT4 compliant operation and the absence of a similar statement about SoundShield.
SOUNDSHIELD UNSUITABLE FOR USE IN CALL CENTRES
 Would a member of the class of persons likely to read and be influenced by the comparison report understand it as representing that SoundShield was unsuitable for use in call centres because of its poor intelligibility when background noise is present?
The class in question consists of managerial staff contemplating the purchase of acoustic shock protection devices for use in call centres.
They are likely to have a familiarity with call centre conditions and the way they operate.
They will know the types of phone calls their operators receive, and be aware of the phenomenon of acoustic shock and the means of reducing the risk of that shock by the use of devices such as SoundShield.
They are also likely to be aware that SoundShield is commonly used in Australian call centres.
The report states that the test was carried out using the Phonetically Balanced Monosyllable (PBM) word test with typical call centre background noise levels.
The subjects were asked to repeat all the words they heard.
A member of the class of readers referred to above would know that call centre operators do not hear random words.
They hear sentences providing context.
Their minds will deal with the problem of a muffled, distorted or missed word by resort to the context in which it appears.
Potential gaps will thus be filled.
There was evidence to this effect, and common experience of telephone use and conversation in general supports it.
Call centre operators do not hear "scythe", which might in isolation be heard as "size", followed by "pit" which might be heard as "hit".
They hear a whole sentence.
On the above basis, the respondents submitted that a member of the relevant class would not carry away from a reading of the report a representation that SoundShield was unsuitable for use in call centres.
Rather, the reader would take away the actual message of the comparison report, namely that M15D's intelligibility was much better than SoundShield's on the PBM word test administered to the subjects.
Mr Guest did not read the report in that way.
When explaining his initial concerns about it, he focused on the percentage errors in the word scoring with 55 and 65dBA background noise compared with the 90% at 55dBA background noise required by TT4.
He said that with a score of that nature, where the error would be one word in five, "we wouldn't be selling any SoundShields".
Mr Guest's "one word in five" error rate derives from reading the comparison report as stating that at 55-65dBA operators using SoundShield will mishear 18 to 26% of words spoken to them.
That is not what the report says.
Professor Blamey stated the obvious when he explained that the score on a PBM word test does not reflect the error rate for sentences in a call centre environment.
He said that an 80% word score means that users will still be scoring close to 100% on sentences in a typical call centre environment.
Mr Guest would seem to have derived his "one in every five words" error rate from Mr Fisher's evidence to that effect.
Professor Blamey's evidence, which I accept, disposes of his opinion on the error rate.
However this error does not itself mean that the question posed at [202] should be answered in the negative.
Mr McNeill did not read the report as implying that SoundShield was unsuitable for use in typical call centre environments, or that it would be "ineffective" for such use.
While he acknowledged that it stated that SoundShield had performed poorly in the intelligibility comparison, he said the Dynamic PBM word test 
 
 doesn't take into account things like context and, you know, in a call centre there is conversation going on, and so the user is expecting a certain language coming back, and so that helps.
So, you know, people in call centres don't write down word lists.

 

 
Mr Gherbaz also distinguished between call centre conversation and word tests, saying that in the latter there is no contextual information, and "your brain can't fill in the gaps for random words".
Taking into account the characteristics of the class of persons likely to read and be influenced by the comparison report, I am of the view that a member of the relevant class would take away from the report that the authors were stating that SoundShield was unsuitable for use in call centres because of its poor intelligibility when background noise is present.
It is true that the report concerned a PBM word test, and that call centre operators deal with conversation which provides a context that word lists do not.
Nevertheless, the passage relied on in particular (b) at [201] transposes a word test based result into a call centre environment, and uses that result for the conclusion that for SoundShield to achieve 90% intelligibility, the background noise level of the call centre would have to be reduced to an unrealistic level.
I do not agree with Plantronic's submission that the report's statement that SoundShield is commonly used in Australian call centres is inconsistent with an implication that the device is not suitable for such use.
In its particulars Polaris also relies on Figures 1 and 2 in the report which are set out below.

 
 
 The extrapolation in Figure 1 is a pictorial representation of the sentence "to achieve an intelligibility score of 90% with the SoundShield, the background noise level of the call centres would have to be reduced to an unrealistic level of about 40dBA".
There was a faint suggestion by Polaris that the dotted line in Figure 1 could be read as representing an actual measurement.
In my view no attentive reader of the relevant class would read the Figure in that way.
The text describes the dotted line as an extrapolation of the PBM results .
Mr Fisher and Professor Blamey disagreed as to the significance of the extrapolation in Figure 1, made by the dotted straight line to show a correlation between increasing intelligibility score and reducing background noise.
In his first affidavit Mr Fisher described the extrapolation as "linear", and said it was accepted in the scientific literature that it is incorrect to linearly extrapolate percentage correct scores and noise levels, because this is a non-linear function.
In response, Professor Blamey referred to Figure 6.6 in TT4 which shows intelligibility as a function of noise level.
He said that in its extrapolation Dynamic approximated the relationship as shown in that figure with a straight line over a 10dB range of background noise level.
He said that if Dynamic had used the non-linear function in Figure 6.6, this would have been to the disadvantage of SoundShield.
In order to achieve 90% speech intelligibility, the background noise would have had to be reduced even lower than 40dBA.
Replying, Mr Fisher said resort to Figure 6.6 was "completely inappropriate" because it related to face to face conversation and not to the situation in which there is "monaural presentation of band limited, equalised and amplitude compressed speech".
In his third affidavit Mr Fisher explained further why in his first affidavit he said a linear extrapolation was incorrect.
He said one needs to consider the extremes of noise levels to realise that a linear relationship is impossible.
Once the noise becomes inaudible, no further reduction in its level will improve speech intelligibility, and once the noise is so great that it has made the speech inaudible, the speech intelligibility score will fall to zero and no further increase in the noise level will reduce the performance.
Professor Blamey's oral response was that Dynamic's extrapolation did not extend above 100 percent or below zero percent.
In cross-examination Polaris' counsel showed Professor Blamey an extrapolation downwards from the 76% correct result to 105dBA and put to him that it was unrealistic to extrapolate on a linear basis.
He replied that counsel's extrapolation was certainly unrealistic.
This written and oral exchange consumed much time, generated many words, but threw little light on the significance of the linear/non linear controversy.
I need not attempt to resolve the disagreement between the experts.
As I have said, Figure 1 is a pictorial representation of the words in particular (b).
The Figure and the sentence explain each other, and the sentence relied on in particular (b) carries the implication asserted by Polaris.
Although its particulars rely on Figure 2 in the report, I did not understand Polaris to have persisted in that reliance.
In any event, in view of what I have said about the sentence in particular (b), I need not spend time on Figure 2.
SOUNDSHIELD NOT COMPLIANT WITH TELSTRA'S INTELLIGIBILITY REQUIREMENT
 Clause 5.2.2 of TT4 requires speech intelligibility of 90% in call centre environments with conversational chatter to 55dBA.
The question is whether the comparison report implies that SoundShield does not comply with this requirement.
Professor Blamey accepted that the 90% sentence in the report was "derived from TT4".
To that sentence should be added the next: 
 
 ADRO on the other hand, easily achieved 90% intelligibility with call centre background noise at a level of 55dBA.

 

 
Professor Blamey agreed that he was not testing to TT4 specifications.
This is the part of the report in which the informed reader will be most interested --- the result of the comparison test.
That reader, especially one with a Telstra affiliation, would recognise the 90% at 55dBA as Telstra's speech intelligibility requirement, and would take from the assertions that to achieve an intelligibility score of 90% with SoundShield, the background noise would have to be reduced to an unrealistic 40dBA, that M15D easily achieved 90% intelligibility with 55dBA background noise, and that SoundShield did not comply with Telstra's speech intelligibility requirement.
The 90% at 55dBA has only one reference point to anyone with knowledge of the specifications applicable in Australia, and that is TT4.
Dynamic was promoting the report as being concerned with TT4 compliance.
It contained the statement that M15D was suitable for TT4 compliance.
Dynamic sent a copy of the report to Telstra asserting, wrongly according to Professor Blamey, that the prototype M15D was TT4 compliant.
SOUNDSHIELD NOT G616 COMPLIANT OR SUITABLE FOR TT4 COMPLIANT OPERATION
 For this implication, particular (c) relies upon the statement in the comparison report that M15D is G616 compliant and suitable for TT4 compliant operation, and the absence of a similar statement about SoundShield.
If this particular stood alone, I would not take it to imply that SoundShield was not TT4 compliant.
There was much evidence about market awareness of SoundShield.
It had, and probably retains, market dominance.
A vast number of sales have been made since 2001 --- at least 60,000.
On the other hand, M15D was a new product, unknown to the market.
In those circumstances, the report's qualified and knowledgeable audience would not see in a statement about M15D an implicit statement to the opposite effect about SoundShield.
However, the particular (c) sentence does not stand alone.
In my view it follows from what I have said about the particular (b) sentence and the one following it (see [218]), that the report implies that SoundShield is not suitable for TT4 compliant operation.
That is because, while speech intelligibility (90% at 55dBA) is only one TT4 requirement, non-satisfaction with it results in a device's non-compliance, even if all other requirements are satisfied.
The comparison report is concerned only with intelligibility for speech.
G616 has no intelligibility requirement.
The assertions referred to at [218] give rise to no implication about SoundShield's compliance with G616.
An informed reader would not see in particular (c) an implication that SoundShield was not G616 compliant.
I refer to what I have said in relation to TT4 at [220].
Were the unsuitability representations misleading?
I have found that representations (a) and (b) at [23] were made, and that representation (c), so far as it concerns TT4 compliance, was made.
The next question is whether they were misleading.
Only three of the particulars to par 10G of the statement of claim were pursued.
The first is that Telstra has purchased SoundShields since 2001 and continues to do so.
I am satisfied that it would not have done this on a past and continuing basis if the devices were unsuitable for use in call centres because of poor intelligibility where background noise is present.
Indeed it was common ground that SoundShield was capable of operating satisfactorily in call centres on MID with an input of 33-36mV.
The second particular is that since 2001 more than 60,000 SoundShield devices, set up by appropriately trained people utilising the Manual, have been installed in call centres throughout Australia without any reported intelligibility problems.
Mr Guest said complaints about poor intelligibility were "very rare".
When there was a complaint, Polaris checked that the settings were properly programmed for the customer's premises.
Adjusting and correcting the settings usually resolved the problem.
Mr Guest's inspection of warranty returns disclosed no case of return as a result of complaints about intelligibility.
Mr Minski said customers had intelligibility problems "quite often" during his five years with Polaris.
But he was speaking of teething difficulties and not substantive problems.
Although the evidence does not establish that there were no reported intelligibility problems over the period during which SoundShield was sold, I am satisfied that apart from teething problems experienced at or shortly after installation, there were very few complaints about intelligibility, and that these were sorted out by Polaris' installers.
That is further evidence (ie in addition to the Telstra custom) that SoundShield is suitable for use in call centres as aforesaid.
The third particular is that when set up by an appropriately trained person utilising the Manual, SoundShield achieves speech intelligibility of 90% in call centres with background voice chatter to 55dBA.
Polaris relies on Mr Fisher's January 2006 and July 2007 tests and Professor Newell's October 2007 test, which it said demonstrated compliance with the 90% intelligibility requirement.
In the January 2006 test Mr Fisher did not use the word test specified in TT4.
He used phonemes instead of words.
Polaris accepted that this was not a complete test of the Telstra intelligibility requirement.
Subject to one issue with which I deal at [230], Mr Fisher's 2007 test demonstrated compliance with the 90% intelligibility requirement.
This time he used the word lists specified in TT4.
However Polaris relied primarily on Professor Newell's test.
That used the limiting requirements, word lists and background noise levels specified in TT4.
The input signal of 48mV was within the range in Table 5.9.
Sixteen test subjects were involved.
Professor Newell's test was scored by word correct and incorrect and by phoneme correct and incorrect.
The 90% requirement was met in all conditions however scored.
Subject to the issue referred to at [230], Professor Newell's test shows that SoundShield complies with the Telstra intelligibility requirement.
The reservation referred to at [228] and [229] relates to Professor Blamey's claim that the input level used in Mr Fisher's test (40mV) and in Professor Newell's test (48mV) did not demonstrate that SoundShield could accept the range of inputs specified in Table 5.9 of TT4.
This table is considered in detail (at [145]-[159]) in connexion with the test set up representations.
Professor Blamey's opinion was that the table "suggests that in every setting of the device which is designed to be used with typical telephone in call centres, the device ... should be able to accept 100mV input signal and achieve 90 per cent speech intelligibility with that input signal".
For the purpose of dealing with the unsuitability requirements, I do not need to come to a conclusion about this very controversial table.
That is because I am satisfied that if set up by an appropriately trained person using the Manual, SoundShield would achieve speech intelligibility of 90% in call centres with voice chatter to 55dBA.
If the installer chose an input in the range 33-48mV, the device would be set to MID.
If the customer insisted on an input of 100mV, the installer would select the HIGH setting in accordance with the instruction in the Manual that "High will be selected for hosts/consoles with a high output level".
There was consistent evidence from the Polaris camp that for a 100mV input the HIGH receive gain setting should be used.
Accordingly, on the basis: of Telstra's past and continuing custom for SoundShields; that there were very few complaints of intelligibility problems in relation to SoundShield's set up by appropriately trained installers; and that when properly set up in accordance with the Manual the device can accommodate an input of 100mV because it would have been set to HIGH by the installer in accordance with the Manual, 
I find that SoundShield:
 
(a) is suitable for use in call centres and, when set up by an appropriately trained person utilising the Manual, does not have poor intelligibility when background noise is present;
 
(b) complies with the Telstra intelligibility requirement, and
 
(c) is suitable for TT4 compliant operation so far as speech intelligibility is concerned.
In relation to (c), "suitable" is the word used in Polaris' pleadings and in the comparison report.
By that word, I understand Polaris to mean that SoundShield is capable of meeting the intelligibility standard required by TT4, as opposed to being TT4 compliant in the more general sense.
As appears above, Professor Blamey did not dispute that the device was able to meet the Telstra intelligibility requirement at "lower input levels".
The case was not concerned with SoundShield's compliance with TT4 in respects other than speech intelligibility.
Hence the words "so far as speech intelligibility is concerned" in (c).
CONCLUSION 
 I have found that the lowest limiting setting representation was made, and that in the comparison test SoundShield's lowest limiting setting was 95dBA and M15D's was 102dBA.
However Polaris has not established that the difference between the two settings made speech heard through the M15D significantly more intelligible than that through SoundShield.
Thus it has not established that the testing of the two devices at their lowest limiting settings provided an inappropriate comparative basis for testing for intelligibility of speech.
The ethics approval representation was made, but was not misleading or deceptive or likely to mislead or deceive.
The test set up representations were made.
The representations pleaded in pars 10H(a), (c) and (d) were misleading or deceptive or likely to mislead or deceive by reason of the fact that: the test upon which the comparison report was based did not contain a suitable control condition; in conducting the test, Dynamic did not follow the randomisation table in the test protocol; and Dynamic did not inform itself adequately of the appropriate settings for SoundShield in the test conditions, nor did it enlist the assistance of a person appropriately trained in the installation of SoundShield.

The representation pleaded at par 10H(b) was not misleading or deceptive or likely to mislead or deceive.
The unsuitability representations pleaded in par 10F(a) and (b) of the statement of claim were made.
It was also represented that SoundShield was not suitable for TT4 compliant operation.
There was no representation that the device was not G616 compliant.
The representations were misleading or deceptive or likely to mislead or deceive.
Polaris has thus made out its case under s 52 of the Act in relation to the unsuitability representations.
Polaris also pleaded its case in relation to the lowest limiting setting and unsuitability representations in reliance on s 53(a) of the Act, namely that the respondents falsely represented that the two devices were each of a particular comparative standard, quality or grade.
I did not understand it to be in dispute that if the unsuitability representations were found to have been made and were misleading, that would constitute a contravention of s 53(a).
In any event, I have concluded that s 53(a) was contravened.
The representations that SoundShield was unsuitable for use in call centres, did not comply with Telstra's intelligibility requirement and was not suitable for TT4 compliant operation, were all false representations that SoundShield was of a particular standard, quality or grade, in that it did not measure up to levels that were required for an acoustic limiting device to be suitable for use in call centres, to comply with Telstra's intelligibility requirement and to be suitable for TT4 compliant operation.
Polaris has alleged breaches of s 9 and s 12(a) of the Fair Trading Act 1991 (Vic).
What I have said about s 52 and s 53(a) of the Act is applicable to ss 9 and 12(a) as well.
Dynamic admits that it published and distributed the report.
Plantronics admits that it provided a copy of the report to Westpac and Siemens, but denies that it caused the report to be published and that it adopted and disseminated the statements and representations contained in it.
I am satisfied that the report was prepared by Dynamic in consultation with Plantronics.
Mr Gherbaz suggested amendments and modifications to the document initially proposed by Dynamic.
Plantronics was not a mere conduit for the carriage of information to those who received the report.
The recipients would regard Plantronics as having adopted its contents, and thus as having made the representations contained in it.
See Gardam v George Wills  Co Ltd [1988] FCA 194 ; (1998) 82 ALR 415 at 427.
I did not understand this matter to have been in dispute.
ORDERS 
 I will not at this stage make final orders.
I will stand the matter over in order that the parties have an opportunity to consider the orders that should be made to give effect to these reasons, and to deal with the question of costs.
If by 25 August 2009 the parties are unable to agree on the orders that should be made, Polaris should within seven days of that date file and serve a notice of the orders it proposes should be made together with an outline of submissions in support thereof, not to exceed five pages in length.
Dynamic and Plantronics should each, within seven days of receipt of Polaris' notice and outline, file and serve a notice of the orders it proposes should be made together with an outline of submissions in support thereof, not to exceed five pages in length.
I certify that the preceding two hundred and forty-two (242) numbered paragraphs are a true copy of the Reasons for Judgment herein of the Honourable Justice Sundberg.
Associate:
 
 
Dated: 18 August 2009
 
 Counsel for the Applicant: C Golvan SC and S Gatford 
 
 Solicitor for the Applicant: GSM Lawyers 
 
 Counsel for the First Respondent: R Kendall QC and M Lapirow 
 
 Solicitor for the First Respondent: Ebsworth  Ebsworth 
 
 Counsel for the Second Respondent: P Crennan 
 
 Solicitor for the Second Respondent: Allens Arthur Robinson 
 Date of Hearing: 14-17, 20-23 April, 25-27 May, 4-5 June 2009 
 
 Date of Judgment: 18 August 2009 
 

 
 AustLII: Copyright Policy | Disclaimers | Privacy Policy | Feedback 
 URL: http://www.austlii.edu.au/au/cases/cth/FCA/2009/890.html 
 
 
